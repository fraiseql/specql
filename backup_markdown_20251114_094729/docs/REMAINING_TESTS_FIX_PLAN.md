# Remaining Test Fixes - Phased Implementation Plan

**Project**: SpecQL Code Generator
**Current Status**: 803/846 tests passing (94.9%)
**Remaining**: 7 FAILED + 7 ERROR tests
**Goal**: 100% passing tests
**Estimated Time**: 3-4 hours
**PostgreSQL Server**: ✅ Available (localhost, active)

---

## Executive Summary

After completing Phases 1-5 of the test suite fixes, we have **14 remaining test issues**:

1. **7 ERROR Tests**: Database integration tests missing `test_db_connection` fixture
2. **6 FAILED Tests**: CLI output format expectations need updating
3. **1 FAILED Test**: Confiture integration test expecting old annotation format

All are straightforward fixes now that the core functionality is working.

---

## Current Test Status

```bash
# Run to verify current state
uv run pytest --tb=no -q

# Expected output:
# 7 failed, 803 passed, 36 skipped, 7 errors in ~30s
```

**Breakdown**:
- ✅ **803 passing** (94.9%)
- ❌ **7 failed** (CLI + 1 confiture)
- ⚠️ **7 errors** (database fixtures missing)
- ⏭️ **36 skipped** (intentional - require specific setup)

---

## Phase 7: Database Integration Tests Setup

**Priority**: HIGH (if CI/CD needed) or MEDIUM (if local testing only)
**Estimated Time**: 2-2.5 hours
**Files to Modify**: 2 files (fixtures + config)
**Tests Fixed**: 7 ERROR tests

### Problem Description

Database integration tests in `tests/pytest/test_contact_integration.py` require a `test_db_connection` fixture that doesn't exist. These tests are designed to verify that generated SQL actually works in PostgreSQL.

**Tests Affected**:
- `test_create_contact_happy_path`
- `test_create_duplicate_contact_fails`
- `test_update_contact_happy_path`
- `test_delete_contact_happy_path`
- `test_full_crud_workflow`
- `test_qualify_lead`
- `test_convert_to_customer`

**All 7 tests** use the `test_db_connection` fixture but it's not defined.

### PostgreSQL Status

✅ **PostgreSQL Server**: Active and running
- Version: PostgreSQL 17.6
- Location: `localhost` (default port 5432)

### Implementation Steps

#### Step 7.1: Create Test Database (30 minutes)

**Task**: Set up a dedicated test database for SpecQL

```bash
# Create test database
sudo -u postgres createdb specql_test

# Or connect and create manually
sudo -u postgres psql
CREATE DATABASE specql_test;
CREATE USER specql_test WITH PASSWORD 'specql_test_password';
GRANT ALL PRIVILEGES ON DATABASE specql_test TO specql_test;
\q

# Verify connection
psql -h localhost -U specql_test -d specql_test -c "SELECT version();"
```

**Alternative (if you have a postgres user setup)**:
```bash
createdb specql_test
psql specql_test -c "SELECT version();"
```

#### Step 7.2: Initialize Database Schema (30 minutes)

**Task**: Load the foundation and contact schema into test database

**File to Create**: `tests/pytest/setup_test_db.sql`

```sql
-- Drop existing schemas if they exist
DROP SCHEMA IF EXISTS app CASCADE;
DROP SCHEMA IF EXISTS crm CASCADE;
DROP SCHEMA IF EXISTS common CASCADE;
DROP SCHEMA IF EXISTS core CASCADE;

-- Create schemas
CREATE SCHEMA app;
CREATE SCHEMA crm;
CREATE SCHEMA common;
CREATE SCHEMA core;

-- Create app.mutation_result type
CREATE TYPE app.mutation_result AS (
    id UUID,
    updated_fields TEXT[],
    status TEXT,
    message TEXT,
    object_data JSONB,
    _meta JSONB
);

-- Create app.type_create_contact_input type
CREATE TYPE app.type_create_contact_input AS (
    email TEXT,
    first_name TEXT,
    last_name TEXT,
    company_id TEXT,
    status TEXT,
    phone TEXT
);

-- Create Contact table (Trinity pattern)
CREATE TABLE crm.tb_contact (
    pk_contact INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    id UUID DEFAULT gen_random_uuid() NOT NULL UNIQUE,
    identifier TEXT,
    tenant_id UUID NOT NULL,
    email TEXT,
    first_name TEXT NOT NULL,
    last_name TEXT NOT NULL,
    fk_company INTEGER,
    status TEXT,
    phone TEXT,
    created_at TIMESTAMP DEFAULT now(),
    created_by UUID,
    updated_at TIMESTAMP DEFAULT now(),
    updated_by UUID,
    deleted_at TIMESTAMP
);

-- Create indexes
CREATE INDEX idx_contact_tenant ON crm.tb_contact(tenant_id);
CREATE INDEX idx_contact_email ON crm.tb_contact(email);
CREATE INDEX idx_contact_status ON crm.tb_contact(status);

-- Create Company table (for FK testing)
CREATE TABLE crm.tb_company (
    pk_company INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    id UUID DEFAULT gen_random_uuid() NOT NULL UNIQUE,
    identifier TEXT,
    tenant_id UUID NOT NULL,
    name TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT now(),
    created_by UUID,
    updated_at TIMESTAMP DEFAULT now(),
    updated_by UUID,
    deleted_at TIMESTAMP
);

-- Add FK constraint
ALTER TABLE crm.tb_contact ADD CONSTRAINT fk_contact_company
    FOREIGN KEY (fk_company) REFERENCES crm.tb_company(pk_company);

-- Trinity helper functions
CREATE OR REPLACE FUNCTION crm.company_pk(company_identifier TEXT, tenant_id UUID)
RETURNS INTEGER AS $$
    SELECT pk_company
    FROM crm.tb_company
    WHERE identifier = company_identifier
      AND crm.tb_company.tenant_id = company_pk.tenant_id
      AND deleted_at IS NULL;
$$ LANGUAGE SQL;

CREATE OR REPLACE FUNCTION crm.contact_pk(contact_identifier TEXT, tenant_id UUID)
RETURNS INTEGER AS $$
    SELECT pk_contact
    FROM crm.tb_contact
    WHERE identifier = contact_identifier
      AND crm.tb_contact.tenant_id = contact_pk.tenant_id
      AND deleted_at IS NULL;
$$ LANGUAGE SQL;

-- Audit logging function
CREATE OR REPLACE FUNCTION app.log_and_return_mutation(
    auth_tenant_id UUID,
    auth_user_id UUID,
    entity_name TEXT,
    entity_id UUID,
    operation TEXT,
    status TEXT,
    updated_fields TEXT[],
    message TEXT,
    object_data JSONB,
    extra JSONB,
    error_details JSONB DEFAULT NULL
) RETURNS app.mutation_result AS $$
DECLARE
    result app.mutation_result;
BEGIN
    -- Build result
    result.id := entity_id;
    result.updated_fields := updated_fields;
    result.status := status;
    result.message := message;
    result.object_data := object_data;
    result._meta := COALESCE(extra, '{}'::JSONB);

    -- In a real implementation, this would log to audit table
    -- For tests, just return the result

    RETURN result;
END;
$$ LANGUAGE plpgsql;
```

**Load into database**:
```bash
psql specql_test < tests/pytest/setup_test_db.sql

# Or if using user credentials:
psql -h localhost -U specql_test -d specql_test < tests/pytest/setup_test_db.sql
```

#### Step 7.3: Load Generated Contact Mutations (30 minutes)

**Task**: Generate and load the actual contact mutation functions

```bash
# Generate contact migrations
cd /home/lionel/code/printoptim_backend_poc

# Generate SQL from contact entity
uv run python -c "
from pathlib import Path
from src.core.specql_parser import SpecQLParser
from src.generators.schema_orchestrator import SchemaOrchestrator

# Parse contact entity
contact_yaml = Path('entities/examples/contact_lightweight.yaml').read_text()
parser = SpecQLParser()
contact_entity = parser.parse(contact_yaml)

# Generate all SQL (actions only, skip schema we already loaded)
orchestrator = SchemaOrchestrator()
action_sql = orchestrator.generate_action_sql([contact_entity])

# Write to file
Path('tests/pytest/contact_actions.sql').write_text(action_sql)
print('Generated contact_actions.sql')
"

# Load into database
psql specql_test < tests/pytest/contact_actions.sql
```

**Alternative Manual Approach**:
Copy the generated SQL from test output (it was shown in the confiture test failure) into `tests/pytest/contact_actions.sql` and load it.

#### Step 7.4: Create Database Fixture (30 minutes)

**File**: `tests/pytest/conftest.py` (create if doesn't exist)

```python
"""Pytest fixtures for database integration tests"""

import os
import pytest
import psycopg
from psycopg import Connection


@pytest.fixture(scope="session")
def db_config():
    """Database configuration from environment or defaults"""
    return {
        "host": os.getenv("TEST_DB_HOST", "localhost"),
        "port": int(os.getenv("TEST_DB_PORT", "5432")),
        "dbname": os.getenv("TEST_DB_NAME", "specql_test"),
        "user": os.getenv("TEST_DB_USER", os.getenv("USER")),
        "password": os.getenv("TEST_DB_PASSWORD", ""),
    }


@pytest.fixture(scope="session")
def test_db_connection(db_config):
    """
    Create database connection for integration tests

    Environment variables (optional):
    - TEST_DB_HOST: Database host (default: localhost)
    - TEST_DB_PORT: Database port (default: 5432)
    - TEST_DB_NAME: Database name (default: specql_test)
    - TEST_DB_USER: Database user (default: current user)
    - TEST_DB_PASSWORD: Database password (default: empty)

    To skip database tests:
        pytest -m "not database"
    """
    try:
        # Build connection string
        conn_parts = [
            f"host={db_config['host']}",
            f"port={db_config['port']}",
            f"dbname={db_config['dbname']}",
            f"user={db_config['user']}",
        ]

        if db_config['password']:
            conn_parts.append(f"password={db_config['password']}")

        conn_string = " ".join(conn_parts)

        # Connect
        conn = psycopg.connect(conn_string, autocommit=False)

        # Verify connection
        with conn.cursor() as cur:
            cur.execute("SELECT version()")
            version = cur.fetchone()[0]
            print(f"\n✅ Database connected: {version[:50]}...")

        yield conn

        # Cleanup
        conn.close()

    except psycopg.OperationalError as e:
        pytest.skip(
            f"Database not available: {e}\n"
            f"To run database tests:\n"
            f"  1. Create database: createdb {db_config['dbname']}\n"
            f"  2. Load schema: psql {db_config['dbname']} < tests/pytest/setup_test_db.sql\n"
            f"  3. Load actions: psql {db_config['dbname']} < tests/pytest/contact_actions.sql"
        )


@pytest.fixture
def clean_contact_table(test_db_connection):
    """Clean contact table before each test"""
    with test_db_connection.cursor() as cur:
        cur.execute("DELETE FROM crm.tb_contact")
        cur.execute("DELETE FROM crm.tb_company")
    test_db_connection.commit()

    yield test_db_connection

    # Cleanup after test
    test_db_connection.rollback()
```

#### Step 7.5: Mark Database Tests (15 minutes)

**File**: `tests/pytest/test_contact_integration.py`

**Add at top of file** (after imports):
```python
import pytest

# Mark all tests in this file as requiring database
pytestmark = pytest.mark.database
```

**Update pytest configuration** (`pyproject.toml`):
```toml
[tool.pytest.ini_options]
markers = [
    "database: marks tests as requiring database (deselect with '-m \"not database\"')",
]
```

#### Step 7.6: Update Test Fixtures (15 minutes)

**File**: `tests/pytest/test_contact_integration.py`

**Update the `clean_db` fixture**:
```python
@pytest.fixture
def clean_db(self, test_db_connection):
    """Clean Contact table before test"""
    # No changes needed - the fixture from conftest.py will be used
    with test_db_connection.cursor() as cur:
        cur.execute("DELETE FROM crm.tb_contact")
        cur.execute("DELETE FROM crm.tb_company")  # Also clean company
    test_db_connection.commit()
    yield test_db_connection
    # Rollback after test to clean up
    test_db_connection.rollback()
```

#### Step 7.7: Test Database Connection (10 minutes)

```bash
# Test the database fixture
uv run pytest tests/pytest/test_contact_integration.py::TestContactIntegration::test_create_contact_happy_path -xvs

# If successful, run all database tests
uv run pytest tests/pytest/test_contact_integration.py -v

# To skip database tests in CI without PostgreSQL:
uv run pytest -m "not database" -v
```

**Expected Issues to Debug**:
1. **Schema not found**: Reload `setup_test_db.sql`
2. **Functions not found**: Generate and load `contact_actions.sql`
3. **Type errors**: Verify `app.type_create_contact_input` matches generated code
4. **Connection refused**: Check PostgreSQL is running

#### Step 7.8: Fix Schema Mismatches (30 minutes)

**Likely Issue**: Generated functions might expect different composite type structure

**Debugging Steps**:

1. **Check what types are needed**:
```bash
psql specql_test -c "\dT app.*"
```

2. **Check what functions expect**:
```bash
psql specql_test -c "\df app.create_contact"
```

3. **Update `setup_test_db.sql`** if types don't match:
```sql
-- Check generated SQL for exact type definition
-- Example from confiture test output:
CREATE TYPE app.type_create_contact_input AS (
    email TEXT,
    first_name TEXT,
    last_name TEXT,
    company_id TEXT,  -- Note: might be UUID or TEXT
    status TEXT,
    phone TEXT
);
```

4. **Reload schema**:
```bash
psql specql_test < tests/pytest/setup_test_db.sql
psql specql_test < tests/pytest/contact_actions.sql
```

### Success Criteria

- ✅ Database `specql_test` created
- ✅ Schema loaded (app, crm, common, core)
- ✅ Contact table created with Trinity pattern
- ✅ Contact mutations (create, update, delete, qualify_lead) loaded
- ✅ `test_db_connection` fixture working
- ✅ All 7 database integration tests passing

**Verification**:
```bash
uv run pytest tests/pytest/ -v

# Expected:
# 7 passed in ~2.0s
```

---

## Phase 8: CLI Test Updates

**Priority**: MEDIUM
**Estimated Time**: 45 minutes - 1 hour
**Files to Modify**: 2 test files
**Tests Fixed**: 6 FAILED tests

### Problem Description

CLI tests expect detailed output including entity names, but the CLI now outputs simpler summary messages like "✅ Generated 2 migration(s)".

**Tests Affected**:
- `test_convert_entity_with_actions` - Entity conversion expectations
- `test_entities_with_single_file` - Expects "contact" in output
- `test_entities_multiple_files` - Expects entity names in output
- `test_entities_invalid_file_error` - Error message format changed
- `test_entities_output_directory_creation` - Directory creation verification
- `test_generate_with_single_entity` - Orchestrator output format

### Implementation Steps

#### Step 8.1: Understand Current CLI Output (15 minutes)

**Task**: Run CLI manually to see actual output

```bash
cd /home/lionel/code/printoptim_backend_poc

# Create temp test directory
mkdir -p /tmp/specql_cli_test

# Run CLI with sample entity
uv run python -m src.cli.generate entities/examples/contact_lightweight.yaml \
    --output-dir /tmp/specql_cli_test

# Check output format
ls -la /tmp/specql_cli_test/

# Try with multiple files
uv run python -m src.cli.generate entities/examples/*.yaml \
    --output-dir /tmp/specql_cli_test

# Try with errors
echo "invalid: yaml: content" > /tmp/invalid.yaml
uv run python -m src.cli.generate /tmp/invalid.yaml \
    --output-dir /tmp/specql_cli_test
```

**Document**:
1. Exact output format for successful generation
2. Exact output format for errors
3. What files are created
4. Exit codes

#### Step 8.2: Fix test_convert_entity_with_actions (10 minutes)

**File**: `tests/unit/cli/test_generate.py:25-47`

**Test**: `TestConvertEntityDefinitionToEntity::test_convert_entity_with_actions`

**Current Failure**: Unknown (need to check exact error)

**Check the failure**:
```bash
uv run pytest tests/unit/cli/test_generate.py::TestConvertEntityDefinitionToEntity::test_convert_entity_with_actions -xvs
```

**Likely Fix**: Update action structure expectations

```python
def test_convert_entity_with_actions(self, specql_parser):
    """Test conversion with action definitions."""
    yaml_content = """
entity: TestEntity
fields:
  email: text
  name: text
actions:
  - name: create
    steps:
      - type: insert
        table: test_entity
  - name: update
    steps:
      - type: update
        table: test_entity
"""
    entity_def = specql_parser.parse(yaml_content)
    entity = convert_entity_definition_to_entity(entity_def)

    assert len(entity.actions) == 2
    assert entity.actions[0].name == "create"
    assert entity.actions[1].name == "update"

    # NEW: Check action steps structure if needed
    # assert len(entity.actions[0].steps) == 1
    # assert entity.actions[0].steps[0]['type'] == 'insert'
```

#### Step 8.3: Fix test_entities_with_single_file (10 minutes)

**File**: `tests/unit/cli/test_generate.py:86-103`

**Test**: `TestGenerateCLI::test_entities_with_single_file`

**Current Failure**: Expects "contact" in output, but output is just "✅ Generated 2 migration(s)"

**Fix Options**:

**Option A: Remove entity name expectation** (RECOMMENDED):
```python
def test_entities_with_single_file(self, cli_runner, sample_entity_file, temp_dir):
    """Test generation with a single entity file."""
    output_dir = temp_dir / "migrations"

    result = cli_runner.invoke(
        cli, ["entities", str(sample_entity_file), "--output-dir", str(output_dir)]
    )

    assert result.exit_code == 0
    # OLD: assert "contact" in result.output.lower()
    # NEW: Just check files were created
    assert (output_dir / "000_app_foundation.sql").exists()

    # Verify at least one migration file was created
    migration_files = list(output_dir.glob("*.sql"))
    assert len(migration_files) >= 2  # foundation + contact
```

**Option B: Enhance CLI to show entity names**:
```python
# In src/cli/generate.py - add verbose output
click.echo(f"✅ Generated 2 migration(s):")
click.echo(f"  - 000_app_foundation.sql")
click.echo(f"  - 100_contact.sql")
```

#### Step 8.4: Fix test_entities_multiple_files (10 minutes)

**File**: `tests/unit/cli/test_generate.py:105-120`

**Test**: `TestGenerateCLI::test_entities_multiple_files`

**Similar Fix to 8.3**: Remove entity name expectations, check files created instead

```python
def test_entities_multiple_files(self, cli_runner, temp_dir):
    """Test generation with multiple entity files."""
    # Create test entity files
    entities_dir = temp_dir / "entities"
    entities_dir.mkdir()

    # ... create files ...

    result = cli_runner.invoke(
        cli, ["entities", str(entities_dir / "*.yaml"), "--output-dir", str(output_dir)]
    )

    assert result.exit_code == 0
    # Check migrations were created
    migration_files = list(output_dir.glob("*.sql"))
    assert len(migration_files) >= 3  # foundation + 2 entities
```

#### Step 8.5: Fix test_entities_invalid_file_error (10 minutes)

**File**: `tests/unit/cli/test_generate.py:122-135`

**Test**: `TestGenerateCLI::test_entities_invalid_file_error`

**Check current error format**:
```bash
uv run pytest tests/unit/cli/test_generate.py::TestGenerateCLI::test_entities_invalid_file_error -xvs
```

**Update assertion to match actual error format**:
```python
def test_entities_invalid_file_error(self, cli_runner, temp_dir):
    """Test error handling for invalid entity file."""
    invalid_file = temp_dir / "invalid.yaml"
    invalid_file.write_text("invalid: yaml: content: [")

    result = cli_runner.invoke(
        cli, ["entities", str(invalid_file), "--output-dir", str(temp_dir)]
    )

    # Check that error occurred
    assert result.exit_code != 0

    # OLD: assert "Error processing" in result.output
    # NEW: Match actual error format (from earlier test output)
    assert "Failed to parse" in result.output or "error" in result.output.lower()
```

#### Step 8.6: Fix test_entities_output_directory_creation (5 minutes)

**File**: `tests/unit/cli/test_generate.py:137-150`

**Test**: `TestGenerateCLI::test_entities_output_directory_creation`

**Likely Issue**: Just needs exit code or output format update

```bash
uv run pytest tests/unit/cli/test_generate.py::TestGenerateCLI::test_entities_output_directory_creation -xvs
```

#### Step 8.7: Fix test_generate_with_single_entity (10 minutes)

**File**: `tests/unit/cli/test_orchestrator.py:90-110`

**Test**: `TestCLIOrchestrator::test_generate_with_single_entity`

**Check failure**:
```bash
uv run pytest tests/unit/cli/test_orchestrator.py::TestCLIOrchestrator::test_generate_with_single_entity -xvs
```

**Similar fix**: Update output expectations or check files instead

### Success Criteria

- ✅ All 6 CLI tests passing
- ✅ CLI still works correctly when run manually
- ✅ Error messages still helpful to users

**Verification**:
```bash
uv run pytest tests/unit/cli/test_generate.py -v
uv run pytest tests/unit/cli/test_orchestrator.py -v

# Expected:
# 9+ passed (all CLI tests)
```

---

## Phase 9: Confiture Integration Test Fix

**Priority**: LOW
**Estimated Time**: 10 minutes
**Files to Modify**: 1 test file
**Tests Fixed**: 1 FAILED test

### Problem Description

The confiture integration test expects inline FraiseQL annotation format (`name=createContact`) but actual code uses YAML format (`name: createContact`).

**Test Affected**:
- `tests/integration/test_confiture_integration.py::TestConfitureIntegration::test_mutation_files_contain_correct_structure`

### Implementation Steps

#### Step 9.1: Update Test Assertion (10 minutes)

**File**: `tests/integration/test_confiture_integration.py:175-185`

**Current Code**:
```python
def test_mutation_files_contain_correct_structure(self):
    """Test: Mutation files contain app wrapper + core logic + FraiseQL"""
    # ... generate SQL ...

    # Check FraiseQL annotations
    assert "name=createContact" in content  # ❌ FAILS - wrong format
```

**Fixed Code**:
```python
def test_mutation_files_contain_correct_structure(self):
    """Test: Mutation files contain app wrapper + core logic + FraiseQL"""
    # ... generate SQL ...

    # Check FraiseQL annotations (YAML format)
    assert "@fraiseql:mutation" in content
    assert "name: createContact" in content  # ✅ YAML format
    assert "input_type: app.type_create_contact_input" in content
    assert "success_type: CreateContactSuccess" in content
    assert "failure_type: CreateContactError" in content
```

### Success Criteria

- ✅ Confiture integration test passing
- ✅ Still validates FraiseQL annotation structure

**Verification**:
```bash
uv run pytest tests/integration/test_confiture_integration.py::TestConfitureIntegration::test_mutation_files_contain_correct_structure -xvs

# Expected:
# 1 passed
```

---

## Execution Order

### Critical Path (Must Complete)

1. **Phase 7**: Database Integration Tests (2-2.5 hours)
   - Most complex, most valuable
   - Validates generated SQL actually works
   - 7 ERROR tests → PASSING

2. **Phase 8**: CLI Test Updates (45-60 minutes)
   - Medium complexity
   - Validates CLI UX
   - 6 FAILED tests → PASSING

3. **Phase 9**: Confiture Test Fix (10 minutes)
   - Trivial fix
   - 1 FAILED test → PASSING

**Total Time**: 3.5-4 hours
**Tests Fixed**: 14 tests
**Final Result**: 846/846 tests passing (100%)

---

## Testing Strategy

### After Each Phase

```bash
# Phase 7 - Database tests
uv run pytest tests/pytest/test_contact_integration.py -v

# Phase 8 - CLI tests
uv run pytest tests/unit/cli/ -v

# Phase 9 - Confiture test
uv run pytest tests/integration/test_confiture_integration.py::TestConfitureIntegration::test_mutation_files_contain_correct_structure -xvs
```

### Final Verification

```bash
# Full test suite
uv run pytest --tb=short

# Should see:
# ===== 846 passed, 36 skipped in ~35s =====

# Generate summary
uv run pytest --tb=no -q

# With database tests
uv run pytest -m database -v

# Without database tests (for CI without PostgreSQL)
uv run pytest -m "not database" -v
```

---

## Database Setup Quick Reference

```bash
# 1. Create database
createdb specql_test

# 2. Create schema file
cat > tests/pytest/setup_test_db.sql << 'EOF'
# (paste schema from Step 7.2)
EOF

# 3. Load schema
psql specql_test < tests/pytest/setup_test_db.sql

# 4. Generate actions
# (run Python script from Step 7.3)

# 5. Load actions
psql specql_test < tests/pytest/contact_actions.sql

# 6. Verify
psql specql_test -c "\dt crm.*"
psql specql_test -c "\df app.create_contact"

# 7. Run tests
uv run pytest tests/pytest/ -v
```

---

## Environment Variables

For flexible database configuration:

```bash
# Set these in your environment or .env file
export TEST_DB_HOST=localhost
export TEST_DB_PORT=5432
export TEST_DB_NAME=specql_test
export TEST_DB_USER=$USER
export TEST_DB_PASSWORD=  # empty for peer auth

# Or use .env file
cat > .env << 'EOF'
TEST_DB_HOST=localhost
TEST_DB_PORT=5432
TEST_DB_NAME=specql_test
TEST_DB_USER=your_username
TEST_DB_PASSWORD=your_password
EOF
```

---

## Troubleshooting

### Database Connection Issues

**Error**: `psycopg.OperationalError: connection failed`

**Solutions**:
1. Check PostgreSQL is running: `systemctl status postgresql`
2. Check database exists: `psql -l | grep specql_test`
3. Check user permissions: `psql specql_test -c "SELECT current_user;"`
4. Check pg_hba.conf for peer/md5 auth

### Schema Loading Issues

**Error**: `ERROR: schema "crm" does not exist`

**Solutions**:
1. Reload schema: `psql specql_test < tests/pytest/setup_test_db.sql`
2. Check schemas: `psql specql_test -c "\dn"`
3. Verify connection to right database: `psql specql_test -c "SELECT current_database();"`

### Function Missing Issues

**Error**: `ERROR: function app.create_contact(...) does not exist`

**Solutions**:
1. Regenerate actions: (run Python script from Step 7.3)
2. Load actions: `psql specql_test < tests/pytest/contact_actions.sql`
3. Check functions: `psql specql_test -c "\df app.*"`
4. Check function signature: `psql specql_test -c "\df+ app.create_contact"`

### Type Mismatch Issues

**Error**: `ERROR: type "app.type_create_contact_input" does not exist`

**Solutions**:
1. Check types: `psql specql_test -c "\dT app.*"`
2. Verify type definition matches generated code
3. Reload schema with correct type definition

---

## Rollback Plan

If database tests cause issues:

```bash
# 1. Mark tests to skip by default
# In tests/pytest/conftest.py:
pytestmark = pytest.mark.skipif(
    not os.getenv("ENABLE_DB_TESTS"),
    reason="Database tests require ENABLE_DB_TESTS=1"
)

# 2. Run tests without database
uv run pytest -m "not database" -v

# 3. Drop test database if needed
dropdb specql_test
```

---

## Success Metrics

### Minimum Success
- ✅ Phase 9 complete (confiture test) - 1 test
- ✅ Phase 8 complete (CLI tests) - 6 tests
- ✅ 810+ tests passing (95%+)

### Full Success
- ✅ Phase 7 complete (database tests) - 7 tests
- ✅ Phase 8 complete (CLI tests) - 6 tests
- ✅ Phase 9 complete (confiture test) - 1 test
- ✅ 846/846 tests passing (100%)
- ✅ All integration tests working with real PostgreSQL

---

## Documentation Updates

After completion, update:

1. **README.md**: Add database setup instructions
2. **GETTING_STARTED.md**: Document how to run tests
3. **CLAUDE.md**: Update test status to 100% passing
4. **.github/workflows/**: Add CI database setup (if applicable)

---

## Agent Handoff Checklist

The implementing agent should:

1. ✅ Read this entire implementation plan
2. ✅ Verify PostgreSQL is running
3. ✅ Execute Phase 9 first (quickest win)
4. ✅ Execute Phase 8 (CLI tests)
5. ✅ Execute Phase 7 (database setup - most complex)
6. ✅ Run full test suite after each phase
7. ✅ Document any issues encountered
8. ✅ Report final test results

**Good luck! You're in the home stretch - 100% test coverage is within reach!**
