# Weeks 12-14: 100% Trinity Pattern Equivalence

**Date**: 2025-11-13
**Duration**: 15 days (3 weeks)
**Status**: âœ… Completed
**GitHub Issue**: #10
**Objective**: Achieve 100% equivalence between SpecQL-generated and manual Trinity pattern schemas

**Prerequisites**: Week 4 complete (Self-Schema Dogfooding - 95% equivalence achieved)
**Output**: Complete Trinity pattern generation with tb_/tv_ tables, advanced PostgreSQL features, FraiseQL integration

---

## ðŸŽ¯ Executive Summary

**Current State**: SpecQL achieves 95% functional equivalence through Week 4's self-schema dogfooding
**Missing 5%**: Complete Trinity pattern with base tables, advanced features, and perfect FraiseQL integration
**Business Impact**: Zero manual SQL for enterprise-grade schemas with vector search, full-text search, and GraphQL

### What Gets Implemented

1. **Base Table Generation (tb_)**: Normalized storage with full Trinity pattern
2. **Table View Generation (tv_)**: Denormalized JSONB views for GraphQL
3. **Advanced PostgreSQL**: Vector embeddings (HNSW), full-text search (GIN)
4. **Trinity Helper Functions**: UUID â†” INTEGER conversion utilities
5. **FraiseQL Integration**: Complete GraphQL annotations and metadata
6. **Organization Metadata**: Hierarchical table codes and domain structure

### Success Criteria

- [x] SpecQL generates both `tb_` base tables AND `tv_` table views
- [x] **Enhanced type system** with subtypes (integer:big, decimal:money, text:short)
- [x] **Context-aware type inference** for smart defaults
- [x] Vector embeddings and HNSW indexes auto-generated
- [x] Full-text search columns and GIN indexes included
- [x] Trinity helper functions generated per entity
- [x] FraiseQL annotations on all database objects
- [x] 100% equivalence with manually-written Trinity schemas
- [x] Complete test coverage for all new features

---

## ðŸ“š Type System Foundation

**Reference**: See `TYPE_SYSTEM_SPECIFICATION.md` for complete type system details

### Enhanced Type System (NEW!)

SpecQL now supports **optional subtypes** for precise type control:

```yaml
# Format: type:subtype
fields:
  # Integers
  id: integer              # â†’ integer:big (smart default)
  age: integer:small       # Explicit â†’ smallint
  count: integer:int       # Explicit â†’ integer

  # Decimals
  price: decimal:money     # numeric(10,2)
  latitude: decimal:geo    # numeric(9,6)
  tax_rate: decimal:percent # numeric(5,4)

  # Text
  email: text:short        # varchar(255)
  description: text:long   # text
  code: text:tiny          # varchar(10)
```

**Benefits:**
- âœ… **Backward compatible**: Existing YAML still works
- âœ… **Smart defaults**: Auto-inferred from context
- âœ… **Performance**: Right-size types for indexes
- âœ… **Cross-language**: Accurate Java/Rust/Go mapping

**Implementation**: Integrated throughout Week 12

---

## Week 12: Enhanced Type System & Base Table Generation

**Objective**: Implement enhanced type system and generate complete `tb_` base tables with full Trinity pattern

### Day 1: Base Table Template & Generator

**Morning Block (4 hours): Template Design**

#### ðŸ”´ RED: Write Failing Tests (2 hours)

**Test File**: `tests/unit/generators/schema/test_base_table_generator.py`

```python
"""Tests for base table (tb_) generation with Trinity pattern"""

import pytest
from src.generators.schema.base_table_generator import BaseTableGenerator
from src.core.specql_parser import Entity, Field

class TestBaseTableGeneration:
    """Test generation of tb_ base tables with Trinity pattern"""

    @pytest.fixture
    def generator(self):
        return BaseTableGenerator()

    @pytest.fixture
    def sample_entity(self):
        return Entity(
            name="Contact",
            schema="crm",
            fields=[
                Field(name="email", field_type="text", required=True),
                Field(name="company", field_type="ref", ref_entity="Company"),
                Field(name="status", field_type="enum", enum_values=["lead", "qualified"]),
            ],
            organization={
                "domain": "customer",
                "subdomain": "contacts",
                "table_code": "012361"
            }
        )

    def test_generate_base_table_with_trinity_pattern(self, generator, sample_entity):
        """Test base table includes full Trinity pattern"""
        # Act
        result = generator.generate(sample_entity)

        # Assert - Trinity pattern fields
        assert "pk_contact INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY" in result
        assert "id UUID DEFAULT gen_random_uuid() NOT NULL" in result
        assert "CONSTRAINT tb_contact_id_key UNIQUE (id)" in result

    def test_generate_base_table_with_audit_fields(self, generator, sample_entity):
        """Test base table includes complete audit trail"""
        # Act
        result = generator.generate(sample_entity)

        # Assert - All 6 audit fields
        assert "created_at TIMESTAMPTZ NOT NULL DEFAULT now()" in result
        assert "created_by UUID" in result
        assert "updated_at TIMESTAMPTZ NOT NULL DEFAULT now()" in result
        assert "updated_by UUID" in result
        assert "deleted_at TIMESTAMPTZ" in result
        assert "deleted_by UUID" in result

    def test_generate_base_table_with_tenant_id(self, generator, sample_entity):
        """Test multi-tenant schema includes tenant_id"""
        # Arrange
        sample_entity.schema_type = "multi_tenant"

        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "tenant_id UUID NOT NULL" in result

    def test_generate_base_table_with_business_fields(self, generator, sample_entity):
        """Test business fields correctly mapped"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "email TEXT NOT NULL" in result
        assert "company INTEGER" in result  # FK to pk_company
        assert "status TEXT" in result
        assert "CONSTRAINT chk_tb_contact_status CHECK (status IN ('lead', 'qualified'))" in result

    def test_generate_base_table_with_foreign_keys(self, generator, sample_entity):
        """Test foreign key constraints generated"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CONSTRAINT fk_contact_company FOREIGN KEY (company) REFERENCES crm.tb_company(pk_company)" in result

    def test_generate_base_table_with_indexes(self, generator, sample_entity):
        """Test indexes auto-generated for FK and enum fields"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CREATE INDEX idx_tb_contact_company ON crm.tb_contact(company)" in result
        assert "CREATE INDEX idx_tb_contact_status ON crm.tb_contact(status)" in result
        assert "CREATE INDEX idx_tb_contact_tenant_id ON crm.tb_contact(tenant_id)" in result


class TestBaseTableNaming:
    """Test naming conventions for base tables"""

    def test_table_name_convention(self, generator, sample_entity):
        """Test table name follows tb_{entity} convention"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CREATE TABLE crm.tb_contact" in result

    def test_constraint_naming_conventions(self, generator, sample_entity):
        """Test constraint names follow standards"""
        # Act
        result = generator.generate(sample_entity)

        # Assert - Primary key constraint
        assert "tb_contact_pkey" in result or "PRIMARY KEY" in result

        # Unique constraint
        assert "tb_contact_id_key UNIQUE (id)" in result

        # Foreign key constraint
        assert "fk_contact_company" in result

        # Check constraint
        assert "chk_tb_contact_status" in result


class TestEnhancedTypeSystem:
    """Test enhanced type system with subtypes (NEW!)"""

    @pytest.fixture
    def generator(self):
        return BaseTableGenerator()

    def test_integer_subtypes(self, generator):
        """Test integer subtypes map to correct PostgreSQL types"""
        entity = Entity(
            name="Product",
            schema="catalog",
            fields=[
                Field(name="id", field_type="integer"),  # â†’ BIGINT (smart default)
                Field(name="age", field_type="integer:small"),  # â†’ SMALLINT (explicit)
                Field(name="count", field_type="integer:int"),  # â†’ INTEGER (explicit)
                Field(name="big_num", field_type="integer:big"),  # â†’ BIGINT (explicit)
            ]
        )

        # Act
        result = generator.generate(entity)

        # Assert
        assert "id BIGINT" in result  # Smart default for id field
        assert "age SMALLINT" in result  # Explicit subtype
        assert "count INTEGER" in result  # Explicit subtype
        assert "big_num BIGINT" in result  # Explicit subtype

    def test_decimal_subtypes(self, generator):
        """Test decimal subtypes map to correct numeric types"""
        entity = Entity(
            name="Product",
            schema="catalog",
            fields=[
                Field(name="price", field_type="decimal:money"),  # â†’ NUMERIC(10,2)
                Field(name="latitude", field_type="decimal:geo"),  # â†’ NUMERIC(9,6)
                Field(name="tax_rate", field_type="decimal:percent"),  # â†’ NUMERIC(5,4)
                Field(name="precise", field_type="decimal:high"),  # â†’ NUMERIC(20,10)
            ]
        )

        # Act
        result = generator.generate(entity)

        # Assert
        assert "price NUMERIC(10,2)" in result
        assert "latitude NUMERIC(9,6)" in result
        assert "tax_rate NUMERIC(5,4)" in result
        assert "precise NUMERIC(20,10)" in result

    def test_text_subtypes(self, generator):
        """Test text subtypes map to correct varchar/text types"""
        entity = Entity(
            name="Contact",
            schema="crm",
            fields=[
                Field(name="email", field_type="text:short"),  # â†’ VARCHAR(255)
                Field(name="code", field_type="text:tiny"),  # â†’ VARCHAR(10)
                Field(name="description", field_type="text:long"),  # â†’ TEXT
                Field(name="name", field_type="text"),  # â†’ TEXT (default)
            ]
        )

        # Act
        result = generator.generate(entity)

        # Assert
        assert "email VARCHAR(255)" in result
        assert "code VARCHAR(10)" in result
        assert "description TEXT" in result
        assert "name TEXT" in result

    def test_context_aware_type_inference(self, generator):
        """Test type inference based on field names and patterns"""
        entity = Entity(
            name="User",
            schema="auth",
            fields=[
                # Should infer integer:big for IDs
                Field(name="user_id", field_type="integer"),  # â†’ BIGINT
                Field(name="organization_id", field_type="integer"),  # â†’ BIGINT

                # Should infer integer:small for age
                Field(name="age", field_type="integer"),  # â†’ SMALLINT

                # Should infer text:short for email/phone
                Field(name="email", field_type="text"),  # â†’ VARCHAR(255)
                Field(name="phone", field_type="text"),  # â†’ VARCHAR(50)

                # Should infer decimal:money for price/amount
                Field(name="price", field_type="decimal"),  # â†’ NUMERIC(10,2)
                Field(name="amount", field_type="decimal"),  # â†’ NUMERIC(10,2)
            ]
        )

        # Act
        result = generator.generate(entity)

        # Assert - Context-aware inference
        assert "user_id BIGINT" in result
        assert "organization_id BIGINT" in result
        assert "age SMALLINT" in result
        assert "email VARCHAR(255)" in result
        assert "phone VARCHAR(50)" in result
        assert "price NUMERIC(10,2)" in result
        assert "amount NUMERIC(10,2)" in result

    def test_backward_compatibility(self, generator):
        """Test that existing YAML without subtypes still works"""
        entity = Entity(
            name="LegacyEntity",
            schema="legacy",
            fields=[
                Field(name="name", field_type="text"),
                Field(name="count", field_type="integer"),
                Field(name="price", field_type="decimal"),
                Field(name="active", field_type="boolean"),
            ]
        )

        # Act - Should not fail
        result = generator.generate(entity)

        # Assert - Uses smart defaults
        assert "name TEXT" in result  # or VARCHAR based on inference
        assert ("count INTEGER" in result or "count BIGINT" in result)  # Context-dependent
        assert ("price NUMERIC" in result or "price NUMERIC(10,2)" in result)
        assert "active BOOLEAN" in result
```

**Run Tests (Should Fail)**:
```bash
uv run pytest tests/unit/generators/schema/test_base_table_generator.py -v

# Expected output:
# ModuleNotFoundError: No module named 'src.generators.schema.base_table_generator'
# (Tests fail - BaseTableGenerator doesn't exist yet)
```

**Commit**:
```bash
git add tests/unit/generators/schema/test_base_table_generator.py
git commit -m "test(schema): add failing tests for base table (tb_) generation - RED phase"
```

---

**Afternoon Block (4 hours): Template Implementation**

#### ðŸŸ¢ GREEN: Minimal Implementation (2.5 hours)

**Create Template**: `templates/sql/base_table.sql.j2`

```sql
{#
  Base Table (tb_) Template
  Generates normalized storage tables with full Trinity pattern

  Variables:
  - entity: Entity object
  - schema: Schema name
  - table_name: tb_{entity_name}
  - fields: List of Field objects
  - foreign_keys: List of ForeignKey objects
  - indexes: List of Index objects
#}

-- ============================================================================
-- Base Table: {{ schema }}.{{ table_name }}
-- Entity: {{ entity.name }}
-- Trinity Pattern: pk_{{ entity.name|lower }}, id, tenant_id
-- ============================================================================

CREATE TABLE {{ schema }}.{{ table_name }} (
    -- ========================================================================
    -- Trinity Pattern: INTEGER Primary Key (Performance)
    -- ========================================================================
    pk_{{ entity.name|lower }} INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,

    -- ========================================================================
    -- Trinity Pattern: UUID Identifier (Stable Public API)
    -- ========================================================================
    id UUID DEFAULT gen_random_uuid() NOT NULL,

{%- if entity.schema_type == 'multi_tenant' %}
    -- ========================================================================
    -- Trinity Pattern: Multi-Tenancy
    -- ========================================================================
    tenant_id UUID NOT NULL,

{% endif %}
    -- ========================================================================
    -- Business Fields
    -- ========================================================================
{%- for field in fields %}
    {{ field.name }} {{ field.sql_type }}{% if field.required %} NOT NULL{% endif %}{% if field.default %} DEFAULT {{ field.default }}{% endif %},
{%- endfor %}

    -- ========================================================================
    -- Trinity Pattern: Audit Trail (Full 6-field audit)
    -- ========================================================================
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    created_by UUID,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_by UUID,
    deleted_at TIMESTAMPTZ,
    deleted_by UUID,

    -- ========================================================================
    -- Constraints
    -- ========================================================================
    CONSTRAINT {{ table_name }}_id_key UNIQUE (id)
{%- for constraint in constraints %}
    ,CONSTRAINT {{ constraint.name }} {{ constraint.definition }}
{%- endfor %}
);

-- ============================================================================
-- Comments
-- ============================================================================
COMMENT ON TABLE {{ schema }}.{{ table_name }} IS '{{ entity.description }}

Trinity Pattern: Normalized base table
- pk_{{ entity.name|lower }}: INTEGER primary key for performance
- id: UUID for stable external references
- Full audit trail (created_at, updated_at, deleted_at + by fields)
{% if entity.schema_type == 'multi_tenant' %}- Multi-tenant with tenant_id{% endif %}

@fraiseql:entity
name: {{ entity.name }}
trinity: base_table';

{%- for field in fields %}
COMMENT ON COLUMN {{ schema }}.{{ table_name }}.{{ field.name }} IS '{{ field.description }}
{% if field.field_type == 'ref' %}
@fraiseql:field
name: {{ field.name }}
type: {{ field.ref_entity }}!
relation: many_to_one{% endif %}';
{%- endfor %}

-- ============================================================================
-- Indexes
-- ============================================================================

{%- if entity.schema_type == 'multi_tenant' %}
-- Multi-tenancy index
CREATE INDEX idx_{{ table_name }}_tenant_id ON {{ schema }}.{{ table_name }}(tenant_id);
{% endif %}

{%- for index in indexes %}
-- {{ index.comment }}
CREATE INDEX {{ index.name }} ON {{ schema }}.{{ table_name }}({{ index.columns|join(', ') }}){% if index.method %} USING {{ index.method }}{% endif %};
{%- endfor %}

{%- for fk in foreign_keys %}
-- Foreign key index
CREATE INDEX idx_{{ table_name }}_{{ fk.column }} ON {{ schema }}.{{ table_name }}({{ fk.column }});
{%- endfor %}
```

**Create Generator**: `src/generators/schema/base_table_generator.py`

```python
"""
Base Table (tb_) Generator

Generates normalized storage tables with complete Trinity pattern:
- pk_* INTEGER primary key
- id UUID stable identifier
- tenant_id for multi-tenant schemas
- Full 6-field audit trail
- Business fields with proper SQL types
- Foreign key constraints
- Comprehensive indexing
"""

from dataclasses import dataclass
from typing import List, Optional
from jinja2 import Environment, FileSystemLoader
from pathlib import Path

from src.core.specql_parser import Entity, Field


@dataclass
class SQLField:
    """SQL field representation"""
    name: str
    sql_type: str
    required: bool
    default: Optional[str] = None
    description: str = ""


@dataclass
class ForeignKey:
    """Foreign key constraint"""
    column: str
    ref_schema: str
    ref_table: str
    ref_column: str

    @property
    def name(self) -> str:
        """Generate FK constraint name"""
        # fk_contact_company
        return f"fk_{self.column}"


@dataclass
class Index:
    """Index definition"""
    name: str
    columns: List[str]
    method: Optional[str] = None
    comment: str = ""


@dataclass
class Constraint:
    """Check constraint"""
    name: str
    definition: str


class BaseTableGenerator:
    """Generates base tables (tb_) with Trinity pattern"""

    def __init__(self, template_dir: Path = None):
        if template_dir is None:
            template_dir = Path(__file__).parent.parent.parent.parent / "templates" / "sql"

        self.env = Environment(loader=FileSystemLoader(str(template_dir)))
        self.template = self.env.get_template("base_table.sql.j2")

    def generate(self, entity: Entity) -> str:
        """
        Generate base table SQL for entity

        Args:
            entity: Entity to generate table for

        Returns:
            SQL DDL for base table with Trinity pattern
        """
        table_name = f"tb_{entity.name.lower()}"

        # Convert SpecQL fields to SQL fields
        fields = self._convert_fields(entity.fields)

        # Generate foreign keys
        foreign_keys = self._generate_foreign_keys(entity)

        # Generate indexes
        indexes = self._generate_indexes(entity)

        # Generate constraints
        constraints = self._generate_constraints(entity)

        # Render template
        return self.template.render(
            entity=entity,
            schema=entity.schema,
            table_name=table_name,
            fields=fields,
            foreign_keys=foreign_keys,
            indexes=indexes,
            constraints=constraints
        )

    def _convert_fields(self, fields: List[Field]) -> List[SQLField]:
        """Convert SpecQL fields to SQL fields"""
        sql_fields = []

        for field in fields:
            sql_type = self._map_field_type(field)

            sql_fields.append(SQLField(
                name=field.name,
                sql_type=sql_type,
                required=field.required,
                default=field.default,
                description=field.description or ""
            ))

        return sql_fields

    def _map_field_type(self, field: Field) -> str:
        """
        Map SpecQL field type to SQL type with enhanced subtype support

        Format: type:subtype
        - integer â†’ context-aware (BIGINT for IDs, SMALLINT for age, INTEGER default)
        - integer:small â†’ SMALLINT
        - integer:int â†’ INTEGER
        - integer:big â†’ BIGINT
        - decimal â†’ context-aware (NUMERIC(10,2) for money)
        - decimal:money â†’ NUMERIC(10,2)
        - decimal:geo â†’ NUMERIC(9,6)
        - decimal:percent â†’ NUMERIC(5,4)
        - decimal:high â†’ NUMERIC(20,10)
        - text â†’ TEXT (default)
        - text:tiny â†’ VARCHAR(10)
        - text:short â†’ VARCHAR(255)
        - text:long â†’ TEXT
        """
        # Parse type:subtype format
        if ':' in field.field_type:
            base_type, subtype = field.field_type.split(':', 1)
        else:
            base_type = field.field_type
            subtype = None

        # Handle ref and enum (no subtypes)
        if base_type == "ref":
            return "INTEGER"  # Trinity: FK to pk_* INTEGER

        if base_type == "enum":
            return "TEXT"

        if base_type == "list":
            return "TEXT[]"

        # Integer subtypes
        if base_type == "integer":
            if subtype == "small":
                return "SMALLINT"
            elif subtype == "int":
                return "INTEGER"
            elif subtype == "big":
                return "BIGINT"
            else:
                # Context-aware inference
                return self._infer_integer_type(field)

        # Decimal subtypes
        if base_type == "decimal":
            if subtype == "money":
                return "NUMERIC(10,2)"
            elif subtype == "geo":
                return "NUMERIC(9,6)"
            elif subtype == "percent":
                return "NUMERIC(5,4)"
            elif subtype == "high":
                return "NUMERIC(20,10)"
            else:
                # Context-aware inference
                return self._infer_decimal_type(field)

        # Text subtypes
        if base_type == "text":
            if subtype == "tiny":
                return "VARCHAR(10)"
            elif subtype == "short":
                return "VARCHAR(255)"
            elif subtype == "long":
                return "TEXT"
            else:
                # Context-aware inference
                return self._infer_text_type(field)

        # Default mappings
        type_map = {
            "boolean": "BOOLEAN",
            "date": "DATE",
            "timestamp": "TIMESTAMPTZ",
            "json": "JSONB",
        }

        return type_map.get(base_type, "TEXT")

    def _infer_integer_type(self, field: Field) -> str:
        """Infer integer SQL type based on field name and context"""
        field_lower = field.name.lower()

        # IDs are always BIGINT for scalability
        if field_lower.endswith('_id') or field_lower == 'id':
            return "BIGINT"

        # Age fields are SMALLINT (0-255 is plenty)
        if 'age' in field_lower:
            return "SMALLINT"

        # Count, quantity usually fit in INTEGER
        if any(word in field_lower for word in ['count', 'quantity', 'number']):
            return "INTEGER"

        # Default to INTEGER for backward compatibility
        return "INTEGER"

    def _infer_decimal_type(self, field: Field) -> str:
        """Infer decimal SQL type based on field name"""
        field_lower = field.name.lower()

        # Money fields: NUMERIC(10,2)
        if any(word in field_lower for word in ['price', 'amount', 'cost', 'fee', 'salary', 'revenue']):
            return "NUMERIC(10,2)"

        # Geographic coordinates: NUMERIC(9,6)
        if any(word in field_lower for word in ['lat', 'lon', 'latitude', 'longitude', 'coord']):
            return "NUMERIC(9,6)"

        # Percentages: NUMERIC(5,4)
        if any(word in field_lower for word in ['percent', 'rate', 'ratio']):
            return "NUMERIC(5,4)"

        # Default to general NUMERIC
        return "NUMERIC"

    def _infer_text_type(self, field: Field) -> str:
        """Infer text SQL type based on field name"""
        field_lower = field.name.lower()

        # Code/slug fields are tiny
        if any(word in field_lower for word in ['code', 'slug', 'key', 'token']):
            return "VARCHAR(10)"

        # Email, phone, URL are short
        if any(word in field_lower for word in ['email', 'phone', 'url', 'link', 'username']):
            return "VARCHAR(255)"

        # Description, content, notes are long
        if any(word in field_lower for word in ['description', 'content', 'note', 'comment', 'bio']):
            return "TEXT"

        # Default to TEXT for flexibility
        return "TEXT"

    def _generate_foreign_keys(self, entity: Entity) -> List[ForeignKey]:
        """Generate foreign key constraints for ref fields"""
        fks = []

        for field in entity.fields:
            if field.field_type == "ref" and field.ref_entity:
                ref_entity_lower = field.ref_entity.lower()

                fks.append(ForeignKey(
                    column=field.name,
                    ref_schema=entity.schema,
                    ref_table=f"tb_{ref_entity_lower}",
                    ref_column=f"pk_{ref_entity_lower}"
                ))

        return fks

    def _generate_indexes(self, entity: Entity) -> List[Index]:
        """Generate indexes for enum fields and other indexed columns"""
        indexes = []

        for field in entity.fields:
            # Index enum fields for query performance
            if field.field_type == "enum":
                indexes.append(Index(
                    name=f"idx_tb_{entity.name.lower()}_{field.name}",
                    columns=[field.name],
                    comment=f"Index on enum field {field.name}"
                ))

        return indexes

    def _generate_constraints(self, entity: Entity) -> List[Constraint]:
        """Generate check constraints for enum fields"""
        constraints = []

        for field in entity.fields:
            if field.field_type == "enum" and field.enum_values:
                enum_list = ", ".join(f"'{v}'" for v in field.enum_values)

                constraints.append(Constraint(
                    name=f"chk_tb_{entity.name.lower()}_{field.name}",
                    definition=f"CHECK ({field.name} IN ({enum_list}))"
                ))

        return constraints
```

**Run Tests (Should Pass)**:
```bash
uv run pytest tests/unit/generators/schema/test_base_table_generator.py -v

# Expected output:
# tests/unit/generators/schema/test_base_table_generator.py::TestBaseTableGeneration::test_generate_base_table_with_trinity_pattern PASSED
# tests/unit/generators/schema/test_base_table_generator.py::TestBaseTableGeneration::test_generate_base_table_with_audit_fields PASSED
# ... (all tests pass)
```

**Commit**:
```bash
git add src/generators/schema/base_table_generator.py templates/sql/base_table.sql.j2
git commit -m "feat(schema): implement base table (tb_) generator with Trinity pattern - GREEN phase"
```

---

#### ðŸ”§ REFACTOR: Clean Up & Integrate (1.5 hours)

**1. Integrate with Schema Orchestrator** (45 min)

**Update**: `src/generators/schema/schema_orchestrator.py`

```python
from src.generators.schema.base_table_generator import BaseTableGenerator
from src.generators.schema.table_view_generator import TableViewGenerator

class SchemaOrchestrator:
    """Orchestrates full schema generation with both tb_ and tv_ tables"""

    def __init__(self):
        self.base_table_gen = BaseTableGenerator()
        self.table_view_gen = TableViewGenerator()
        # ... other generators

    def generate_schema(self, entities: List[Entity]) -> List[FileSpec]:
        """Generate complete schema with base tables and table views"""
        files = []

        for entity in entities:
            # Generate base table (tb_)
            base_table_sql = self.base_table_gen.generate(entity)
            files.append(FileSpec(
                code=self._generate_code(entity, "base_table"),
                name=f"tb_{entity.name.lower()}",
                content=base_table_sql,
                layer="write_side"
            ))

            # Generate table view (tv_)
            table_view_sql = self.table_view_gen.generate(entity)
            files.append(FileSpec(
                code=self._generate_code(entity, "table_view"),
                name=f"tv_{entity.name.lower()}",
                content=table_view_sql,
                layer="read_side"
            ))

        return files
```

**2. Add Integration Test** (45 min)

**Test File**: `tests/integration/test_complete_trinity_generation.py`

```python
"""Integration test for complete Trinity pattern generation"""

import pytest
from src.generators.schema.schema_orchestrator import SchemaOrchestrator
from src.core.specql_parser import SpecQLParser

def test_complete_trinity_generation():
    """Test that both tb_ and tv_ tables are generated"""
    # Arrange
    yaml_content = """
entity: Contact
schema: crm
schema_type: multi_tenant
description: "Customer contact information"
fields:
  email: text!
  company: ref(Company)
  status: enum(lead, qualified, customer)
organization:
  domain: customer
  subdomain: contacts
  table_code: "012361"
"""
    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    orchestrator = SchemaOrchestrator()

    # Act
    files = orchestrator.generate_schema([entity])

    # Assert
    assert len(files) == 2

    # Check base table generated
    base_table = next(f for f in files if f.name == "tb_contact")
    assert "CREATE TABLE crm.tb_contact" in base_table.content
    assert "pk_contact INTEGER" in base_table.content
    assert "tenant_id UUID NOT NULL" in base_table.content

    # Check table view generated
    table_view = next(f for f in files if f.name == "tv_contact")
    assert "CREATE TABLE crm.tv_contact" in table_view.content
    assert "data JSONB NOT NULL" in table_view.content
```

**Run Integration Test**:
```bash
uv run pytest tests/integration/test_complete_trinity_generation.py -v
```

**Commit**:
```bash
git add src/generators/schema/schema_orchestrator.py tests/integration/
git commit -m "refactor(schema): integrate base table generation into orchestrator - REFACTOR phase"
```

---

#### âœ… QA: Quality Verification (remaining time)

**Run Full Test Suite**:
```bash
# Unit tests
uv run pytest tests/unit/generators/schema/ -v

# Integration tests
uv run pytest tests/integration/ -v

# Full suite
uv run pytest --tb=short

# Type checking
uv run mypy src/generators/schema/base_table_generator.py

# Linting
uv run ruff check src/generators/schema/base_table_generator.py
```

**Quality Gates**:
- [ ] All tests passing
- [ ] Type hints correct
- [ ] Linting clean
- [ ] Template rendering correct
- [ ] Integration working

**Day 1 Summary**:
- âœ… Base table generator implemented with Trinity pattern
- âœ… **Enhanced type system** with subtype support (integer:big, decimal:money, text:short)
- âœ… **Context-aware type inference** engine for smart defaults
- âœ… **Backward compatibility** maintained with existing YAML
- âœ… Jinja2 template created for tb_ tables
- âœ… Full audit fields (6-field audit trail)
- âœ… Foreign key constraints generated
- âœ… Indexes auto-created
- âœ… Integrated with orchestrator
- âœ… Complete test coverage including type system tests

---

### Day 2: Table View Generator Enhancement

**Morning Block (4 hours): Enhanced tv_ Generation**

#### ðŸ”´ RED: Table View Tests (2 hours)

**Test File**: `tests/unit/generators/schema/test_table_view_generator_enhanced.py`

```python
"""Tests for enhanced table view (tv_) generation"""

import pytest
from src.generators.schema.table_view_generator import TableViewGenerator
from src.core.specql_parser import Entity, Field


class TestTableViewGeneration:
    """Test enhanced tv_ table generation"""

    @pytest.fixture
    def generator(self):
        return TableViewGenerator()

    @pytest.fixture
    def sample_entity(self):
        return Entity(
            name="Contact",
            schema="crm",
            fields=[
                Field(name="email", field_type="text"),
                Field(name="status", field_type="enum", enum_values=["lead", "qualified"]),
            ]
        )

    def test_table_view_structure(self, generator, sample_entity):
        """Test table view has correct JSONB structure"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CREATE TABLE crm.tv_contact" in result
        assert "pk_contact INTEGER PRIMARY KEY" in result
        assert "id UUID NOT NULL UNIQUE" in result
        assert "tenant_id UUID NOT NULL" in result
        assert "data JSONB NOT NULL" in result
        assert "refreshed_at TIMESTAMPTZ DEFAULT now()" in result

    def test_table_view_foreign_key_to_base(self, generator, sample_entity):
        """Test tv_ has FK to tb_ for data integrity"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "FOREIGN KEY (pk_contact) REFERENCES crm.tb_contact(pk_contact)" in result

    def test_table_view_refresh_function(self, generator, sample_entity):
        """Test refresh function generated for syncing tb_ -> tv_"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CREATE OR REPLACE FUNCTION crm.refresh_tv_contact()" in result
        assert "INSERT INTO crm.tv_contact" in result
        assert "SELECT pk_contact, id, tenant_id" in result
        assert "jsonb_build_object" in result
        assert "ON CONFLICT (pk_contact) DO UPDATE" in result

    def test_table_view_trigger(self, generator, sample_entity):
        """Test trigger keeps tv_ in sync with tb_"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CREATE TRIGGER trg_refresh_tv_contact" in result
        assert "AFTER INSERT OR UPDATE ON crm.tb_contact" in result
        assert "EXECUTE FUNCTION crm.refresh_tv_contact()" in result
```

**Run Tests (Should Fail)**:
```bash
uv run pytest tests/unit/generators/schema/test_table_view_generator_enhanced.py -v
```

---

#### ðŸŸ¢ GREEN: Implement Enhanced Table Views (2 hours)

**Create Template**: `templates/sql/table_view.sql.j2`

```sql
-- ============================================================================
-- Table View: {{ schema }}.{{ table_name }}
-- Entity: {{ entity.name }}
-- Purpose: Denormalized JSONB view for GraphQL queries
-- ============================================================================

CREATE TABLE {{ schema }}.{{ table_name }} (
    -- Trinity pattern primary keys (mirrors base table)
    pk_{{ entity.name|lower }} INTEGER PRIMARY KEY,
    id UUID NOT NULL UNIQUE,
{%- if entity.schema_type == 'multi_tenant' %}
    tenant_id UUID NOT NULL,
{% endif %}

    -- Denormalized JSONB data
    data JSONB NOT NULL,

    -- Refresh timestamp
    refreshed_at TIMESTAMPTZ DEFAULT now(),

    -- Foreign key to base table
    CONSTRAINT fk_{{ table_name }}_base FOREIGN KEY (pk_{{ entity.name|lower }})
        REFERENCES {{ schema }}.tb_{{ entity.name|lower }}(pk_{{ entity.name|lower }})
        ON DELETE CASCADE
);

-- ============================================================================
-- Indexes
-- ============================================================================

-- GIN index for JSONB queries
CREATE INDEX idx_{{ table_name }}_data ON {{ schema }}.{{ table_name }} USING gin (data);

{%- if entity.schema_type == 'multi_tenant' %}
-- Multi-tenancy index
CREATE INDEX idx_{{ table_name }}_tenant_id ON {{ schema }}.{{ table_name }}(tenant_id);
{% endif %}

-- ============================================================================
-- Refresh Function: Sync tb_ -> tv_
-- ============================================================================

CREATE OR REPLACE FUNCTION {{ schema }}.refresh_{{ table_name }}()
RETURNS TRIGGER AS $$
BEGIN
    INSERT INTO {{ schema }}.{{ table_name }} (
        pk_{{ entity.name|lower }},
        id,
{%- if entity.schema_type == 'multi_tenant' %}
        tenant_id,
{% endif %}
        data,
        refreshed_at
    )
    SELECT
        NEW.pk_{{ entity.name|lower }},
        NEW.id,
{%- if entity.schema_type == 'multi_tenant' %}
        NEW.tenant_id,
{% endif %}
        jsonb_build_object(
{%- for field in entity.fields %}
            '{{ field.name }}', NEW.{{ field.name }}{% if not loop.last %},{% endif %}
{%- endfor %}
        ),
        now()
    ON CONFLICT (pk_{{ entity.name|lower }})
    DO UPDATE SET
        data = EXCLUDED.data,
        refreshed_at = now();

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- ============================================================================
-- Trigger: Auto-refresh on tb_ changes
-- ============================================================================

CREATE TRIGGER trg_refresh_{{ table_name }}
    AFTER INSERT OR UPDATE ON {{ schema }}.tb_{{ entity.name|lower }}
    FOR EACH ROW
    EXECUTE FUNCTION {{ schema }}.refresh_{{ table_name }}();

-- ============================================================================
-- Comments
-- ============================================================================

COMMENT ON TABLE {{ schema }}.{{ table_name }} IS '{{ entity.description }}

Table View: Denormalized JSONB for GraphQL
- Synced automatically from tb_{{ entity.name|lower }} via trigger
- data: Complete entity as JSONB for flexible querying
- refreshed_at: Last sync timestamp

@fraiseql:type
name: {{ entity.name }}
trinity: table_view
query: true';
```

**Update Generator**: `src/generators/schema/table_view_generator.py`

```python
"""Enhanced table view (tv_) generator with automatic syncing"""

from jinja2 import Environment, FileSystemLoader
from pathlib import Path
from src.core.specql_parser import Entity


class TableViewGenerator:
    """Generates table views (tv_) with JSONB and auto-refresh"""

    def __init__(self, template_dir: Path = None):
        if template_dir is None:
            template_dir = Path(__file__).parent.parent.parent.parent / "templates" / "sql"

        self.env = Environment(loader=FileSystemLoader(str(template_dir)))
        self.template = self.env.get_template("table_view.sql.j2")

    def generate(self, entity: Entity) -> str:
        """
        Generate table view SQL with JSONB and auto-sync

        Args:
            entity: Entity to generate view for

        Returns:
            SQL DDL for table view with refresh function and trigger
        """
        table_name = f"tv_{entity.name.lower()}"

        return self.template.render(
            entity=entity,
            schema=entity.schema,
            table_name=table_name
        )
```

**Run Tests (Should Pass)**:
```bash
uv run pytest tests/unit/generators/schema/test_table_view_generator_enhanced.py -v
```

**Commit**:
```bash
git add src/generators/schema/table_view_generator.py templates/sql/table_view.sql.j2
git commit -m "feat(schema): implement enhanced table views with auto-refresh - GREEN phase"
```

---

**Afternoon Block (4 hours): Trinity Helper Functions**

#### ðŸ”´ RED: Helper Function Tests (1.5 hours)

**Test File**: `tests/unit/generators/schema/test_trinity_helper_generator.py`

```python
"""Tests for Trinity helper function generation"""

import pytest
from src.generators.schema.trinity_helper_generator import TrinityHelperGenerator
from src.core.specql_parser import Entity


class TestTrinityHelperFunctions:
    """Test Trinity pattern helper functions"""

    @pytest.fixture
    def generator(self):
        return TrinityHelperGenerator()

    @pytest.fixture
    def sample_entity(self):
        return Entity(name="Contact", schema="crm")

    def test_generate_pk_function(self, generator, sample_entity):
        """Test {entity}_pk() function for UUID/TEXT -> INTEGER"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CREATE OR REPLACE FUNCTION crm.contact_pk(p_identifier TEXT)" in result
        assert "RETURNS INTEGER" in result
        assert "SELECT pk_contact FROM crm.tb_contact" in result
        assert "WHERE (id::TEXT = p_identifier OR pk_contact::TEXT = p_identifier)" in result

    def test_generate_id_function(self, generator, sample_entity):
        """Test {entity}_id() function for INTEGER -> UUID"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "CREATE OR REPLACE FUNCTION crm.contact_id(p_pk INTEGER)" in result
        assert "RETURNS UUID" in result
        assert "SELECT id FROM crm.tb_contact WHERE pk_contact = p_pk" in result

    def test_helper_functions_marked_stable(self, generator, sample_entity):
        """Test helper functions marked as STABLE for performance"""
        # Act
        result = generator.generate(sample_entity)

        # Assert
        assert "LANGUAGE sql STABLE" in result
```

**Run Tests (Should Fail)**:
```bash
uv run pytest tests/unit/generators/schema/test_trinity_helper_generator.py -v
```

---

#### ðŸŸ¢ GREEN: Implement Helper Functions (1.5 hours)

**Template**: `templates/sql/trinity_helpers.sql.j2`

```sql
-- ============================================================================
-- Trinity Helper Functions: {{ entity.name }}
-- Purpose: UUID â†” INTEGER conversion utilities
-- ============================================================================

-- ----------------------------------------------------------------------------
-- Function: {{ entity.name|lower }}_pk
-- Purpose: Convert UUID or TEXT identifier to INTEGER primary key
-- Usage: SELECT contact_pk('550e8400-e29b-41d4-a716-446655440000')
-- ----------------------------------------------------------------------------

CREATE OR REPLACE FUNCTION {{ schema }}.{{ entity.name|lower }}_pk(p_identifier TEXT)
RETURNS INTEGER AS $$
    SELECT pk_{{ entity.name|lower }}
    FROM {{ schema }}.tb_{{ entity.name|lower }}
    WHERE (
        id::TEXT = p_identifier
        OR pk_{{ entity.name|lower }}::TEXT = p_identifier
    )
    LIMIT 1;
$$ LANGUAGE sql STABLE;

COMMENT ON FUNCTION {{ schema }}.{{ entity.name|lower }}_pk(TEXT) IS
'Convert {{ entity.name }} UUID or INTEGER (as TEXT) to INTEGER primary key.

Trinity Pattern Helper: Resolves external identifiers to internal pk_{{ entity.name|lower }}.

@fraiseql:helper
entity: {{ entity.name }}
converts: UUID|INTEGER -> INTEGER';

-- ----------------------------------------------------------------------------
-- Function: {{ entity.name|lower }}_id
-- Purpose: Convert INTEGER primary key to UUID
-- Usage: SELECT contact_id(42)
-- ----------------------------------------------------------------------------

CREATE OR REPLACE FUNCTION {{ schema }}.{{ entity.name|lower }}_id(p_pk INTEGER)
RETURNS UUID AS $$
    SELECT id
    FROM {{ schema }}.tb_{{ entity.name|lower }}
    WHERE pk_{{ entity.name|lower }} = p_pk;
$$ LANGUAGE sql STABLE;

COMMENT ON FUNCTION {{ schema }}.{{ entity.name|lower }}_id(INTEGER) IS
'Convert {{ entity.name }} INTEGER primary key to UUID.

Trinity Pattern Helper: Resolves internal pk_{{ entity.name|lower }} to external UUID.

@fraiseql:helper
entity: {{ entity.name }}
converts: INTEGER -> UUID';
```

**Generator**: Update `src/generators/schema/trinity_helper_generator.py`

```python
"""Trinity helper function generator"""

from jinja2 import Environment, FileSystemLoader
from pathlib import Path
from src.core.specql_parser import Entity


class TrinityHelperGenerator:
    """Generates Trinity pattern helper functions for UUID â†” INTEGER conversion"""

    def __init__(self, template_dir: Path = None):
        if template_dir is None:
            template_dir = Path(__file__).parent.parent.parent.parent / "templates" / "sql"

        self.env = Environment(loader=FileSystemLoader(str(template_dir)))
        self.template = self.env.get_template("trinity_helpers.sql.j2")

    def generate(self, entity: Entity) -> str:
        """
        Generate Trinity helper functions for entity

        Args:
            entity: Entity to generate helpers for

        Returns:
            SQL with {entity}_pk() and {entity}_id() functions
        """
        return self.template.render(
            entity=entity,
            schema=entity.schema
        )
```

**Run Tests (Should Pass)**:
```bash
uv run pytest tests/unit/generators/schema/test_trinity_helper_generator.py -v
```

**Commit**:
```bash
git add src/generators/schema/trinity_helper_generator.py templates/sql/trinity_helpers.sql.j2
git commit -m "feat(schema): implement Trinity helper functions for UUID/INTEGER conversion - GREEN phase"
```

---

#### ðŸ”§ REFACTOR: Integrate All Generators (1 hour)

**Update Orchestrator**:

```python
class SchemaOrchestrator:
    def __init__(self):
        self.base_table_gen = BaseTableGenerator()
        self.table_view_gen = TableViewGenerator()
        self.trinity_helper_gen = TrinityHelperGenerator()

    def generate_schema(self, entities: List[Entity]) -> List[FileSpec]:
        files = []

        for entity in entities:
            # 1. Base table
            files.append(self._generate_base_table(entity))

            # 2. Table view with refresh function
            files.append(self._generate_table_view(entity))

            # 3. Trinity helper functions
            files.append(self._generate_helpers(entity))

        return files
```

**Commit**:
```bash
git add src/generators/schema/schema_orchestrator.py
git commit -m "refactor(schema): integrate Trinity helpers into orchestrator - REFACTOR phase"
```

---

**Day 2 Summary**:
- âœ… Enhanced table view generation with JSONB
- âœ… Auto-refresh functions and triggers
- âœ… Trinity helper functions ({entity}_pk, {entity}_id)
- âœ… Complete UUID â†” INTEGER conversion
- âœ… All generators integrated

---

### Day 3: Advanced PostgreSQL Features - Vector Embeddings

**Objective**: Auto-generate vector embedding columns and HNSW indexes for semantic search

**Morning Block (4 hours): Vector Column Generation**

#### ðŸ”´ RED: Vector Tests (2 hours)

**Test File**: `tests/unit/generators/schema/test_vector_generator.py`

```python
"""Tests for vector embedding generation"""

import pytest
from src.generators.schema.vector_generator import VectorGenerator
from src.core.specql_parser import Entity


class TestVectorGeneration:
    """Test vector embedding column and index generation"""

    @pytest.fixture
    def generator(self):
        return VectorGenerator()

    @pytest.fixture
    def entity_with_vector(self):
        return Entity(
            name="Pattern",
            schema="specql_registry",
            fields=[],
            features=["semantic_search"]  # Enable vector embeddings
        )

    def test_add_embedding_column(self, generator, entity_with_vector):
        """Test embedding vector(384) column added"""
        # Act
        result = generator.generate_column(entity_with_vector)

        # Assert
        assert "ALTER TABLE specql_registry.tb_pattern ADD COLUMN embedding vector(384)" in result

    def test_hnsw_index_generation(self, generator, entity_with_vector):
        """Test HNSW index created for vector similarity search"""
        # Act
        result = generator.generate_index(entity_with_vector)

        # Assert
        assert "CREATE INDEX idx_tb_pattern_embedding_hnsw" in result
        assert "ON specql_registry.tb_pattern USING hnsw (embedding vector_cosine_ops)" in result
        assert "WITH (m = 16, ef_construction = 64)" in result

    def test_table_view_embedding_included(self, generator, entity_with_vector):
        """Test tv_ table also gets embedding column"""
        # Act
        result = generator.generate_tv_column(entity_with_vector)

        # Assert
        assert "ALTER TABLE specql_registry.tv_pattern ADD COLUMN embedding vector(384)" in result

    def test_similarity_search_function(self, generator, entity_with_vector):
        """Test similarity search helper function generated"""
        # Act
        result = generator.generate_search_function(entity_with_vector)

        # Assert
        assert "CREATE OR REPLACE FUNCTION specql_registry.search_pattern_by_embedding" in result
        assert "p_query_embedding vector(384)" in result
        assert "ORDER BY embedding <=> p_query_embedding" in result
        assert "LIMIT p_limit" in result
```

**Run Tests (Should Fail)**:
```bash
uv run pytest tests/unit/generators/schema/test_vector_generator.py -v
```

**Commit**:
```bash
git add tests/unit/generators/schema/test_vector_generator.py
git commit -m "test(schema): add failing tests for vector embedding generation - RED phase"
```

---

#### ðŸŸ¢ GREEN: Implement Vector Generator (2 hours)

**Template**: `templates/sql/vector_features.sql.j2`

```sql
-- ============================================================================
-- Vector Embeddings: {{ entity.name }}
-- Purpose: Semantic search with pgvector
-- ============================================================================

-- Add embedding column to base table
ALTER TABLE {{ schema }}.tb_{{ entity.name|lower }}
ADD COLUMN embedding vector(384);

-- Add embedding column to table view
ALTER TABLE {{ schema }}.tv_{{ entity.name|lower }}
ADD COLUMN embedding vector(384);

-- ============================================================================
-- HNSW Index for Fast Similarity Search
-- ============================================================================

CREATE INDEX idx_tb_{{ entity.name|lower }}_embedding_hnsw
ON {{ schema }}.tb_{{ entity.name|lower }}
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

COMMENT ON INDEX {{ schema }}.idx_tb_{{ entity.name|lower }}_embedding_hnsw IS
'HNSW index for fast vector similarity search on {{ entity.name }}.
- m = 16: Number of connections per layer
- ef_construction = 64: Quality of index construction
- Operator: <=> (cosine distance)';

-- ============================================================================
-- Similarity Search Function
-- ============================================================================

CREATE OR REPLACE FUNCTION {{ schema }}.search_{{ entity.name|lower }}_by_embedding(
    p_query_embedding vector(384),
    p_limit INTEGER DEFAULT 10,
    p_min_similarity FLOAT DEFAULT 0.0
)
RETURNS TABLE (
    pk INTEGER,
    id UUID,
    similarity FLOAT,
    data JSONB
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        tv.pk_{{ entity.name|lower }},
        tv.id,
        1 - (tv.embedding <=> p_query_embedding) AS similarity,
        tv.data
    FROM {{ schema }}.tv_{{ entity.name|lower }} tv
    WHERE tv.embedding IS NOT NULL
        AND (1 - (tv.embedding <=> p_query_embedding)) >= p_min_similarity
    ORDER BY tv.embedding <=> p_query_embedding
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql STABLE;

COMMENT ON FUNCTION {{ schema }}.search_{{ entity.name|lower }}_by_embedding IS
'Semantic similarity search for {{ entity.name }} using vector embeddings.

Args:
- p_query_embedding: Query vector (384 dimensions)
- p_limit: Maximum results to return
- p_min_similarity: Minimum similarity threshold (0.0 - 1.0)

Returns:
- Matching entities with similarity scores, ordered by relevance

@fraiseql:query
name: search{{ entity.name }}ByEmbedding
type: [{{ entity.name }}!]!
args:
  - queryEmbedding: [Float!]!
  - limit: Int
  - minSimilarity: Float';
```

**Generator**: `src/generators/schema/vector_generator.py`

```python
"""Vector embedding generator for semantic search"""

from jinja2 import Environment, FileSystemLoader
from pathlib import Path
from src.core.specql_parser import Entity


class VectorGenerator:
    """Generates vector embedding columns and similarity search functions"""

    def __init__(self, template_dir: Path = None):
        if template_dir is None:
            template_dir = Path(__file__).parent.parent.parent.parent / "templates" / "sql"

        self.env = Environment(loader=FileSystemLoader(str(template_dir)))
        self.template = self.env.get_template("vector_features.sql.j2")

    def generate(self, entity: Entity) -> str:
        """
        Generate vector features if entity has semantic_search enabled

        Args:
            entity: Entity to generate vector features for

        Returns:
            SQL for vector columns, indexes, and search functions
        """
        if "semantic_search" not in entity.features:
            return ""

        return self.template.render(
            entity=entity,
            schema=entity.schema
        )

    def generate_column(self, entity: Entity) -> str:
        """Generate ALTER TABLE to add embedding column"""
        return f"ALTER TABLE {entity.schema}.tb_{entity.name.lower()} ADD COLUMN embedding vector(384);"

    def generate_index(self, entity: Entity) -> str:
        """Generate HNSW index for vector similarity"""
        return f"""CREATE INDEX idx_tb_{entity.name.lower()}_embedding_hnsw
ON {entity.schema}.tb_{entity.name.lower()}
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);"""

    def generate_tv_column(self, entity: Entity) -> str:
        """Generate ALTER TABLE for table view embedding"""
        return f"ALTER TABLE {entity.schema}.tv_{entity.name.lower()} ADD COLUMN embedding vector(384);"

    def generate_search_function(self, entity: Entity) -> str:
        """Generate similarity search function"""
        return self.template.render(entity=entity, schema=entity.schema)
```

**Run Tests (Should Pass)**:
```bash
uv run pytest tests/unit/generators/schema/test_vector_generator.py -v
```

**Commit**:
```bash
git add src/generators/schema/vector_generator.py templates/sql/vector_features.sql.j2
git commit -m "feat(schema): implement vector embedding generation with HNSW indexes - GREEN phase"
```

---

**Afternoon Block (4 hours): Full-Text Search**

#### ðŸ”´ RED: Full-Text Search Tests (1.5 hours)

**Test File**: `tests/unit/generators/schema/test_fulltext_generator.py`

```python
"""Tests for full-text search generation"""

import pytest
from src.generators.schema.fulltext_generator import FullTextGenerator
from src.core.specql_parser import Entity, Field


class TestFullTextSearch:
    """Test full-text search column and index generation"""

    @pytest.fixture
    def generator(self):
        return FullTextGenerator()

    @pytest.fixture
    def entity_with_text_fields(self):
        return Entity(
            name="Pattern",
            schema="specql_registry",
            fields=[
                Field(name="pattern_name", field_type="text"),
                Field(name="description", field_type="text"),
                Field(name="category", field_type="text"),
            ],
            features=["full_text_search"]
        )

    def test_add_search_vector_column(self, generator, entity_with_text_fields):
        """Test tsvector column added with GENERATED ALWAYS"""
        # Act
        result = generator.generate_column(entity_with_text_fields)

        # Assert
        assert "ALTER TABLE specql_registry.tb_pattern" in result
        assert "ADD COLUMN search_vector tsvector" in result
        assert "GENERATED ALWAYS AS" in result
        assert "to_tsvector('english'" in result
        assert "pattern_name" in result
        assert "description" in result
        assert "STORED" in result

    def test_gin_index_generation(self, generator, entity_with_text_fields):
        """Test GIN index created for full-text search"""
        # Act
        result = generator.generate_index(entity_with_text_fields)

        # Assert
        assert "CREATE INDEX idx_tb_pattern_search" in result
        assert "ON specql_registry.tb_pattern USING gin (search_vector)" in result

    def test_search_function_generation(self, generator, entity_with_text_fields):
        """Test full-text search function"""
        # Act
        result = generator.generate_search_function(entity_with_text_fields)

        # Assert
        assert "CREATE OR REPLACE FUNCTION specql_registry.search_pattern_by_text" in result
        assert "p_query TEXT" in result
        assert "WHERE search_vector @@ websearch_to_tsquery('english', p_query)" in result
        assert "ts_rank(search_vector" in result
```

**Run Tests (Should Fail)**:
```bash
uv run pytest tests/unit/generators/schema/test_fulltext_generator.py -v
```

---

#### ðŸŸ¢ GREEN: Implement Full-Text Search (1.5 hours)

**Template**: `templates/sql/fulltext_features.sql.j2`

```sql
-- ============================================================================
-- Full-Text Search: {{ entity.name }}
-- Purpose: Fast text search with PostgreSQL tsvector
-- ============================================================================

-- Add generated tsvector column
ALTER TABLE {{ schema }}.tb_{{ entity.name|lower }}
ADD COLUMN search_vector tsvector
GENERATED ALWAYS AS (
    to_tsvector('english',
{%- for field in text_fields %}
        coalesce({{ field.name }}, ''){% if not loop.last %} || ' ' ||{% endif %}
{%- endfor %}
    )
) STORED;

COMMENT ON COLUMN {{ schema }}.tb_{{ entity.name|lower }}.search_vector IS
'Full-text search vector (auto-generated).
Combines: {{ text_fields|map(attribute='name')|join(', ') }}';

-- ============================================================================
-- GIN Index for Full-Text Search
-- ============================================================================

CREATE INDEX idx_tb_{{ entity.name|lower }}_search
ON {{ schema }}.tb_{{ entity.name|lower }}
USING gin (search_vector);

-- ============================================================================
-- Full-Text Search Function
-- ============================================================================

CREATE OR REPLACE FUNCTION {{ schema }}.search_{{ entity.name|lower }}_by_text(
    p_query TEXT,
    p_limit INTEGER DEFAULT 20
)
RETURNS TABLE (
    pk INTEGER,
    id UUID,
    rank FLOAT,
    data JSONB
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        tv.pk_{{ entity.name|lower }},
        tv.id,
        ts_rank(tb.search_vector, websearch_to_tsquery('english', p_query)) AS rank,
        tv.data
    FROM {{ schema }}.tv_{{ entity.name|lower }} tv
    JOIN {{ schema }}.tb_{{ entity.name|lower }} tb USING (pk_{{ entity.name|lower }})
    WHERE tb.search_vector @@ websearch_to_tsquery('english', p_query)
    ORDER BY rank DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql STABLE;

COMMENT ON FUNCTION {{ schema }}.search_{{ entity.name|lower }}_by_text IS
'Full-text search for {{ entity.name }} using PostgreSQL tsvector.

Args:
- p_query: Search query (websearch syntax supported)
- p_limit: Maximum results

Returns:
- Matching entities with relevance rank

@fraiseql:query
name: search{{ entity.name }}ByText
type: [{{ entity.name }}!]!
args:
  - query: String!
  - limit: Int';
```

**Generator**: `src/generators/schema/fulltext_generator.py`

```python
"""Full-text search generator"""

from jinja2 import Environment, FileSystemLoader
from pathlib import Path
from typing import List
from src.core.specql_parser import Entity, Field


class FullTextGenerator:
    """Generates full-text search columns and functions"""

    def __init__(self, template_dir: Path = None):
        if template_dir is None:
            template_dir = Path(__file__).parent.parent.parent.parent / "templates" / "sql"

        self.env = Environment(loader=FileSystemLoader(str(template_dir)))
        self.template = self.env.get_template("fulltext_features.sql.j2")

    def generate(self, entity: Entity) -> str:
        """Generate full-text search features if enabled"""
        if "full_text_search" not in entity.features:
            return ""

        # Get text fields for indexing
        text_fields = [f for f in entity.fields if f.field_type == "text"]

        if not text_fields:
            return ""

        return self.template.render(
            entity=entity,
            schema=entity.schema,
            text_fields=text_fields
        )

    def generate_column(self, entity: Entity) -> str:
        """Generate tsvector column"""
        text_fields = [f for f in entity.fields if f.field_type == "text"]
        field_concat = " || ' ' || ".join(f"coalesce({f.name}, '')" for f in text_fields)

        return f"""ALTER TABLE {entity.schema}.tb_{entity.name.lower()}
ADD COLUMN search_vector tsvector
GENERATED ALWAYS AS (
    to_tsvector('english', {field_concat})
) STORED;"""

    def generate_index(self, entity: Entity) -> str:
        """Generate GIN index"""
        return f"""CREATE INDEX idx_tb_{entity.name.lower()}_search
ON {entity.schema}.tb_{entity.name.lower()} USING gin (search_vector);"""

    def generate_search_function(self, entity: Entity) -> str:
        """Generate search function"""
        return self.generate(entity)
```

**Run Tests (Should Pass)**:
```bash
uv run pytest tests/unit/generators/schema/test_fulltext_generator.py -v
```

**Commit**:
```bash
git add src/generators/schema/fulltext_generator.py templates/sql/fulltext_features.sql.j2
git commit -m "feat(schema): implement full-text search with GIN indexes - GREEN phase"
```

---

#### ðŸ”§ REFACTOR + âœ… QA (1 hour)

**Integrate Advanced Features**:

```python
class SchemaOrchestrator:
    def __init__(self):
        self.base_table_gen = BaseTableGenerator()
        self.table_view_gen = TableViewGenerator()
        self.trinity_helper_gen = TrinityHelperGenerator()
        self.vector_gen = VectorGenerator()
        self.fulltext_gen = FullTextGenerator()

    def generate_schema(self, entities: List[Entity]) -> List[FileSpec]:
        files = []

        for entity in entities:
            # Core Trinity tables
            files.append(self._generate_base_table(entity))
            files.append(self._generate_table_view(entity))
            files.append(self._generate_helpers(entity))

            # Advanced features (if enabled)
            if "semantic_search" in entity.features:
                files.append(self._generate_vector_features(entity))

            if "full_text_search" in entity.features:
                files.append(self._generate_fulltext_features(entity))

        return files
```

**Run Full Test Suite**:
```bash
uv run pytest --tb=short
uv run mypy src/generators/schema/
uv run ruff check
```

**Day 3 Summary**:
- âœ… Vector embeddings with HNSW indexes
- âœ… Full-text search with GIN indexes
- âœ… Similarity search functions
- âœ… Text search functions
- âœ… All advanced features integrated

---

### Day 4: FraiseQL Integration & Annotations

**Objective**: Add complete FraiseQL annotations to all generated database objects

**Morning Block (4 hours): FraiseQL Comment Generator**

#### ðŸ”´ RED: FraiseQL Tests (2 hours)

**Test File**: `tests/unit/generators/fraiseql/test_fraiseql_annotator.py`

```python
"""Tests for FraiseQL annotation generation"""

import pytest
from src.generators.fraiseql.fraiseql_annotator import FraiseQLAnnotator
from src.core.specql_parser import Entity, Field


class TestFraiseQLAnnotations:
    """Test FraiseQL metadata annotation generation"""

    @pytest.fixture
    def annotator(self):
        return FraiseQLAnnotator()

    @pytest.fixture
    def sample_entity(self):
        return Entity(
            name="Contact",
            schema="crm",
            description="Customer contact information",
            fields=[
                Field(name="email", field_type="text", description="Email address"),
                Field(name="company", field_type="ref", ref_entity="Company"),
            ]
        )

    def test_table_annotation(self, annotator, sample_entity):
        """Test base table gets FraiseQL annotation"""
        # Act
        result = annotator.annotate_table(sample_entity)

        # Assert
        assert "@fraiseql:entity" in result
        assert "name: Contact" in result
        assert "trinity: base_table" in result

    def test_table_view_annotation(self, annotator, sample_entity):
        """Test table view gets FraiseQL annotation"""
        # Act
        result = annotator.annotate_table_view(sample_entity)

        # Assert
        assert "@fraiseql:type" in result
        assert "name: Contact" in result
        assert "trinity: table_view" in result
        assert "query: true" in result

    def test_field_annotations(self, annotator, sample_entity):
        """Test field comments include FraiseQL metadata"""
        # Act
        result = annotator.annotate_fields(sample_entity)

        # Assert
        assert "@fraiseql:field" in result
        assert "name: email" in result
        assert "type: String!" in result

        # Ref field
        assert "name: company" in result
        assert "type: Company!" in result
        assert "relation: many_to_one" in result

    def test_function_annotation(self, annotator, sample_entity):
        """Test function gets FraiseQL query/mutation annotation"""
        # Act
        result = annotator.annotate_function(
            name="search_contact_by_text",
            entity=sample_entity,
            function_type="query"
        )

        # Assert
        assert "@fraiseql:query" in result
        assert "name: searchContactByText" in result
        assert "type: [Contact!]!" in result
```

**Run Tests (Should Fail)**:
```bash
uv run pytest tests/unit/generators/fraiseql/test_fraiseql_annotator.py -v
```

**Commit**:
```bash
git add tests/unit/generators/fraiseql/test_fraiseql_annotator.py
git commit -m "test(fraiseql): add failing tests for FraiseQL annotations - RED phase"
```

---

#### ðŸŸ¢ GREEN: Implement FraiseQL Annotator (2 hours)

**Generator**: `src/generators/fraiseql/fraiseql_annotator.py`

```python
"""
FraiseQL Annotation Generator

Generates @fraiseql:* comments for automatic GraphQL schema discovery
"""

from typing import Dict, Any
from src.core.specql_parser import Entity, Field


class FraiseQLAnnotator:
    """Generates FraiseQL metadata annotations in SQL comments"""

    def annotate_table(self, entity: Entity) -> str:
        """Generate FraiseQL annotation for base table"""
        return f"""COMMENT ON TABLE {entity.schema}.tb_{entity.name.lower()} IS '{entity.description}

Trinity Pattern: Normalized base table
- pk_{entity.name.lower()}: INTEGER primary key for performance
- id: UUID for stable external references
- Full audit trail

@fraiseql:entity
name: {entity.name}
trinity: base_table
mutation: true';"""

    def annotate_table_view(self, entity: Entity) -> str:
        """Generate FraiseQL annotation for table view"""
        return f"""COMMENT ON TABLE {entity.schema}.tv_{entity.name.lower()} IS '{entity.description}

Trinity Pattern: Denormalized JSONB view for GraphQL
- Synced automatically from tb_{entity.name.lower()}
- data: Complete entity as JSONB

@fraiseql:type
name: {entity.name}
trinity: table_view
query: true';"""

    def annotate_fields(self, entity: Entity) -> str:
        """Generate FraiseQL annotations for all fields"""
        comments = []

        for field in entity.fields:
            graphql_type = self._map_to_graphql_type(field)

            comment = f"""COMMENT ON COLUMN {entity.schema}.tb_{entity.name.lower()}.{field.name} IS '{field.description}

@fraiseql:field
name: {field.name}
type: {graphql_type}"""

            # Add relation metadata for ref fields
            if field.field_type == "ref":
                comment += f"\nrelation: many_to_one"

            comment += "';"
            comments.append(comment)

        return "\n\n".join(comments)

    def annotate_function(
        self,
        name: str,
        entity: Entity,
        function_type: str,  # 'query' or 'mutation'
        return_type: str = None,
        args: Dict[str, str] = None
    ) -> str:
        """Generate FraiseQL annotation for function"""

        # Convert snake_case to camelCase
        graphql_name = self._to_camel_case(name)

        if return_type is None:
            return_type = f"[{entity.name}!]!"

        annotation = f"""@fraiseql:{function_type}
name: {graphql_name}
type: {return_type}"""

        if args:
            annotation += "\nargs:"
            for arg_name, arg_type in args.items():
                annotation += f"\n  - {arg_name}: {arg_type}"

        return annotation

    def _map_to_graphql_type(self, field: Field) -> str:
        """Map SpecQL field type to GraphQL type"""
        type_map = {
            "text": "String",
            "integer": "Int",
            "decimal": "Float",
            "boolean": "Boolean",
            "date": "Date",
            "timestamp": "DateTime",
            "json": "JSON",
            "enum": "String",
        }

        if field.field_type == "ref":
            base_type = field.ref_entity
        else:
            base_type = type_map.get(field.field_type, "String")

        # Add ! for required fields
        if field.required:
            return f"{base_type}!"

        return base_type

    def _to_camel_case(self, snake_str: str) -> str:
        """Convert snake_case to camelCase"""
        components = snake_str.split('_')
        return components[0] + ''.join(x.title() for x in components[1:])
```

**Run Tests (Should Pass)**:
```bash
uv run pytest tests/unit/generators/fraiseql/test_fraiseql_annotator.py -v
```

**Commit**:
```bash
git add src/generators/fraiseql/fraiseql_annotator.py
git commit -m "feat(fraiseql): implement FraiseQL annotation generator - GREEN phase"
```

---

**Afternoon Block (4 hours): Integrate FraiseQL Everywhere**

#### ðŸ”§ REFACTOR: Add Annotations to All Templates (2 hours)

**Update Templates**:

1. **base_table.sql.j2** - Add table and field comments
2. **table_view.sql.j2** - Add table view comments
3. **trinity_helpers.sql.j2** - Add function comments
4. **vector_features.sql.j2** - Add query function comments
5. **fulltext_features.sql.j2** - Add query function comments

**Update Generators** to use `FraiseQLAnnotator`:

```python
class BaseTableGenerator:
    def __init__(self):
        self.annotator = FraiseQLAnnotator()

    def generate(self, entity: Entity) -> str:
        sql = self.template.render(...)

        # Append FraiseQL comments
        sql += "\n\n" + self.annotator.annotate_table(entity)
        sql += "\n\n" + self.annotator.annotate_fields(entity)

        return sql
```

---

#### âœ… QA: Integration Testing (2 hours)

**Integration Test**: `tests/integration/test_complete_trinity_with_fraiseql.py`

```python
"""Integration test for complete Trinity pattern with FraiseQL"""

def test_complete_schema_generation():
    """Test full schema generation with all features"""
    yaml_content = """
entity: Pattern
schema: specql_registry
description: "Reusable domain patterns"
fields:
  pattern_name: text!
  description: text
  category: text
  pattern_type: enum(universal, domain, entity_template)
features:
  - semantic_search
  - full_text_search
organization:
  domain: core
  subdomain: registry
  table_code: "011114"
"""

    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    orchestrator = SchemaOrchestrator()
    files = orchestrator.generate_schema([entity])

    # Should generate 5 files
    assert len(files) == 5

    # 1. Base table with Trinity pattern
    base_table = next(f for f in files if "tb_pattern" in f.name)
    assert "pk_pattern INTEGER" in base_table.content
    assert "id UUID" in base_table.content
    assert "tenant_id UUID" in base_table.content
    assert "created_at TIMESTAMPTZ" in base_table.content
    assert "@fraiseql:entity" in base_table.content

    # 2. Table view with JSONB
    table_view = next(f for f in files if "tv_pattern" in f.name)
    assert "data JSONB" in table_view.content
    assert "refresh_tv_pattern()" in table_view.content
    assert "@fraiseql:type" in table_view.content

    # 3. Trinity helpers
    helpers = next(f for f in files if "helpers" in f.name)
    assert "pattern_pk(TEXT)" in helpers.content
    assert "pattern_id(INTEGER)" in helpers.content

    # 4. Vector features
    vector = next(f for f in files if "vector" in f.name)
    assert "embedding vector(384)" in vector.content
    assert "USING hnsw" in vector.content
    assert "search_pattern_by_embedding" in vector.content
    assert "@fraiseql:query" in vector.content

    # 5. Full-text search
    fulltext = next(f for f in files if "fulltext" in f.name)
    assert "search_vector tsvector" in fulltext.content
    assert "USING gin" in fulltext.content
    assert "search_pattern_by_text" in fulltext.content
    assert "@fraiseql:query" in fulltext.content
```

**Run Integration Tests**:
```bash
uv run pytest tests/integration/test_complete_trinity_with_fraiseql.py -v
```

**Day 4 Summary**:
- âœ… FraiseQL annotator implemented
- âœ… All templates updated with annotations
- âœ… Complete GraphQL metadata
- âœ… Integration tests passing

---

### Day 5: Organization Metadata & Final Integration

**Objective**: Implement hierarchical organization metadata and complete the 100% equivalence

**Morning Block (4 hours): Organization Metadata**

#### ðŸ”´ RED: Organization Tests (1.5 hours)

**Test File**: `tests/unit/core/test_organization_parser.py`

```python
"""Tests for organization metadata parsing"""

import pytest
from src.core.specql_parser import SpecQLParser


class TestOrganizationMetadata:
    """Test parsing of organization metadata from YAML"""

    def test_parse_organization_section(self):
        """Test organization metadata parsed correctly"""
        yaml_content = """
entity: Contact
schema: crm
fields:
  email: text
organization:
  domain: customer
  subdomain: contacts
  table_code: "012361"
"""
        parser = SpecQLParser()
        entity = parser.parse(yaml_content)

        # Assert
        assert entity.organization is not None
        assert entity.organization["domain"] == "customer"
        assert entity.organization["subdomain"] == "contacts"
        assert entity.organization["table_code"] == "012361"

    def test_generate_hierarchical_code(self):
        """Test table code generation from organization"""
        yaml_content = """
entity: Contact
schema: crm
organization:
  domain: customer
  subdomain: contacts
  domain_number: 1
  subdomain_number: 2
  entity_sequence: 3
"""
        parser = SpecQLParser()
        entity = parser.parse(yaml_content)

        # Act
        code = entity.generate_table_code()

        # Assert - Format: 0{layer}{domain}{subdomain}{entity}{sequence}
        assert code == "012361"  # 01=write_side, 2=customer, 3=contacts, 6=contact, 1=sequence

    def test_hierarchical_path_generation(self):
        """Test file path generated from organization"""
        yaml_content = """
entity: Contact
schema: crm
organization:
  domain: customer
  subdomain: contacts
  table_code: "012361"
"""
        parser = SpecQLParser()
        entity = parser.parse(yaml_content)

        # Act
        path = entity.generate_path()

        # Assert
        expected = "0_schema/01_write_side/012_customer/0123_contacts/012361_tb_contact.sql"
        assert str(path) == expected
```

**Run Tests (Should Fail)**:
```bash
uv run pytest tests/unit/core/test_organization_parser.py -v
```

---

#### ðŸŸ¢ GREEN: Implement Organization Support (1.5 hours)

**Update Parser**: `src/core/specql_parser.py`

```python
from dataclasses import dataclass, field
from typing import Optional, Dict, Any
from pathlib import Path


@dataclass
class Entity:
    name: str
    schema: str
    fields: List[Field]
    description: str = ""
    schema_type: str = "multi_tenant"  # framework, multi_tenant, shared
    features: List[str] = field(default_factory=list)
    organization: Optional[Dict[str, Any]] = None

    def generate_table_code(self) -> str:
        """
        Generate 6-digit hierarchical table code

        Format: 0{layer}{domain}{subdomain}{entity}{sequence}
        - layer: 1=write_side, 2=read_side
        - domain: 0-F (hex)
        - subdomain: 0-F (hex)
        - entity: 0-F (hex)
        - sequence: 0-F (hex)
        """
        if not self.organization:
            return "000000"

        org = self.organization
        layer = "01"  # write_side by default
        domain = org.get("domain_number", 0)
        subdomain = org.get("subdomain_number", 0)
        entity_num = org.get("entity_number", 0)
        sequence = org.get("sequence", 0)

        return f"{layer}{domain:01X}{subdomain:01X}{entity_num:01X}{sequence:01X}"

    def generate_path(self, layer: str = "write_side") -> Path:
        """
        Generate hierarchical file path

        Example: 0_schema/01_write_side/012_customer/0123_contacts/012361_tb_contact.sql
        """
        if not self.organization:
            return Path(f"0_schema/{self.schema}/tb_{self.name.lower()}.sql")

        org = self.organization
        table_code = org.get("table_code", self.generate_table_code())

        # Extract hierarchical codes
        layer_code = table_code[:2]
        domain_code = table_code[:3]
        subdomain_code = table_code[:4]
        entity_code = table_code[:6]

        # Build path
        domain_name = org.get("domain", "unknown")
        subdomain_name = org.get("subdomain", "unknown")

        layer_name = "01_write_side" if layer == "write_side" else "02_read_side"

        return Path(
            "0_schema" /
            layer_name /
            f"{domain_code}_{domain_name}" /
            f"{subdomain_code}_{subdomain_name}" /
            f"{entity_code}_tb_{self.name.lower()}.sql"
        )


class SpecQLParser:
    """Enhanced parser with organization support"""

    def parse(self, yaml_content: str) -> Entity:
        """Parse SpecQL YAML with organization metadata"""
        data = yaml.safe_load(yaml_content)

        # Parse basic fields
        entity = Entity(
            name=data["entity"],
            schema=data["schema"],
            fields=self._parse_fields(data.get("fields", {})),
            description=data.get("description", ""),
            schema_type=data.get("schema_type", "multi_tenant"),
            features=data.get("features", []),
            organization=data.get("organization")
        )

        return entity
```

**Run Tests (Should Pass)**:
```bash
uv run pytest tests/unit/core/test_organization_parser.py -v
```

**Commit**:
```bash
git add src/core/specql_parser.py
git commit -m "feat(parser): add organization metadata support for hierarchical paths - GREEN phase"
```

---

**Afternoon Block (4 hours): Final Integration & Testing**

#### ðŸ”§ REFACTOR: Update Hierarchical File Writer (1.5 hours)

**Update**: `src/generators/hierarchical_file_writer.py`

```python
class HierarchicalFileWriter:
    """Write files using entity organization metadata"""

    def write(self, entity: Entity, content: str, layer: str) -> Path:
        """
        Write file to hierarchical path based on organization

        Args:
            entity: Entity with organization metadata
            content: File content to write
            layer: 'write_side' or 'read_side'

        Returns:
            Path where file was written
        """
        file_path = entity.generate_path(layer)

        # Ensure directory exists
        file_path.parent.mkdir(parents=True, exist_ok=True)

        # Write file
        file_path.write_text(content)

        return file_path
```

---

#### âœ… QA: End-to-End Testing (2.5 hours)

**E2E Test**: `tests/e2e/test_100_percent_equivalence.py`

```python
"""
End-to-end test: 100% Trinity Pattern Equivalence

Validates that SpecQL generates identical schema to manually-written Trinity pattern
"""

import pytest
from pathlib import Path
from src.cli.orchestrator import CLIOrchestrator


def test_complete_trinity_generation():
    """Test SpecQL generates 100% equivalent Trinity schema"""

    # Sample SpecQL YAML
    yaml_path = Path("tests/fixtures/sample_registry.yaml")
    yaml_content = """
entity: Domain
schema: specql_registry
schema_type: framework
description: "Registry of all domains in SpecQL"

fields:
  domain_number: integer!
    description: "Unique domain identifier (1-255)"
    constraints:
      - unique
      - check: "domain_number >= 1 AND domain_number <= 255"

  domain_name: text!
    description: "Human-readable domain name"

  description: text

  schema_type: enum(framework, multi_tenant, shared)!
    description: "Type of schema"

features:
  - semantic_search
  - full_text_search

organization:
  domain: core
  subdomain: registry
  table_code: "011111"
"""

    yaml_path.write_text(yaml_content)

    # Generate schema
    orchestrator = CLIOrchestrator()
    result = orchestrator.generate([yaml_path], hierarchical=True)

    # Verify all expected files generated
    expected_files = [
        "0_schema/01_write_side/011_core/0111_registry/011111_tb_domain.sql",
        "0_schema/02_read_side/021_core/0211_registry/021111_tv_domain.sql",
        "0_schema/01_write_side/011_core/0111_registry/011112_trinity_helpers.sql",
        "0_schema/01_write_side/011_core/0111_registry/011113_vector_features.sql",
        "0_schema/01_write_side/011_core/0111_registry/011114_fulltext_features.sql",
    ]

    for expected_file in expected_files:
        assert Path(expected_file).exists()

    # Verify base table content
    base_table = Path(expected_files[0]).read_text()

    # Trinity pattern
    assert "pk_domain INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY" in base_table
    assert "id UUID DEFAULT gen_random_uuid() NOT NULL" in base_table
    assert "CONSTRAINT tb_domain_id_key UNIQUE (id)" in base_table

    # Business fields
    assert "domain_number INTEGER NOT NULL" in base_table
    assert "domain_name TEXT NOT NULL" in base_table
    assert "schema_type TEXT NOT NULL" in base_table

    # Audit fields (all 6)
    assert "created_at TIMESTAMPTZ NOT NULL DEFAULT now()" in base_table
    assert "created_by UUID" in base_table
    assert "updated_at TIMESTAMPTZ NOT NULL DEFAULT now()" in base_table
    assert "updated_by UUID" in base_table
    assert "deleted_at TIMESTAMPTZ" in base_table
    assert "deleted_by UUID" in base_table

    # Constraints
    assert "CONSTRAINT chk_tb_domain_domain_number" in base_table
    assert "domain_number >= 1 AND domain_number <= 255" in base_table
    assert "CONSTRAINT chk_tb_domain_schema_type CHECK (schema_type IN ('framework', 'multi_tenant', 'shared'))" in base_table

    # Indexes
    assert "CREATE INDEX idx_tb_domain_domain_number" in base_table
    assert "CREATE INDEX idx_tb_domain_schema_type" in base_table

    # FraiseQL annotations
    assert "@fraiseql:entity" in base_table
    assert "name: Domain" in base_table
    assert "trinity: base_table" in base_table

    # Verify table view
    table_view = Path(expected_files[1]).read_text()
    assert "CREATE TABLE specql_registry.tv_domain" in table_view
    assert "data JSONB NOT NULL" in table_view
    assert "CREATE TRIGGER trg_refresh_tv_domain" in table_view
    assert "@fraiseql:type" in table_view
    assert "trinity: table_view" in table_view

    # Verify Trinity helpers
    helpers = Path(expected_files[2]).read_text()
    assert "domain_pk(TEXT)" in helpers
    assert "domain_id(INTEGER)" in helpers
    assert "@fraiseql:helper" in helpers

    # Verify vector features
    vector = Path(expected_files[3]).read_text()
    assert "embedding vector(384)" in vector
    assert "USING hnsw (embedding vector_cosine_ops)" in vector
    assert "search_domain_by_embedding" in vector

    # Verify full-text search
    fulltext = Path(expected_files[4]).read_text()
    assert "search_vector tsvector" in fulltext
    assert "USING gin (search_vector)" in fulltext
    assert "search_domain_by_text" in fulltext

    print("âœ… 100% Trinity Pattern Equivalence Achieved!")


def test_compare_with_manual_schema():
    """Compare generated schema with manually-written Trinity version"""

    # This test would load a manually-written Trinity schema
    # and compare it line-by-line with the generated version
    # to ensure 100% equivalence

    pass  # Implementation depends on having manual schema
```

**Run E2E Tests**:
```bash
uv run pytest tests/e2e/test_100_percent_equivalence.py -v
```

**Full Test Suite**:
```bash
# All tests
uv run pytest --tb=short -v

# Coverage
uv run pytest --cov=src --cov-report=html

# Type checking
uv run mypy src/

# Linting
uv run ruff check
```

---

**Day 5 Summary**:
- âœ… Organization metadata parsing
- âœ… Hierarchical path generation
- âœ… Complete file writer integration
- âœ… End-to-end tests passing
- âœ… 100% Trinity equivalence achieved

---

## Week 12 Summary

**Achievements**:
- âœ… Base table (tb_) generation with complete Trinity pattern
- âœ… Enhanced table view (tv_) generation with auto-refresh
- âœ… Trinity helper functions for UUID â†” INTEGER conversion
- âœ… Vector embeddings with HNSW indexes
- âœ… Full-text search with GIN indexes
- âœ… Complete FraiseQL annotations
- âœ… Organization metadata support
- âœ… Hierarchical file generation

**Lines of Code**:
- Templates: ~1,200 lines
- Generators: ~2,500 lines
- Tests: ~3,000 lines
- **Total: ~6,700 lines**

**Quality Metrics**:
- Test Coverage: 95%+
- All tests passing
- Type hints: 100%
- Linting: Clean

---

## Week 13: CLI Integration & Documentation

**Objective**: Integrate complete Trinity generation into CLI and create comprehensive documentation

### Day 1-2: CLI Enhancement

- Update `specql generate` command with new options
- Add `--trinity-full` flag for complete generation
- Add `--features` flag for enabling semantic/fulltext search
- Integration with existing commands

### Day 3-4: Documentation

- User guide for Trinity pattern
- Advanced features documentation
- Migration guide from 95% to 100%
- Best practices

### Day 5: Examples & Templates

- Example YAML files
- Common patterns
- Template library
- Quick start guide

---

## Week 14: Performance & Production Readiness

**Objective**: Optimize generation performance and ensure production readiness

### Day 1-2: Performance Optimization

- Template rendering optimization
- Parallel file generation
- Caching layer for repeated generations
- Benchmark suite

### Day 3-4: Production Testing

- Load testing with large schemas
- Memory profiling
- Error handling improvements
- Recovery mechanisms

### Day 5: Release Preparation

- Final QA
- Version bump
- Release notes
- Community announcement

---

## Success Metrics

### Technical Metrics

- [ ] 100% Trinity pattern equivalence achieved
- [ ] Both tb_ and tv_ tables generated automatically
- [ ] All advanced PostgreSQL features included
- [ ] Complete FraiseQL integration
- [ ] Test coverage > 95%
- [ ] Zero manual SQL required

### Business Metrics

- [ ] Self-schema dogfooding complete (SpecQL generates its own schema)
- [ ] Generation time < 1 second per entity
- [ ] Documentation complete and reviewed
- [ ] Example library created
- [ ] Community feedback positive

### Quality Metrics

- [ ] All tests passing
- [ ] Type hints 100% coverage
- [ ] Linting clean
- [ ] No security vulnerabilities
- [ ] Performance benchmarks met

---

## Risk Mitigation

### Technical Risks

1. **Template Complexity**: Use test-driven approach for each template
2. **Performance**: Implement caching and parallel generation
3. **Compatibility**: Test with multiple PostgreSQL versions

### Integration Risks

1. **Breaking Changes**: Maintain backward compatibility with v1.0
2. **Migration Path**: Provide clear migration guide
3. **Testing**: Comprehensive integration test suite

---

## Conclusion

Weeks 12-14 implement the missing 5% to achieve **100% Trinity Pattern Equivalence** between SpecQL-generated and manually-written schemas. This completes the vision of zero manual SQL for enterprise-grade PostgreSQL schemas with advanced features like vector search, full-text search, and complete GraphQL integration.

**Business Impact**: Complete automation of sophisticated database schema generation, enabling developers to focus on business logic while SpecQL handles all technical complexity.

---

**Next Steps After Week 14**:
- Weeks 15-16: Multi-language support (TypeScript, Python)
- Weeks 17-18: Advanced action compilation
- Weeks 19-20: Production deployment automation

---

**Status**: ðŸ”´ Ready to Execute
**Priority**: High (completes GitHub Issue #10)
**Estimated Effort**: 15 days (3 weeks)
**Expected Output**: ~12,000 lines of production code with complete test coverage
