<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Missing Patterns Implementation Plans - SpecQL Documentation</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Missing Patterns Implementation Plans";
        var mkdocs_page_input_path = "implementation-plans/MISSING_PATTERNS_IMPLEMENTATION.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> SpecQL Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="../../getting-started/">Getting Started</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Guides</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="../../guides/mutation-patterns/">Mutation Patterns</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../guides/test-generation/">Test Generation</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../guides/cli/">CLI</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="../../reference/">Reference</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="../../examples/">Examples</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="../../tutorials/">Tutorials</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="../../best-practices/">Best Practices</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="../../troubleshooting/">Troubleshooting</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">SpecQL Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Missing Patterns Implementation Plans</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="missing-patterns-implementation-plans">Missing Patterns Implementation Plans</h1>
<p><strong>Document Purpose</strong>: Detailed phased implementation plans for three patterns from PrintOptim backend:
1. Identifier Recalculation (recalcid functions)
2. LTREE Hierarchical Data
3. Node + Info Two-Table Split for Hierarchical Entities</p>
<p><strong>Methodology</strong>: Phased TDD Approach (RED → GREEN → REFACTOR → QA)</p>
<p><strong>Overall Timeline</strong>: 6 weeks (2 weeks per pattern)</p>
<p><strong>Expert Validation</strong>: SQL architect confirmed node+info split is "good, intentional design" for hierarchical entities.</p>
<hr />
<h2 id="pattern-1-identifier-recalculation-recalcid-functions">Pattern 1: Identifier Recalculation (recalcid) Functions</h2>
<h3 id="executive-summary">Executive Summary</h3>
<p><strong>Problem</strong>: Derived/computed fields (temporal flags, aggregated values, cache columns) become stale when source data changes. Manual recalculation is error-prone.</p>
<p><strong>Solution</strong>: Auto-generate <code>recalcid_{entity}()</code> functions that recalculate derived fields, with cascade support for related entities.</p>
<p><strong>Complexity</strong>: COMPLEX - Multi-phase TDD approach required</p>
<p><strong>Teams Involved</strong>:
- <strong>Team B</strong>: Generate <code>recalculation_context</code> composite type
- <strong>Team C</strong>: Generate <code>recalcid_{entity}()</code> functions and cascade triggers</p>
<p><strong>Business Value</strong>: Eliminates data inconsistency bugs, enables complex temporal business logic</p>
<hr />
<h3 id="phase-1-foundation-recalculation-context-type">PHASE 1: Foundation - Recalculation Context Type</h3>
<p><strong>Objective</strong>: Create reusable <code>recalculation_context</code> composite type for propagating entity IDs through cascade chains</p>
<p><strong>Duration</strong>: 2 days</p>
<h4 id="tdd-cycle-11-define-recalculation-context-type">TDD Cycle 1.1: Define Recalculation Context Type</h4>
<p><strong>RED</strong>: Write failing test for context type generation</p>
<pre><code class="language-python"># tests/unit/schema/test_recalculation_context.py
def test_generate_recalculation_context_type():
    &quot;&quot;&quot;Schema generator should create recalculation_context composite type&quot;&quot;&quot;
    generator = SchemaGenerator()

    # Generate foundation types (one-time, goes in migration 000)
    sql = generator.generate_foundation_types()

    assert &quot;CREATE TYPE core.recalculation_context&quot; in sql
    assert &quot;entity_id INTEGER&quot; in sql
    assert &quot;entity_uuid UUID&quot; in sql
    assert &quot;related_ids INTEGER[]&quot; in sql
    assert &quot;tenant_id INTEGER&quot; in sql

    # Run test - should FAIL (not implemented yet)
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'SchemaGenerator' object has no attribute 'generate_foundation_types'</code></p>
<hr />
<p><strong>GREEN</strong>: Minimal implementation to pass test</p>
<pre><code class="language-python"># src/generators/schema/schema_generator.py
class SchemaGenerator:
    def generate_foundation_types(self) -&gt; str:
        &quot;&quot;&quot;Generate one-time foundation types for framework&quot;&quot;&quot;
        return &quot;&quot;&quot;
-- Recalculation context for cascade updates
CREATE TYPE core.recalculation_context AS (
    entity_id INTEGER,        -- Primary key of entity being recalculated
    entity_uuid UUID,          -- UUID of entity (for external references)
    related_ids INTEGER[],     -- PKs of related entities affected
    tenant_id INTEGER          -- Tenant context for multi-tenancy
);

COMMENT ON TYPE core.recalculation_context IS
  'Context object passed through recalculation cascade chains';
&quot;&quot;&quot;
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_recalculation_context.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Clean up and add documentation</p>
<pre><code class="language-python"># src/generators/schema/schema_generator.py
class SchemaGenerator:
    def generate_foundation_types(self) -&gt; str:
        &quot;&quot;&quot;
        Generate framework foundation types (one-time generation).

        These types are created once in migration 000 and used across
        all entities. Currently includes:
        - recalculation_context: For cascade update propagation

        Returns:
            SQL DDL for foundation types
        &quot;&quot;&quot;
        types_sql = []

        # Recalculation context type
        types_sql.append(self._recalculation_context_type())

        return &quot;\n\n&quot;.join(types_sql)

    def _recalculation_context_type(self) -&gt; str:
        &quot;&quot;&quot;Generate recalculation_context composite type&quot;&quot;&quot;
        return &quot;&quot;&quot;
-- ============================================================
-- RECALCULATION CONTEXT TYPE
-- ============================================================
-- Context object for propagating entity information through
-- cascade update chains (recalcid functions).
--
-- Usage:
--   v_ctx := ROW(pk_entity, entity.id, NULL, NULL)::core.recalculation_context;
--   PERFORM core.recalcid_related_entity(v_ctx);
-- ============================================================

CREATE TYPE core.recalculation_context AS (
    entity_id INTEGER,        -- Primary key of source entity
    entity_uuid UUID,          -- UUID of source entity
    related_ids INTEGER[],     -- PKs of affected related entities
    tenant_id INTEGER          -- Tenant context (NULL if not multi-tenant)
);

COMMENT ON TYPE core.recalculation_context IS
  '@fraiseql:type name=RecalculationContext internal=true';
&quot;&quot;&quot;.strip()
</code></pre>
<p><strong>Run tests</strong>: <code>uv run pytest tests/unit/schema/ -v</code></p>
<p><strong>Expected</strong>: ✅ All schema tests pass</p>
<hr />
<p><strong>QA</strong>: Verify quality and integration</p>
<pre><code class="language-bash"># Full test suite
uv run pytest --tb=short

# Type checking
uv run mypy src/generators/schema/

# Linting
uv run ruff check src/generators/schema/

# Integration test - verify SQL is valid
uv run pytest tests/integration/test_foundation_types.py -v
</code></pre>
<p><strong>Quality gates</strong>:
- [ ] All tests pass
- [ ] Type hints correct
- [ ] No linting errors
- [ ] Generated SQL executes without errors in PostgreSQL</p>
<hr />
<h4 id="tdd-cycle-12-add-to-migration-000-generator">TDD Cycle 1.2: Add to Migration 000 Generator</h4>
<p><strong>RED</strong>: Write failing test for migration 000 inclusion</p>
<pre><code class="language-python"># tests/unit/cli/test_migration_000.py
def test_migration_000_includes_foundation_types():
    &quot;&quot;&quot;Migration 000 should include all foundation types&quot;&quot;&quot;
    orchestrator = Orchestrator()

    # Generate base migration (migration 000)
    migration_000 = orchestrator.generate_migration_000()

    assert &quot;CREATE TYPE core.recalculation_context&quot; in migration_000
    assert &quot;CREATE SCHEMA IF NOT EXISTS core&quot; in migration_000

    # Should come before any entity tables
    context_pos = migration_000.index(&quot;recalculation_context&quot;)
    entity_pos = migration_000.find(&quot;CREATE TABLE&quot;)
    assert context_pos &lt; entity_pos, &quot;Foundation types must come before tables&quot;
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'Orchestrator' object has no attribute 'generate_migration_000'</code></p>
<hr />
<p><strong>GREEN</strong>: Minimal implementation</p>
<pre><code class="language-python"># src/cli/orchestrator.py
class Orchestrator:
    def generate_migration_000(self) -&gt; str:
        &quot;&quot;&quot;
        Generate migration 000 with framework foundations:
        - Schemas
        - Extensions
        - Foundation types
        &quot;&quot;&quot;
        schema_gen = SchemaGenerator()

        parts = [
            &quot;-- Migration 000: Framework Foundations&quot;,
            &quot;-- Auto-generated by SpecQL&quot;,
            &quot;&quot;,
            &quot;-- Create schemas&quot;,
            &quot;CREATE SCHEMA IF NOT EXISTS core;&quot;,
            &quot;CREATE SCHEMA IF NOT EXISTS management;&quot;,
            &quot;CREATE SCHEMA IF NOT EXISTS tenant;&quot;,
            &quot;CREATE SCHEMA IF NOT EXISTS catalog;&quot;,
            &quot;&quot;,
            &quot;-- Extensions&quot;,
            &quot;CREATE EXTENSION IF NOT EXISTS \&quot;uuid-ossp\&quot;;&quot;,
            &quot;&quot;,
            &quot;-- Foundation types&quot;,
            schema_gen.generate_foundation_types()
        ]

        return &quot;\n&quot;.join(parts)
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/cli/test_migration_000.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Extract schema list to configuration</p>
<pre><code class="language-python"># src/core/config.py
@dataclass
class FrameworkConfig:
    &quot;&quot;&quot;Framework-wide configuration&quot;&quot;&quot;

    # Standard schemas (always created)
    STANDARD_SCHEMAS = [
        &quot;core&quot;,        # Framework foundations
        &quot;management&quot;,  # Management entities
        &quot;tenant&quot;,      # Tenant-scoped entities
        &quot;catalog&quot;,     # Reference data
        &quot;mutation_metadata&quot;  # FraiseQL metadata types
    ]

    # Required extensions
    REQUIRED_EXTENSIONS = [
        &quot;uuid-ossp&quot;,   # UUID generation
        &quot;ltree&quot;        # Hierarchical data (added for Pattern 2)
    ]

# src/cli/orchestrator.py
from src.core.config import FrameworkConfig

class Orchestrator:
    def __init__(self):
        self.config = FrameworkConfig()

    def generate_migration_000(self) -&gt; str:
        &quot;&quot;&quot;Generate migration 000 with framework foundations&quot;&quot;&quot;
        schema_gen = SchemaGenerator()

        # Generate schema creation SQL
        schemas_sql = &quot;\n&quot;.join([
            f&quot;CREATE SCHEMA IF NOT EXISTS {schema};&quot;
            for schema in self.config.STANDARD_SCHEMAS
        ])

        # Generate extension SQL
        extensions_sql = &quot;\n&quot;.join([
            f&quot;CREATE EXTENSION IF NOT EXISTS \&quot;{ext}\&quot;;&quot;
            for ext in self.config.REQUIRED_EXTENSIONS
        ])

        parts = [
            &quot;-- ============================================================&quot;,
            &quot;-- Migration 000: Framework Foundations&quot;,
            &quot;-- Auto-generated by SpecQL Code Generator&quot;,
            &quot;-- ============================================================&quot;,
            &quot;&quot;,
            &quot;-- Schemas&quot;,
            schemas_sql,
            &quot;&quot;,
            &quot;-- Extensions&quot;,
            extensions_sql,
            &quot;&quot;,
            &quot;-- Foundation Types&quot;,
            schema_gen.generate_foundation_types()
        ]

        return &quot;\n&quot;.join(parts)
</code></pre>
<p><strong>Run tests</strong>: <code>uv run pytest tests/unit/cli/ -v</code></p>
<p><strong>Expected</strong>: ✅ All CLI tests pass</p>
<hr />
<p><strong>QA</strong>: Integration testing</p>
<pre><code class="language-python"># tests/integration/test_migration_000_execution.py
import psycopg2
import pytest

def test_migration_000_executes_successfully(test_db_connection):
    &quot;&quot;&quot;Migration 000 should execute without errors in PostgreSQL&quot;&quot;&quot;
    orchestrator = Orchestrator()
    migration_sql = orchestrator.generate_migration_000()

    conn = test_db_connection
    cursor = conn.cursor()

    # Execute migration
    cursor.execute(migration_sql)
    conn.commit()

    # Verify schemas exist
    cursor.execute(&quot;&quot;&quot;
        SELECT schema_name
        FROM information_schema.schemata
        WHERE schema_name IN ('core', 'management', 'tenant')
    &quot;&quot;&quot;)
    schemas = [row[0] for row in cursor.fetchall()]
    assert 'core' in schemas
    assert 'management' in schemas

    # Verify type exists
    cursor.execute(&quot;&quot;&quot;
        SELECT typname
        FROM pg_type
        WHERE typname = 'recalculation_context'
    &quot;&quot;&quot;)
    assert cursor.fetchone() is not None
</code></pre>
<p><strong>Run integration tests</strong>: <code>uv run pytest tests/integration/ -v</code></p>
<p><strong>Expected</strong>: ✅ Migration executes cleanly</p>
<hr />
<h3 id="phase-2-ast-support-for-recalcid-configuration">PHASE 2: AST Support for Recalcid Configuration</h3>
<p><strong>Objective</strong>: Extend SpecQL AST to parse and represent recalcid configuration</p>
<p><strong>Duration</strong>: 3 days</p>
<h4 id="tdd-cycle-21-parse-recalcid-flag">TDD Cycle 2.1: Parse recalcid Flag</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/core/test_recalcid_parsing.py
def test_parse_recalcid_flag():
    &quot;&quot;&quot;Parser should recognize operations.recalcid flag&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Contact
schema: crm

fields:
  status: enum(lead, qualified)

operations:
  recalcid: true
&quot;&quot;&quot;

    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    assert entity.operations.recalcid is True
</code></pre>
<p><strong>Expected failure</strong>: Test should fail (already implemented in AST, but test missing)</p>
<hr />
<p><strong>GREEN</strong>: Verify implementation exists</p>
<pre><code class="language-python"># This should already pass - AST models have recalcid support
# src/core/ast_models.py already has:
# @dataclass
# class OperationConfig:
#     recalcid: bool = True
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/core/test_recalcid_parsing.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS (implementation already exists)</p>
<hr />
<h4 id="tdd-cycle-22-parse-cascade-updates-configuration">TDD Cycle 2.2: Parse Cascade Updates Configuration</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/core/test_cascade_updates_parsing.py
def test_parse_cascade_updates():
    &quot;&quot;&quot;Parser should recognize business_logic.cascade_updates&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: MachineItem

business_logic:
  cascade_updates:
    - name: recalculate_identifiers
      trigger: after_insert
      scope: self
      function: recalcid_machine_item
      parameters: [v_ctx]

    - name: refresh_parent_machine
      trigger: after_insert
      scope: parent
      entity: Machine
      function: refresh_machine
      parameters: [v_ctx]
      ignore_errors: true
&quot;&quot;&quot;

    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    assert len(entity.business_logic.cascade_updates) == 2

    # First cascade
    recalc = entity.business_logic.cascade_updates[0]
    assert recalc.name == &quot;recalculate_identifiers&quot;
    assert recalc.trigger == &quot;after_insert&quot;
    assert recalc.scope == &quot;self&quot;
    assert recalc.function == &quot;recalcid_machine_item&quot;
    assert recalc.parameters == [&quot;v_ctx&quot;]

    # Second cascade
    refresh = entity.business_logic.cascade_updates[1]
    assert refresh.scope == &quot;parent&quot;
    assert refresh.entity == &quot;Machine&quot;
    assert refresh.ignore_errors is True
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'BusinessLogic' object has no attribute 'cascade_updates'</code></p>
<hr />
<p><strong>GREEN</strong>: Add AST model for cascade updates</p>
<pre><code class="language-python"># src/core/ast_models.py

@dataclass
class CascadeUpdate:
    &quot;&quot;&quot;Cascade update configuration for recalcid chains&quot;&quot;&quot;
    name: str
    trigger: str  # &quot;after_insert&quot;, &quot;after_update&quot;, &quot;after_delete&quot;
    scope: str    # &quot;self&quot;, &quot;parent&quot;, &quot;related&quot;
    function: str
    parameters: List[str]
    entity: Optional[str] = None  # For parent/related scope
    ignore_errors: bool = False
    find_related: Optional[Dict[str, Any]] = None  # For related scope

@dataclass
class BusinessLogic:
    &quot;&quot;&quot;Business logic configuration&quot;&quot;&quot;
    default_values: List[DefaultValue] = field(default_factory=list)
    validations: List[Validation] = field(default_factory=list)
    cascade_updates: List[CascadeUpdate] = field(default_factory=list)  # NEW
    conflict_detection: List[ConflictDetection] = field(default_factory=list)
</code></pre>
<p><strong>Update parser</strong>:</p>
<pre><code class="language-python"># src/core/specql_parser.py

def _parse_business_logic(self, bl_data: Dict[str, Any]) -&gt; BusinessLogic:
    &quot;&quot;&quot;Parse business_logic section&quot;&quot;&quot;
    return BusinessLogic(
        default_values=self._parse_default_values(bl_data.get(&quot;default_values&quot;, [])),
        validations=self._parse_validations(bl_data.get(&quot;validations&quot;, [])),
        cascade_updates=self._parse_cascade_updates(bl_data.get(&quot;cascade_updates&quot;, [])),
        conflict_detection=self._parse_conflict_detection(bl_data.get(&quot;conflict_detection&quot;, []))
    )

def _parse_cascade_updates(self, cascade_data: List[Dict]) -&gt; List[CascadeUpdate]:
    &quot;&quot;&quot;Parse cascade_updates configuration&quot;&quot;&quot;
    cascades = []
    for item in cascade_data:
        cascades.append(CascadeUpdate(
            name=item[&quot;name&quot;],
            trigger=item[&quot;trigger&quot;],
            scope=item[&quot;scope&quot;],
            function=item[&quot;function&quot;],
            parameters=item[&quot;parameters&quot;],
            entity=item.get(&quot;entity&quot;),
            ignore_errors=item.get(&quot;ignore_errors&quot;, False),
            find_related=item.get(&quot;find_related&quot;)
        ))
    return cascades
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/core/test_cascade_updates_parsing.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Add validation for cascade configuration</p>
<pre><code class="language-python"># src/core/specql_parser.py

def _parse_cascade_updates(self, cascade_data: List[Dict]) -&gt; List[CascadeUpdate]:
    &quot;&quot;&quot;Parse and validate cascade_updates configuration&quot;&quot;&quot;
    cascades = []

    for idx, item in enumerate(cascade_data):
        # Validate required fields
        if &quot;name&quot; not in item:
            raise ValueError(f&quot;cascade_updates[{idx}]: 'name' is required&quot;)
        if &quot;trigger&quot; not in item:
            raise ValueError(f&quot;cascade_updates[{idx}]: 'trigger' is required&quot;)

        # Validate trigger value
        valid_triggers = [&quot;after_insert&quot;, &quot;after_update&quot;, &quot;after_delete&quot;]
        if item[&quot;trigger&quot;] not in valid_triggers:
            raise ValueError(
                f&quot;cascade_updates[{idx}]: trigger must be one of {valid_triggers}&quot;
            )

        # Validate scope
        valid_scopes = [&quot;self&quot;, &quot;parent&quot;, &quot;related&quot;]
        scope = item.get(&quot;scope&quot;, &quot;self&quot;)
        if scope not in valid_scopes:
            raise ValueError(
                f&quot;cascade_updates[{idx}]: scope must be one of {valid_scopes}&quot;
            )

        # Validate scope-specific requirements
        if scope in [&quot;parent&quot;, &quot;related&quot;] and &quot;entity&quot; not in item:
            raise ValueError(
                f&quot;cascade_updates[{idx}]: 'entity' is required for scope={scope}&quot;
            )

        if scope == &quot;related&quot; and &quot;find_related&quot; not in item:
            raise ValueError(
                f&quot;cascade_updates[{idx}]: 'find_related' is required for scope=related&quot;
            )

        cascades.append(CascadeUpdate(
            name=item[&quot;name&quot;],
            trigger=item[&quot;trigger&quot;],
            scope=scope,
            function=item[&quot;function&quot;],
            parameters=item.get(&quot;parameters&quot;, []),
            entity=item.get(&quot;entity&quot;),
            ignore_errors=item.get(&quot;ignore_errors&quot;, False),
            find_related=item.get(&quot;find_related&quot;)
        ))

    return cascades
</code></pre>
<p><strong>Add validation tests</strong>:</p>
<pre><code class="language-python"># tests/unit/core/test_cascade_updates_validation.py
import pytest

def test_cascade_missing_name_raises_error():
    &quot;&quot;&quot;Missing name should raise validation error&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Test
business_logic:
  cascade_updates:
    - trigger: after_insert
      function: test_func
&quot;&quot;&quot;
    parser = SpecQLParser()
    with pytest.raises(ValueError, match=&quot;'name' is required&quot;):
        parser.parse(yaml_content)

def test_cascade_invalid_trigger_raises_error():
    &quot;&quot;&quot;Invalid trigger should raise validation error&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Test
business_logic:
  cascade_updates:
    - name: test
      trigger: before_insert  # Invalid
      function: test_func
&quot;&quot;&quot;
    parser = SpecQLParser()
    with pytest.raises(ValueError, match=&quot;trigger must be one of&quot;):
        parser.parse(yaml_content)

def test_cascade_parent_scope_requires_entity():
    &quot;&quot;&quot;Parent scope without entity should raise error&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Test
business_logic:
  cascade_updates:
    - name: test
      trigger: after_insert
      scope: parent
      function: test_func
&quot;&quot;&quot;
    parser = SpecQLParser()
    with pytest.raises(ValueError, match=&quot;'entity' is required for scope=parent&quot;):
        parser.parse(yaml_content)
</code></pre>
<p><strong>Run tests</strong>: <code>uv run pytest tests/unit/core/test_cascade_updates*.py -v</code></p>
<p><strong>Expected</strong>: ✅ All cascade parsing tests pass</p>
<hr />
<p><strong>QA</strong>: Full quality check</p>
<pre><code class="language-bash">uv run pytest tests/unit/core/ -v
uv run mypy src/core/
uv run ruff check src/core/
</code></pre>
<p><strong>Quality gates</strong>:
- [ ] All core tests pass
- [ ] Type checking passes
- [ ] No linting errors
- [ ] Validation catches malformed YAML</p>
<hr />
<h3 id="phase-3-generate-recalcid-functions-team-c">PHASE 3: Generate recalcid Functions (Team C)</h3>
<p><strong>Objective</strong>: Generate <code>recalcid_{entity}()</code> functions that recalculate derived fields</p>
<p><strong>Duration</strong>: 5 days</p>
<h4 id="tdd-cycle-31-basic-recalcid-function-generation">TDD Cycle 3.1: Basic recalcid Function Generation</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/actions/test_recalcid_generation.py
def test_generate_basic_recalcid_function():
    &quot;&quot;&quot;Should generate recalcid function for entity with derived fields&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Allocation&quot;,
        schema=&quot;management&quot;,
        fields=[
            Field(name=&quot;start_date&quot;, field_type=FieldType(base_type=&quot;date&quot;)),
            Field(name=&quot;end_date&quot;, field_type=FieldType(base_type=&quot;date&quot;)),
            Field(name=&quot;is_current&quot;, field_type=FieldType(base_type=&quot;boolean&quot;)),
            Field(name=&quot;is_past&quot;, field_type=FieldType(base_type=&quot;boolean&quot;)),
        ],
        operations=OperationConfig(recalcid=True)
    )

    compiler = ActionCompiler()
    sql = compiler.generate_recalcid_function(entity)

    # Should generate function signature
    assert &quot;CREATE OR REPLACE FUNCTION management.recalcid_allocation&quot; in sql
    assert &quot;p_ctx core.recalculation_context&quot; in sql
    assert &quot;RETURNS void&quot; in sql

    # Should recalculate derived fields
    assert &quot;UPDATE management.tb_allocation&quot; in sql
    assert &quot;is_current =&quot; in sql
    assert &quot;is_past =&quot; in sql

    # Should use context
    assert &quot;(p_ctx).entity_id&quot; in sql
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'ActionCompiler' object has no attribute 'generate_recalcid_function'</code></p>
<hr />
<p><strong>GREEN</strong>: Minimal implementation</p>
<pre><code class="language-python"># src/generators/actions/action_compiler.py

class ActionCompiler:
    def generate_recalcid_function(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;
        Generate recalcid_{entity}() function.

        Currently generates basic template - derived field detection
        will be added in refactor phase.
        &quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()
        table_name = f&quot;tb_{entity_name}&quot;
        pk_name = f&quot;pk_{entity_name}&quot;

        return f&quot;&quot;&quot;
CREATE OR REPLACE FUNCTION {schema}.recalcid_{entity_name}(
    p_ctx core.recalculation_context
)
RETURNS void AS $$
BEGIN
    -- Recalculate derived fields
    UPDATE {schema}.{table_name}
    SET
        is_current = (start_date &lt;= CURRENT_DATE AND end_date &gt;= CURRENT_DATE),
        is_past = (end_date &lt; CURRENT_DATE),
        updated_at = now(),
        updated_by = (p_ctx).tenant_id
    WHERE {pk_name} = (p_ctx).entity_id;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION {schema}.recalcid_{entity_name} IS
  'Recalculate derived/computed fields for {entity.name}';
&quot;&quot;&quot;.strip()
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/actions/test_recalcid_generation.py::test_generate_basic_recalcid_function -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Make it field-driven (detect derived fields)</p>
<pre><code class="language-python"># src/generators/actions/recalcid_generator.py

from typing import List, Tuple
from src.core.ast_models import Entity, Field

class RecalcidGenerator:
    &quot;&quot;&quot;Generator for recalcid functions&quot;&quot;&quot;

    def __init__(self):
        self.temporal_field_patterns = {
            &quot;is_current&quot;: &quot;start_date &lt;= CURRENT_DATE AND end_date &gt;= CURRENT_DATE&quot;,
            &quot;is_past&quot;: &quot;end_date &lt; CURRENT_DATE&quot;,
            &quot;is_future&quot;: &quot;start_date &gt; CURRENT_DATE&quot;,
            &quot;is_active&quot;: &quot;start_date &lt;= CURRENT_DATE AND (end_date IS NULL OR end_date &gt;= CURRENT_DATE)&quot;
        }

    def generate(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate recalcid function for entity&quot;&quot;&quot;
        if not entity.operations.recalcid:
            return &quot;&quot;

        derived_fields = self._detect_derived_fields(entity)

        if not derived_fields:
            # No derived fields, skip function generation
            return &quot;&quot;

        return self._build_function(entity, derived_fields)

    def _detect_derived_fields(self, entity: Entity) -&gt; List[Tuple[str, str]]:
        &quot;&quot;&quot;
        Detect derived/computed fields that need recalculation.

        Returns:
            List of (field_name, calculation_expression) tuples
        &quot;&quot;&quot;
        derived = []
        field_names = {f.name for f in entity.fields}

        # Check for temporal boolean patterns
        for field_name, expression in self.temporal_field_patterns.items():
            if field_name in field_names:
                # Verify required date fields exist
                if &quot;start_date&quot; in field_names and &quot;end_date&quot; in field_names:
                    derived.append((field_name, expression))

        return derived

    def _build_function(self, entity: Entity, derived_fields: List[Tuple[str, str]]) -&gt; str:
        &quot;&quot;&quot;Build recalcid function SQL&quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()
        table_name = f&quot;tb_{entity_name}&quot;
        pk_name = f&quot;pk_{entity_name}&quot;

        # Build SET clause
        set_assignments = []
        for field_name, expression in derived_fields:
            set_assignments.append(f&quot;        {field_name} = ({expression})&quot;)

        # Always update audit fields
        set_assignments.extend([
            &quot;        updated_at = now()&quot;,
            &quot;        updated_by = (p_ctx).tenant_id&quot;
        ])

        set_clause = &quot;,\n&quot;.join(set_assignments)

        return f&quot;&quot;&quot;
CREATE OR REPLACE FUNCTION {schema}.recalcid_{entity_name}(
    p_ctx core.recalculation_context
)
RETURNS void AS $$
BEGIN
    -- Recalculate derived/computed fields
    UPDATE {schema}.{table_name}
    SET
{set_clause}
    WHERE {pk_name} = (p_ctx).entity_id;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION {schema}.recalcid_{entity_name} IS
  '@fraiseql:internal
   Recalculate derived fields for {entity.name}.
   Derived fields: {&quot;, &quot;.join([f[0] for f in derived_fields])}';
&quot;&quot;&quot;.strip()

# Update ActionCompiler to use RecalcidGenerator
# src/generators/actions/action_compiler.py

class ActionCompiler:
    def __init__(self):
        self.recalcid_gen = RecalcidGenerator()

    def generate_recalcid_function(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate recalcid function using specialized generator&quot;&quot;&quot;
        return self.recalcid_gen.generate(entity)
</code></pre>
<p><strong>Add more comprehensive tests</strong>:</p>
<pre><code class="language-python"># tests/unit/actions/test_recalcid_detection.py

def test_detect_temporal_derived_fields():
    &quot;&quot;&quot;Should detect temporal boolean fields&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Allocation&quot;,
        schema=&quot;management&quot;,
        fields=[
            Field(name=&quot;start_date&quot;, field_type=FieldType(base_type=&quot;date&quot;)),
            Field(name=&quot;end_date&quot;, field_type=FieldType(base_type=&quot;date&quot;)),
            Field(name=&quot;is_current&quot;, field_type=FieldType(base_type=&quot;boolean&quot;)),
            Field(name=&quot;is_past&quot;, field_type=FieldType(base_type=&quot;boolean&quot;)),
            Field(name=&quot;is_future&quot;, field_type=FieldType(base_type=&quot;boolean&quot;)),
        ],
        operations=OperationConfig(recalcid=True)
    )

    generator = RecalcidGenerator()
    derived = generator._detect_derived_fields(entity)

    assert len(derived) == 3
    field_names = [f[0] for f in derived]
    assert &quot;is_current&quot; in field_names
    assert &quot;is_past&quot; in field_names
    assert &quot;is_future&quot; in field_names

def test_skip_entity_without_recalcid_flag():
    &quot;&quot;&quot;Should not generate function if recalcid=False&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Contact&quot;,
        schema=&quot;crm&quot;,
        fields=[Field(name=&quot;email&quot;, field_type=FieldType(base_type=&quot;text&quot;))],
        operations=OperationConfig(recalcid=False)
    )

    generator = RecalcidGenerator()
    sql = generator.generate(entity)

    assert sql == &quot;&quot;

def test_skip_entity_without_derived_fields():
    &quot;&quot;&quot;Should not generate function if no derived fields detected&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Contact&quot;,
        schema=&quot;crm&quot;,
        fields=[
            Field(name=&quot;email&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
            Field(name=&quot;status&quot;, field_type=FieldType(base_type=&quot;text&quot;))
        ],
        operations=OperationConfig(recalcid=True)
    )

    generator = RecalcidGenerator()
    sql = generator.generate(entity)

    assert sql == &quot;&quot;
</code></pre>
<p><strong>Run tests</strong>: <code>uv run pytest tests/unit/actions/test_recalcid*.py -v</code></p>
<p><strong>Expected</strong>: ✅ All recalcid tests pass</p>
<hr />
<p><strong>QA</strong>: Integration test with real database</p>
<pre><code class="language-python"># tests/integration/test_recalcid_execution.py

def test_recalcid_function_executes(test_db):
    &quot;&quot;&quot;Generated recalcid function should execute without errors&quot;&quot;&quot;

    # Setup: Create entity and generate SQL
    entity = Entity(
        name=&quot;Allocation&quot;,
        schema=&quot;management&quot;,
        fields=[
            Field(name=&quot;start_date&quot;, field_type=FieldType(base_type=&quot;date&quot;)),
            Field(name=&quot;end_date&quot;, field_type=FieldType(base_type=&quot;date&quot;)),
            Field(name=&quot;is_current&quot;, field_type=FieldType(base_type=&quot;boolean&quot;)),
        ],
        operations=OperationConfig(recalcid=True)
    )

    schema_gen = SchemaGenerator()
    action_compiler = ActionCompiler()

    table_sql = schema_gen.generate_table(entity)
    recalcid_sql = action_compiler.generate_recalcid_function(entity)

    # Execute SQL
    test_db.execute(table_sql)
    test_db.execute(recalcid_sql)

    # Insert test data
    test_db.execute(&quot;&quot;&quot;
        INSERT INTO management.tb_allocation (start_date, end_date, is_current)
        VALUES ('2025-01-01', '2025-12-31', FALSE)
        RETURNING pk_allocation
    &quot;&quot;&quot;)
    pk = test_db.fetchone()[0]

    # Call recalcid function
    test_db.execute(f&quot;&quot;&quot;
        SELECT management.recalcid_allocation(
            ROW({pk}, NULL, NULL, NULL)::core.recalculation_context
        )
    &quot;&quot;&quot;)

    # Verify field was recalculated
    test_db.execute(f&quot;&quot;&quot;
        SELECT is_current
        FROM management.tb_allocation
        WHERE pk_allocation = {pk}
    &quot;&quot;&quot;)
    is_current = test_db.fetchone()[0]
    assert is_current is True  # 2025-11-08 is between 2025-01-01 and 2025-12-31
</code></pre>
<p><strong>Quality gates</strong>:
- [ ] All unit tests pass
- [ ] Integration test executes in real PostgreSQL
- [ ] Generated SQL is syntactically valid
- [ ] Function correctly recalculates fields</p>
<hr />
<h4 id="tdd-cycle-32-cascade-updates-integration">TDD Cycle 3.2: Cascade Updates Integration</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/actions/test_cascade_updates.py

def test_generate_function_with_cascade_updates():
    &quot;&quot;&quot;Should add cascade calls to generated functions&quot;&quot;&quot;
    entity = Entity(
        name=&quot;MachineItem&quot;,
        schema=&quot;management&quot;,
        fields=[Field(name=&quot;machine&quot;, field_type=FieldType(base_type=&quot;ref&quot;, ref_entity=&quot;Machine&quot;))],
        business_logic=BusinessLogic(
            cascade_updates=[
                CascadeUpdate(
                    name=&quot;recalculate_self&quot;,
                    trigger=&quot;after_insert&quot;,
                    scope=&quot;self&quot;,
                    function=&quot;recalcid_machine_item&quot;,
                    parameters=[&quot;v_ctx&quot;]
                ),
                CascadeUpdate(
                    name=&quot;refresh_parent&quot;,
                    trigger=&quot;after_insert&quot;,
                    scope=&quot;parent&quot;,
                    entity=&quot;Machine&quot;,
                    function=&quot;refresh_machine&quot;,
                    parameters=[&quot;v_ctx&quot;],
                    ignore_errors=True
                )
            ]
        )
    )

    compiler = ActionCompiler()
    sql = compiler.generate_insert_function(entity)

    # Should call recalcid on self
    assert &quot;PERFORM management.recalcid_machine_item(v_ctx)&quot; in sql

    # Should call parent refresh with error handling
    assert &quot;BEGIN&quot; in sql
    assert &quot;PERFORM management.refresh_machine(ctx := v_ctx)&quot; in sql
    assert &quot;EXCEPTION WHEN OTHERS THEN NULL&quot; in sql
</code></pre>
<p><strong>Expected failure</strong>: Generated function doesn't include cascade calls</p>
<hr />
<p><strong>GREEN</strong>: Add cascade generation</p>
<pre><code class="language-python"># src/generators/actions/cascade_generator.py

class CascadeGenerator:
    &quot;&quot;&quot;Generate cascade update calls&quot;&quot;&quot;

    def generate_cascade_calls(
        self,
        cascades: List[CascadeUpdate],
        trigger: str
    ) -&gt; str:
        &quot;&quot;&quot;
        Generate SQL for cascade update calls.

        Args:
            cascades: List of cascade configurations
            trigger: Current trigger point (after_insert, after_update, etc.)

        Returns:
            SQL statements for cascade calls
        &quot;&quot;&quot;
        calls = []

        for cascade in cascades:
            if cascade.trigger != trigger:
                continue

            call_sql = self._build_cascade_call(cascade)

            if cascade.ignore_errors:
                call_sql = f&quot;&quot;&quot;
    BEGIN
        {call_sql}
    EXCEPTION
        WHEN OTHERS THEN NULL;
    END;
&quot;&quot;&quot;
            else:
                call_sql = f&quot;    {call_sql}&quot;

            calls.append(call_sql)

        return &quot;\n&quot;.join(calls)

    def _build_cascade_call(self, cascade: CascadeUpdate) -&gt; str:
        &quot;&quot;&quot;Build individual cascade call&quot;&quot;&quot;

        # Build parameter list
        params = &quot;, &quot;.join([
            f&quot;{p.split(':=')[0].strip()} := {p.split(':=')[1].strip()}&quot;
            if &quot;:=&quot; in p else p
            for p in cascade.parameters
        ])

        if cascade.scope == &quot;self&quot;:
            schema = &quot;management&quot;  # TODO: get from entity
            return f&quot;PERFORM {schema}.{cascade.function}({params});&quot;

        elif cascade.scope == &quot;parent&quot;:
            # TODO: Determine schema from entity reference
            schema = &quot;management&quot;
            return f&quot;PERFORM {schema}.{cascade.function}({params});&quot;

        elif cascade.scope == &quot;related&quot;:
            # TODO: Build query to find related entities
            # This is complex - needs Phase 4
            return f&quot;-- TODO: Related cascade for {cascade.entity}&quot;

        return &quot;&quot;

# Update ActionCompiler
class ActionCompiler:
    def __init__(self):
        self.recalcid_gen = RecalcidGenerator()
        self.cascade_gen = CascadeGenerator()

    def generate_insert_function(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate INSERT function with cascade support&quot;&quot;&quot;

        # ... existing function generation ...

        # Add cascade calls after insert
        cascade_calls = self.cascade_gen.generate_cascade_calls(
            entity.business_logic.cascade_updates,
            trigger=&quot;after_insert&quot;
        )

        # Insert cascade calls before RETURN
        # ... implementation details ...
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/actions/test_cascade_updates.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Full integration with action compiler</p>
<pre><code class="language-python"># src/generators/actions/action_compiler.py

class ActionCompiler:
    &quot;&quot;&quot;Compile SpecQL actions to PL/pgSQL functions&quot;&quot;&quot;

    def __init__(self):
        self.recalcid_gen = RecalcidGenerator()
        self.cascade_gen = CascadeGenerator()
        self.step_compiler = StepCompiler()

    def compile(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;
        Compile all action-related functions for entity.

        Generates:
        - recalcid_{entity}() if operations.recalcid=true
        - {action_name}() for each action in entity.actions
        - INSERT/UPDATE triggers with cascade calls
        &quot;&quot;&quot;
        functions = []

        # Generate recalcid function
        recalcid_fn = self.recalcid_gen.generate(entity)
        if recalcid_fn:
            functions.append(recalcid_fn)

        # Generate action functions
        for action in entity.actions:
            action_fn = self.compile_action(entity, action)
            functions.append(action_fn)

        # Generate triggers with cascades
        if entity.business_logic.cascade_updates:
            trigger_fn = self._generate_cascade_trigger(entity)
            functions.append(trigger_fn)

        return &quot;\n\n&quot;.join(functions)

    def _generate_cascade_trigger(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate trigger function that invokes cascade updates&quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()

        # Build context creation
        context_init = &quot;&quot;&quot;
    DECLARE
        v_ctx core.recalculation_context;
    BEGIN
        -- Build recalculation context
        v_ctx := ROW(
            NEW.pk_{entity_name},
            NEW.id,
            NULL,
            NULL
        )::core.recalculation_context;
&quot;&quot;&quot;.format(entity_name=entity_name)

        # Generate cascade calls for each trigger type
        after_insert = self.cascade_gen.generate_cascade_calls(
            entity.business_logic.cascade_updates,
            trigger=&quot;after_insert&quot;
        )

        after_update = self.cascade_gen.generate_cascade_calls(
            entity.business_logic.cascade_updates,
            trigger=&quot;after_update&quot;
        )

        return f&quot;&quot;&quot;
CREATE OR REPLACE FUNCTION {schema}.{entity_name}_cascade_trigger()
RETURNS trigger AS $$
{context_init}

        -- After insert cascades
        IF (TG_OP = 'INSERT') THEN
{after_insert}
        END IF;

        -- After update cascades
        IF (TG_OP = 'UPDATE') THEN
{after_update}
        END IF;

        RETURN NEW;
    END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_{entity_name}_cascade
    AFTER INSERT OR UPDATE ON {schema}.tb_{entity_name}
    FOR EACH ROW
    EXECUTE FUNCTION {schema}.{entity_name}_cascade_trigger();
&quot;&quot;&quot;.strip()
</code></pre>
<p><strong>Run tests</strong>: <code>uv run pytest tests/unit/actions/ -v</code></p>
<p><strong>Expected</strong>: ✅ All action compiler tests pass</p>
<hr />
<p><strong>QA</strong>: End-to-end cascade test</p>
<pre><code class="language-python"># tests/integration/test_cascade_chain.py

def test_cascade_chain_executes(test_db):
    &quot;&quot;&quot;Cascade updates should propagate through entity relationships&quot;&quot;&quot;

    # Create parent entity (Machine)
    machine = Entity(name=&quot;Machine&quot;, schema=&quot;management&quot;, fields=[...])

    # Create child entity (MachineItem) with cascade to parent
    machine_item = Entity(
        name=&quot;MachineItem&quot;,
        schema=&quot;management&quot;,
        fields=[...],
        business_logic=BusinessLogic(
            cascade_updates=[
                CascadeUpdate(
                    name=&quot;refresh_parent&quot;,
                    trigger=&quot;after_insert&quot;,
                    scope=&quot;parent&quot;,
                    entity=&quot;Machine&quot;,
                    function=&quot;refresh_machine&quot;,
                    parameters=[&quot;v_ctx&quot;]
                )
            ]
        )
    )

    # Generate and execute SQL
    compiler = ActionCompiler()
    schema_gen = SchemaGenerator()

    test_db.execute(schema_gen.generate_table(machine))
    test_db.execute(compiler.compile(machine))

    test_db.execute(schema_gen.generate_table(machine_item))
    test_db.execute(compiler.compile(machine_item))

    # Insert parent
    test_db.execute(&quot;INSERT INTO management.tb_machine (...) VALUES (...)&quot;)

    # Insert child - should trigger cascade to parent
    test_db.execute(&quot;INSERT INTO management.tb_machine_item (...) VALUES (...)&quot;)

    # Verify parent was refreshed
    # ... verification logic ...
</code></pre>
<p><strong>Quality gates</strong>:
- [ ] All tests pass
- [ ] Cascade chain executes without errors
- [ ] Parent entity is updated when child changes
- [ ] Error handling works (ignore_errors=true)</p>
<hr />
<h3 id="phase-4-related-entity-cascades">PHASE 4: Related Entity Cascades</h3>
<p><strong>Objective</strong>: Support <code>scope: related</code> cascades that find and update related entities</p>
<p><strong>Duration</strong>: 3 days</p>
<p><em>(This phase is complex and would follow similar TDD cycles - skipping for brevity)</em></p>
<p><strong>Key Features</strong>:
- Parse <code>find_related</code> query configuration
- Generate SQL to find related PKs
- Batch call recalcid functions for related entities
- Handle edge cases (no related entities, circular references)</p>
<hr />
<h2 id="success-criteria-pattern-1">Success Criteria - Pattern 1</h2>
<ul>
<li>[ ] <code>recalculation_context</code> type generated in migration 000</li>
<li>[ ] SpecQL parser recognizes <code>operations.recalcid</code> and <code>business_logic.cascade_updates</code></li>
<li>[ ] <code>recalcid_{entity}()</code> functions auto-generated for entities with derived fields</li>
<li>[ ] Cascade triggers call recalcid functions after INSERT/UPDATE</li>
<li>[ ] <code>scope: self</code> cascades work</li>
<li>[ ] <code>scope: parent</code> cascades work</li>
<li>[ ] <code>scope: related</code> cascades work (Phase 4)</li>
<li>[ ] Error handling respects <code>ignore_errors</code> flag</li>
<li>[ ] All tests pass (90%+ coverage)</li>
<li>[ ] Integration tests verify cascade chains execute correctly</li>
<li>[ ] Documentation updated with examples</li>
</ul>
<hr />
<h2 id="pattern-2-ltree-hierarchical-data">Pattern 2: LTREE Hierarchical Data</h2>
<h3 id="executive-summary_1">Executive Summary</h3>
<p><strong>Problem</strong>: Self-referencing hierarchies (organizational units, locations, industry classifications) need efficient ancestor/descendant queries and path-based operations.</p>
<p><strong>Solution</strong>: Auto-generate LTREE <code>path</code> column for entities with <code>parent: ref(self)</code>, with automatic path maintenance triggers.</p>
<p><strong>Complexity</strong>: MEDIUM - Simpler than recalcid, but requires trigger logic</p>
<p><strong>Teams Involved</strong>:
- <strong>Team B</strong>: Generate LTREE columns, indexes, and triggers</p>
<p><strong>Business Value</strong>: Enables efficient hierarchical queries (find all descendants, get ancestors, etc.) without recursive CTEs</p>
<p><strong>Expert Validation</strong>: SQL architect confirmed this is standard pattern for hierarchical data in PostgreSQL</p>
<hr />
<h3 id="phase-1-ltree-foundation">PHASE 1: LTREE Foundation</h3>
<p><strong>Objective</strong>: Add LTREE extension to framework foundations</p>
<p><strong>Duration</strong>: 1 day</p>
<h4 id="tdd-cycle-11-add-ltree-extension">TDD Cycle 1.1: Add LTREE Extension</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/schema/test_ltree_foundation.py

def test_migration_000_includes_ltree_extension():
    &quot;&quot;&quot;Migration 000 should enable LTREE extension&quot;&quot;&quot;
    orchestrator = Orchestrator()
    migration_sql = orchestrator.generate_migration_000()

    assert 'CREATE EXTENSION IF NOT EXISTS &quot;ltree&quot;' in migration_sql
</code></pre>
<p><strong>Expected failure</strong>: LTREE not in extension list</p>
<hr />
<p><strong>GREEN</strong>: Add to config</p>
<pre><code class="language-python"># src/core/config.py

@dataclass
class FrameworkConfig:
    REQUIRED_EXTENSIONS = [
        &quot;uuid-ossp&quot;,
        &quot;ltree&quot;  # Add this
    ]
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_ltree_foundation.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: No refactoring needed - simple change</p>
<hr />
<p><strong>QA</strong>: Verify in integration test</p>
<pre><code class="language-python"># tests/integration/test_ltree_available.py

def test_ltree_extension_available(test_db):
    &quot;&quot;&quot;LTREE extension should be available after migration 000&quot;&quot;&quot;
    orchestrator = Orchestrator()
    test_db.execute(orchestrator.generate_migration_000())

    # Test LTREE functionality
    test_db.execute(&quot;&quot;&quot;
        CREATE TABLE test_tree (path LTREE);
        INSERT INTO test_tree VALUES ('Top.Science.Astronomy');
    &quot;&quot;&quot;)

    # Test LTREE operator
    result = test_db.execute(&quot;&quot;&quot;
        SELECT path::text
        FROM test_tree
        WHERE path &lt;@ 'Top.Science'
    &quot;&quot;&quot;)

    assert result.fetchone()[0] == 'Top.Science.Astronomy'
</code></pre>
<hr />
<h3 id="phase-2-detect-hierarchical-entities">PHASE 2: Detect Hierarchical Entities</h3>
<p><strong>Objective</strong>: Identify entities with <code>parent: ref(self)</code> pattern</p>
<p><strong>Duration</strong>: 2 days</p>
<h4 id="tdd-cycle-21-detect-self-referencing-parent">TDD Cycle 2.1: Detect Self-Referencing Parent</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/core/test_hierarchical_detection.py

def test_parse_self_referencing_parent():
    &quot;&quot;&quot;Parser should recognize parent: ref(self) as hierarchical entity&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Location
schema: management

fields:
  name: text
  parent: ref(Location)  # Self-reference
&quot;&quot;&quot;

    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    # Should mark as hierarchical
    assert entity.is_hierarchical is True

    # Should identify parent field
    parent_field = next(f for f in entity.fields if f.name == &quot;parent&quot;)
    assert parent_field.field_type.is_self_reference is True
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'Entity' object has no attribute 'is_hierarchical'</code></p>
<hr />
<p><strong>GREEN</strong>: Add detection logic</p>
<pre><code class="language-python"># src/core/ast_models.py

@dataclass
class FieldType:
    base_type: str
    ref_entity: Optional[str] = None
    is_self_reference: bool = False  # NEW
    # ... existing fields ...

@dataclass
class Entity:
    name: str
    schema: str
    fields: List[Field]
    is_hierarchical: bool = False  # NEW
    # ... existing fields ...

# src/core/specql_parser.py

def parse(self, yaml_content: str) -&gt; Entity:
    &quot;&quot;&quot;Parse SpecQL YAML to Entity AST&quot;&quot;&quot;
    data = yaml.safe_load(yaml_content)

    entity_name = data[&quot;entity&quot;]
    fields = self._parse_fields(data.get(&quot;fields&quot;, {}), entity_name)

    # Detect hierarchical structure
    is_hierarchical = self._detect_hierarchical(fields, entity_name)

    entity = Entity(
        name=entity_name,
        schema=data.get(&quot;schema&quot;, &quot;public&quot;),
        fields=fields,
        is_hierarchical=is_hierarchical,
        # ... other fields ...
    )

    return entity

def _detect_hierarchical(self, fields: List[Field], entity_name: str) -&gt; bool:
    &quot;&quot;&quot;Detect if entity is hierarchical (has self-referencing parent field)&quot;&quot;&quot;
    for field in fields:
        if field.field_type.base_type == &quot;ref&quot;:
            if field.field_type.ref_entity == entity_name:
                # Mark as self-reference
                field.field_type.is_self_reference = True
                return True
    return False
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/core/test_hierarchical_detection.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Support explicit hierarchical flag</p>
<pre><code class="language-python"># Support both implicit (parent: ref(self)) and explicit (hierarchical: true)

def test_explicit_hierarchical_flag():
    &quot;&quot;&quot;Should support explicit hierarchical: true flag&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Category
schema: catalog

hierarchical: true  # Explicit flag

fields:
  name: text
  parent_category: ref(Category)
&quot;&quot;&quot;

    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    assert entity.is_hierarchical is True
</code></pre>
<hr />
<p><strong>QA</strong>: Test edge cases</p>
<pre><code class="language-python">def test_non_hierarchical_entity():
    &quot;&quot;&quot;Regular entities should not be marked hierarchical&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Contact
fields:
  email: text
  company: ref(Company)  # Not self-reference
&quot;&quot;&quot;
    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    assert entity.is_hierarchical is False

def test_multiple_self_references_raises_error():
    &quot;&quot;&quot;Multiple parent fields should raise validation error&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Node
fields:
  parent1: ref(Node)
  parent2: ref(Node)  # Error - only one parent allowed
&quot;&quot;&quot;
    parser = SpecQLParser()
    with pytest.raises(ValueError, match=&quot;Multiple self-references not allowed&quot;):
        parser.parse(yaml_content)
</code></pre>
<hr />
<h3 id="phase-3-generate-ltree-schema">PHASE 3: Generate LTREE Schema</h3>
<p><strong>Objective</strong>: Auto-generate <code>path</code> column, indexes, and triggers for hierarchical entities</p>
<p><strong>Duration</strong>: 4 days</p>
<h4 id="tdd-cycle-31-generate-path-column">TDD Cycle 3.1: Generate Path Column</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/schema/test_ltree_generation.py

def test_generate_ltree_path_column():
    &quot;&quot;&quot;Should add LTREE path column to hierarchical entities&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        fields=[
            Field(name=&quot;name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
            Field(name=&quot;parent&quot;, field_type=FieldType(
                base_type=&quot;ref&quot;,
                ref_entity=&quot;Location&quot;,
                is_self_reference=True
            ))
        ],
        is_hierarchical=True
    )

    generator = SchemaGenerator()
    sql = generator.generate_table(entity)

    # Should include path column
    assert &quot;path LTREE NOT NULL&quot; in sql

    # Should include GIST index
    assert &quot;CREATE INDEX idx_location_path_gist&quot; in sql
    assert &quot;USING GIST (path)&quot; in sql

    # Should NOT generate regular btree index for parent FK
    # (path provides better query performance)
</code></pre>
<p><strong>Expected failure</strong>: Generated SQL doesn't include path column</p>
<hr />
<p><strong>GREEN</strong>: Add path column generation</p>
<pre><code class="language-python"># src/generators/schema/schema_generator.py

class SchemaGenerator:
    def generate_table(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate CREATE TABLE statement&quot;&quot;&quot;

        columns = []

        # Trinity pattern
        columns.extend(self._trinity_columns(entity))

        # Business fields
        columns.extend(self._business_columns(entity))

        # Hierarchical path (if applicable)
        if entity.is_hierarchical:
            columns.append(&quot;    path LTREE NOT NULL&quot;)

        # Audit fields
        columns.extend(self._audit_columns())

        table_sql = f&quot;&quot;&quot;
CREATE TABLE {entity.schema}.tb_{entity.name.lower()} (
{','.join(columns)}
);
&quot;&quot;&quot;

        # Indexes
        indexes = self._generate_indexes(entity)

        return table_sql + &quot;\n&quot; + indexes

    def _generate_indexes(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate indexes for table&quot;&quot;&quot;
        indexes = []
        table_name = f&quot;{entity.schema}.tb_{entity.name.lower()}&quot;

        # Standard indexes for FK fields, etc.
        indexes.extend(self._standard_indexes(entity))

        # LTREE GIST index for hierarchical entities
        if entity.is_hierarchical:
            indexes.append(f&quot;&quot;&quot;
CREATE INDEX idx_{entity.name.lower()}_path_gist
    ON {table_name}
    USING GIST (path);
&quot;&quot;&quot;.strip())

        return &quot;\n&quot;.join(indexes)
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_ltree_generation.py::test_generate_ltree_path_column -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<h4 id="tdd-cycle-32-generate-path-maintenance-trigger">TDD Cycle 3.2: Generate Path Maintenance Trigger</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/schema/test_ltree_triggers.py

def test_generate_path_maintenance_trigger():
    &quot;&quot;&quot;Should generate trigger to maintain LTREE paths automatically&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        fields=[...],
        is_hierarchical=True
    )

    generator = SchemaGenerator()
    sql = generator.generate_table(entity)

    # Should include trigger function
    assert &quot;CREATE OR REPLACE FUNCTION management.update_location_path()&quot; in sql

    # Should calculate path from parent
    assert &quot;SELECT path || text2ltree(NEW.identifier)&quot; in sql
    assert &quot;FROM management.tb_location&quot; in sql
    assert &quot;WHERE pk_location = NEW.fk_parent_location&quot; in sql

    # Should handle root nodes (no parent)
    assert &quot;NEW.path := text2ltree(NEW.identifier)&quot; in sql

    # Should create trigger
    assert &quot;CREATE TRIGGER trg_location_path&quot; in sql
    assert &quot;BEFORE INSERT OR UPDATE&quot; in sql
</code></pre>
<p><strong>Expected failure</strong>: No trigger function in generated SQL</p>
<hr />
<p><strong>GREEN</strong>: Generate trigger</p>
<pre><code class="language-python"># src/generators/schema/ltree_generator.py

class LtreeGenerator:
    &quot;&quot;&quot;Generator for LTREE hierarchical support&quot;&quot;&quot;

    def generate_path_trigger(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate trigger function to maintain LTREE paths&quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()
        table_name = f&quot;tb_{entity_name}&quot;
        pk_name = f&quot;pk_{entity_name}&quot;

        # Find parent field
        parent_field = next(
            (f for f in entity.fields if f.field_type.is_self_reference),
            None
        )
        if not parent_field:
            raise ValueError(f&quot;Hierarchical entity {entity.name} has no parent field&quot;)

        parent_fk = f&quot;fk_{parent_field.name}&quot;

        return f&quot;&quot;&quot;
CREATE OR REPLACE FUNCTION {schema}.update_{entity_name}_path()
RETURNS trigger AS $$
BEGIN
    IF NEW.{parent_fk} IS NULL THEN
        -- Root node: path is just the identifier
        NEW.path := text2ltree(NEW.identifier);
    ELSE
        -- Child node: append to parent's path
        SELECT path || text2ltree(NEW.identifier)
        INTO NEW.path
        FROM {schema}.{table_name}
        WHERE {pk_name} = NEW.{parent_fk};

        IF NEW.path IS NULL THEN
            RAISE EXCEPTION 'Parent node not found: %', NEW.{parent_fk};
        END IF;
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_{entity_name}_path
    BEFORE INSERT OR UPDATE OF {parent_fk}, identifier
    ON {schema}.{table_name}
    FOR EACH ROW
    EXECUTE FUNCTION {schema}.update_{entity_name}_path();
&quot;&quot;&quot;.strip()

# Update SchemaGenerator to use LtreeGenerator
class SchemaGenerator:
    def __init__(self):
        self.ltree_gen = LtreeGenerator()

    def generate_table(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate table with LTREE support if hierarchical&quot;&quot;&quot;
        parts = [self._create_table_statement(entity)]
        parts.append(self._generate_indexes(entity))

        if entity.is_hierarchical:
            parts.append(self.ltree_gen.generate_path_trigger(entity))

        return &quot;\n\n&quot;.join(parts)
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_ltree_triggers.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Add path update propagation</p>
<pre><code class="language-python"># When a node moves (parent changes), update all descendant paths

class LtreeGenerator:
    def generate_path_trigger(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate trigger with descendant update support&quot;&quot;&quot;

        # ... existing trigger code ...

        # Add UPDATE cascading for descendants
        update_descendants = f&quot;&quot;&quot;
    -- If parent changed, update all descendant paths
    IF (TG_OP = 'UPDATE' AND OLD.{parent_fk} IS DISTINCT FROM NEW.{parent_fk}) THEN
        -- Recursively update all descendants
        WITH RECURSIVE descendants AS (
            SELECT {pk_name}, path
            FROM {schema}.{table_name}
            WHERE {parent_fk} = NEW.{pk_name}

            UNION ALL

            SELECT t.{pk_name}, t.path
            FROM {schema}.{table_name} t
            JOIN descendants d ON t.{parent_fk} = d.{pk_name}
        )
        UPDATE {schema}.{table_name} t
        SET path = (
            SELECT path
            FROM {schema}.{table_name}
            WHERE {pk_name} = t.{parent_fk}
        ) || text2ltree(t.identifier)
        WHERE {pk_name} IN (SELECT {pk_name} FROM descendants);
    END IF;
&quot;&quot;&quot;

        # Insert into trigger function before RETURN NEW
        # ... implementation ...
</code></pre>
<hr />
<p><strong>QA</strong>: Integration test with real database</p>
<pre><code class="language-python"># tests/integration/test_ltree_hierarchy.py

def test_ltree_path_automatically_maintained(test_db):
    &quot;&quot;&quot;LTREE paths should be automatically calculated and updated&quot;&quot;&quot;

    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        fields=[
            Field(name=&quot;name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
            Field(name=&quot;parent&quot;, field_type=FieldType(
                base_type=&quot;ref&quot;,
                ref_entity=&quot;Location&quot;,
                is_self_reference=True
            ))
        ],
        is_hierarchical=True
    )

    generator = SchemaGenerator()
    sql = generator.generate_table(entity)
    test_db.execute(sql)

    # Insert root node
    test_db.execute(&quot;&quot;&quot;
        INSERT INTO management.tb_location (identifier, name, fk_parent_location)
        VALUES ('USA', 'United States', NULL)
        RETURNING pk_location, path::text
    &quot;&quot;&quot;)
    usa_pk, usa_path = test_db.fetchone()
    assert usa_path == 'USA'

    # Insert child node
    test_db.execute(f&quot;&quot;&quot;
        INSERT INTO management.tb_location (identifier, name, fk_parent_location)
        VALUES ('CA', 'California', {usa_pk})
        RETURNING pk_location, path::text
    &quot;&quot;&quot;)
    ca_pk, ca_path = test_db.fetchone()
    assert ca_path == 'USA.CA'

    # Insert grandchild
    test_db.execute(f&quot;&quot;&quot;
        INSERT INTO management.tb_location (identifier, name, fk_parent_location)
        VALUES ('SF', 'San Francisco', {ca_pk})
        RETURNING path::text
    &quot;&quot;&quot;)
    sf_path = test_db.fetchone()[0]
    assert sf_path == 'USA.CA.SF'

    # Test hierarchical query - all CA descendants
    test_db.execute(&quot;&quot;&quot;
        SELECT path::text
        FROM management.tb_location
        WHERE path &lt;@ 'USA.CA'
        ORDER BY path
    &quot;&quot;&quot;)
    results = test_db.fetchall()
    assert len(results) == 2  # CA and SF
    assert results[0][0] == 'USA.CA'
    assert results[1][0] == 'USA.CA.SF'

def test_move_node_updates_descendants(test_db):
    &quot;&quot;&quot;Moving a node should update all descendant paths&quot;&quot;&quot;

    # Setup hierarchy: USA -&gt; CA -&gt; SF
    # ... insert nodes as above ...

    # Move CA to a different parent (create 'Canada' first)
    test_db.execute(&quot;&quot;&quot;
        INSERT INTO management.tb_location (identifier, name, fk_parent_location)
        VALUES ('CAN', 'Canada', NULL)
        RETURNING pk_location
    &quot;&quot;&quot;)
    canada_pk = test_db.fetchone()[0]

    # Move CA under Canada
    test_db.execute(f&quot;&quot;&quot;
        UPDATE management.tb_location
        SET fk_parent_location = {canada_pk}
        WHERE identifier = 'CA'
    &quot;&quot;&quot;)

    # Verify CA and SF paths updated
    test_db.execute(&quot;&quot;&quot;
        SELECT identifier, path::text
        FROM management.tb_location
        WHERE identifier IN ('CA', 'SF')
        ORDER BY identifier
    &quot;&quot;&quot;)
    results = test_db.fetchall()
    assert results[0] == ('CA', 'CAN.CA')    # CA moved
    assert results[1] == ('SF', 'CAN.CA.SF')  # SF updated automatically
</code></pre>
<p><strong>Quality gates</strong>:
- [ ] All unit tests pass
- [ ] Integration tests execute in PostgreSQL
- [ ] Paths automatically calculated on INSERT
- [ ] Paths updated when parent changes
- [ ] Descendant paths cascade correctly
- [ ] Hierarchical queries work (LTREE operators)</p>
<hr />
<h3 id="phase-4-helper-functions-and-views">PHASE 4: Helper Functions and Views</h3>
<p><strong>Objective</strong>: Generate convenience functions for common hierarchical operations</p>
<p><strong>Duration</strong>: 2 days</p>
<h4 id="tdd-cycle-41-ancestordescendant-functions">TDD Cycle 4.1: Ancestor/Descendant Functions</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/schema/test_ltree_helpers.py

def test_generate_ancestor_function():
    &quot;&quot;&quot;Should generate function to get all ancestors&quot;&quot;&quot;
    entity = Entity(name=&quot;Location&quot;, is_hierarchical=True, ...)

    generator = SchemaGenerator()
    sql = generator.generate_table(entity)

    assert &quot;CREATE FUNCTION management.location_ancestors&quot; in sql
    assert &quot;SELECT * FROM management.tb_location&quot; in sql
    assert &quot;WHERE p_path ~ CONCAT(path::text, '.*')::lquery&quot; in sql
</code></pre>
<hr />
<p><strong>GREEN</strong>: Generate helper functions</p>
<pre><code class="language-python"># src/generators/schema/ltree_generator.py

class LtreeGenerator:
    def generate_helper_functions(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate helper functions for hierarchical queries&quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()
        table_name = f&quot;tb_{entity_name}&quot;

        return f&quot;&quot;&quot;
-- Get all ancestors of a node (including self)
CREATE FUNCTION {schema}.{entity_name}_ancestors(p_path LTREE)
RETURNS SETOF {schema}.{table_name} AS $$
    SELECT *
    FROM {schema}.{table_name}
    WHERE p_path ~ CONCAT(path::text, '.*')::lquery
    ORDER BY nlevel(path);
$$ LANGUAGE sql STABLE;

-- Get all descendants of a node (including self)
CREATE FUNCTION {schema}.{entity_name}_descendants(p_path LTREE)
RETURNS SETOF {schema}.{table_name} AS $$
    SELECT *
    FROM {schema}.{table_name}
    WHERE path &lt;@ p_path
    ORDER BY path;
$$ LANGUAGE sql STABLE;

-- Get immediate children only
CREATE FUNCTION {schema}.{entity_name}_children(p_pk INTEGER)
RETURNS SETOF {schema}.{table_name} AS $$
    SELECT *
    FROM {schema}.{table_name}
    WHERE fk_parent_{entity_name} = p_pk
    ORDER BY identifier;
$$ LANGUAGE sql STABLE;

-- Get depth/level in tree
CREATE FUNCTION {schema}.{entity_name}_depth(p_path LTREE)
RETURNS INTEGER AS $$
    SELECT nlevel(p_path);
$$ LANGUAGE sql IMMUTABLE;
&quot;&quot;&quot;.strip()
</code></pre>
<hr />
<p><strong>REFACTOR</strong>: Add FraiseQL annotations</p>
<pre><code class="language-python"># Add @fraiseql comments for GraphQL exposure

COMMENT ON FUNCTION {schema}.{entity_name}_ancestors IS
  '@fraiseql:query
   name={entity_name}Ancestors
   returns=[{entity.name}!]!
   description=Get all ancestors of a node';
</code></pre>
<hr />
<p><strong>QA</strong>: Test helper functions</p>
<pre><code class="language-python">def test_ancestor_function_works(test_db):
    &quot;&quot;&quot;Ancestor function should return parent chain&quot;&quot;&quot;
    # Setup: USA -&gt; CA -&gt; SF
    # ... insert nodes ...

    # Get ancestors of SF
    result = test_db.execute(&quot;&quot;&quot;
        SELECT name
        FROM management.location_ancestors('USA.CA.SF')
        ORDER BY path
    &quot;&quot;&quot;)

    names = [r[0] for r in result.fetchall()]
    assert names == ['United States', 'California', 'San Francisco']
</code></pre>
<hr />
<h2 id="success-criteria-pattern-2">Success Criteria - Pattern 2</h2>
<ul>
<li>[ ] LTREE extension enabled in migration 000</li>
<li>[ ] Parser detects hierarchical entities (<code>parent: ref(self)</code>)</li>
<li>[ ] <code>path LTREE</code> column auto-generated</li>
<li>[ ] GIST index created on path</li>
<li>[ ] Trigger automatically maintains paths on INSERT/UPDATE</li>
<li>[ ] Moving nodes updates descendant paths</li>
<li>[ ] Helper functions generated (ancestors, descendants, children, depth)</li>
<li>[ ] All tests pass</li>
<li>[ ] Integration tests verify hierarchical queries work</li>
<li>[ ] Documentation includes LTREE usage examples</li>
</ul>
<hr />
<h2 id="pattern-3-node-info-two-table-split">Pattern 3: Node + Info Two-Table Split</h2>
<h3 id="executive-summary_2">Executive Summary</h3>
<p><strong>Problem</strong>: Hierarchical entities have structural concerns (parent, path, identifier) mixed with domain-specific attributes, leading to complex tables and inconsistent patterns across hierarchies.</p>
<p><strong>Solution</strong>: Split into <code>tb_{entity}</code> (structure: pk, parent, path, identifier) and <code>tb_{entity}_info</code> (domain attributes: name, type, metadata), with convenience view for querying.</p>
<p><strong>Complexity</strong>: COMPLEX - Requires dual table generation, FK management, view creation</p>
<p><strong>Teams Involved</strong>:
- <strong>Team B</strong>: Generate both tables + view
- <strong>Team D</strong>: FraiseQL annotations for both tables</p>
<p><strong>Business Value</strong>: Clean separation of concerns, reusable tree logic, easier versioning/auditing of attribute changes</p>
<p><strong>Expert Validation</strong>: SQL architect confirmed "good, intentional design" for hierarchical entities</p>
<hr />
<h3 id="phase-1-ast-support-for-metadata-split">PHASE 1: AST Support for Metadata Split</h3>
<p><strong>Objective</strong>: Extend SpecQL to recognize and parse metadata split configuration</p>
<p><strong>Duration</strong>: 2 days</p>
<h4 id="tdd-cycle-11-parse-metadata-split-flag">TDD Cycle 1.1: Parse Metadata Split Flag</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/core/test_metadata_split_parsing.py

def test_parse_metadata_split_flag():
    &quot;&quot;&quot;Should recognize metadata_split flag for hierarchical entities&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Location
schema: management

hierarchical: true
metadata_split: true  # Enable node+info pattern

fields:
  # Node fields (structural)
  parent: ref(Location)

  # Info fields (domain attributes)
  location_type: ref(LocationType)
  legal_name: text
  tax_id: text
&quot;&quot;&quot;

    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    assert entity.metadata_split is True
    assert entity.is_hierarchical is True
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'Entity' object has no attribute 'metadata_split'</code></p>
<hr />
<p><strong>GREEN</strong>: Add to AST</p>
<pre><code class="language-python"># src/core/ast_models.py

@dataclass
class Entity:
    name: str
    schema: str
    fields: List[Field]
    is_hierarchical: bool = False
    metadata_split: bool = False  # NEW
    # ... existing fields ...
</code></pre>
<p><strong>Update parser</strong>:</p>
<pre><code class="language-python"># src/core/specql_parser.py

def parse(self, yaml_content: str) -&gt; Entity:
    data = yaml.safe_load(yaml_content)

    # ... existing parsing ...

    metadata_split = data.get(&quot;metadata_split&quot;, False)

    # Validation: metadata_split requires hierarchical
    if metadata_split and not is_hierarchical:
        raise ValueError(
            f&quot;Entity {entity_name}: metadata_split requires hierarchical=true&quot;
        )

    entity = Entity(
        # ... existing fields ...
        is_hierarchical=is_hierarchical,
        metadata_split=metadata_split
    )

    return entity
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/core/test_metadata_split_parsing.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Add validation test</p>
<pre><code class="language-python">def test_metadata_split_requires_hierarchical():
    &quot;&quot;&quot;metadata_split without hierarchical should raise error&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Contact
metadata_split: true  # Error - not hierarchical
fields:
  email: text
&quot;&quot;&quot;
    parser = SpecQLParser()
    with pytest.raises(ValueError, match=&quot;metadata_split requires hierarchical&quot;):
        parser.parse(yaml_content)
</code></pre>
<hr />
<p><strong>QA</strong>: Edge cases</p>
<pre><code class="language-python">def test_hierarchical_without_metadata_split():
    &quot;&quot;&quot;Hierarchical entities can opt out of metadata split&quot;&quot;&quot;
    yaml_content = &quot;&quot;&quot;
entity: Category
hierarchical: true
metadata_split: false  # Single table
fields:
  parent: ref(Category)
  name: text
&quot;&quot;&quot;
    parser = SpecQLParser()
    entity = parser.parse(yaml_content)

    assert entity.is_hierarchical is True
    assert entity.metadata_split is False
</code></pre>
<hr />
<h3 id="phase-2-field-classification">PHASE 2: Field Classification</h3>
<p><strong>Objective</strong>: Classify fields into "node" (structural) vs "info" (domain) categories</p>
<p><strong>Duration</strong>: 3 days</p>
<h4 id="tdd-cycle-21-detect-node-vs-info-fields">TDD Cycle 2.1: Detect Node vs Info Fields</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/schema/test_field_classification.py

def test_classify_fields_for_metadata_split():
    &quot;&quot;&quot;Should classify fields into node and info categories&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[
            # Node fields (structural)
            Field(name=&quot;parent&quot;, field_type=FieldType(base_type=&quot;ref&quot;, ref_entity=&quot;Location&quot;)),

            # Info fields (domain attributes)
            Field(name=&quot;location_type&quot;, field_type=FieldType(base_type=&quot;ref&quot;, ref_entity=&quot;LocationType&quot;)),
            Field(name=&quot;legal_name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
            Field(name=&quot;tax_id&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
        ]
    )

    generator = SchemaGenerator()
    classifier = generator.field_classifier

    node_fields, info_fields = classifier.classify(entity)

    # Node fields: only parent (trinity, path, identifier auto-added)
    assert len(node_fields) == 1
    assert node_fields[0].name == &quot;parent&quot;

    # Info fields: all domain attributes
    assert len(info_fields) == 3
    info_names = [f.name for f in info_fields]
    assert &quot;location_type&quot; in info_names
    assert &quot;legal_name&quot; in info_names
    assert &quot;tax_id&quot; in info_names
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'SchemaGenerator' object has no attribute 'field_classifier'</code></p>
<hr />
<p><strong>GREEN</strong>: Implement classifier</p>
<pre><code class="language-python"># src/generators/schema/field_classifier.py

class FieldClassifier:
    &quot;&quot;&quot;Classify fields into node (structural) vs info (domain) for metadata split&quot;&quot;&quot;

    NODE_FIELD_PATTERNS = {
        &quot;parent&quot;,           # Self-reference
        &quot;fk_parent&quot;,        # Parent FK variations
        &quot;organizational_unit&quot;,  # Org hierarchy reference
    }

    def classify(self, entity: Entity) -&gt; Tuple[List[Field], List[Field]]:
        &quot;&quot;&quot;
        Classify entity fields into node and info categories.

        Node fields (go in tb_{entity}):
        - Self-referencing parent field
        - Trinity pattern fields (auto-added, not from user)
        - Path field (auto-added for hierarchical)
        - Audit fields (auto-added)

        Info fields (go in tb_{entity}_info):
        - All other user-defined fields

        Returns:
            (node_fields, info_fields)
        &quot;&quot;&quot;
        if not entity.metadata_split:
            raise ValueError(&quot;classify() only applies to metadata_split entities&quot;)

        node_fields = []
        info_fields = []

        for field in entity.fields:
            if self._is_node_field(field, entity):
                node_fields.append(field)
            else:
                info_fields.append(field)

        return node_fields, info_fields

    def _is_node_field(self, field: Field, entity: Entity) -&gt; bool:
        &quot;&quot;&quot;Determine if field belongs in node table&quot;&quot;&quot;

        # Self-reference (parent field)
        if field.field_type.is_self_reference:
            return True

        # Known node field patterns
        if field.name.lower() in self.NODE_FIELD_PATTERNS:
            return True

        # Everything else is info
        return False

# Update SchemaGenerator
class SchemaGenerator:
    def __init__(self):
        self.field_classifier = FieldClassifier()
        self.ltree_gen = LtreeGenerator()
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_field_classification.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Support explicit classification</p>
<pre><code class="language-python"># Allow users to explicitly mark fields as node/info

@dataclass
class Field:
    name: str
    field_type: FieldType
    required: bool = True
    table_placement: Optional[str] = None  # NEW: &quot;node&quot;, &quot;info&quot;, or None (auto)

# In YAML:
# fields:
#   created_by:
#     type: ref(User)
#     table: node  # Explicitly in node table
</code></pre>
<hr />
<p><strong>QA</strong>: Test edge cases</p>
<pre><code class="language-python">def test_classify_all_info_fields():
    &quot;&quot;&quot;Entity with no user node fields should have all in info table&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[
            Field(name=&quot;name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
            Field(name=&quot;description&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
        ]
    )

    classifier = FieldClassifier()
    node_fields, info_fields = classifier.classify(entity)

    assert len(node_fields) == 0  # No user-defined node fields
    assert len(info_fields) == 2

def test_classify_with_explicit_placement():
    &quot;&quot;&quot;Should respect explicit table placement&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[
            Field(name=&quot;created_by&quot;, field_type=FieldType(base_type=&quot;uuid&quot;),
                  table_placement=&quot;node&quot;),  # Force into node table
            Field(name=&quot;name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
        ]
    )

    classifier = FieldClassifier()
    node_fields, info_fields = classifier.classify(entity)

    assert any(f.name == &quot;created_by&quot; for f in node_fields)
    assert len(info_fields) == 1
</code></pre>
<hr />
<h3 id="phase-3-generate-node-and-info-tables">PHASE 3: Generate Node and Info Tables</h3>
<p><strong>Objective</strong>: Generate both <code>tb_{entity}</code> and <code>tb_{entity}_info</code> tables</p>
<p><strong>Duration</strong>: 5 days</p>
<h4 id="tdd-cycle-31-generate-node-table">TDD Cycle 3.1: Generate Node Table</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/schema/test_node_info_generation.py

def test_generate_node_table():
    &quot;&quot;&quot;Should generate node table with structural fields only&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[
            Field(name=&quot;parent&quot;, field_type=FieldType(
                base_type=&quot;ref&quot;,
                ref_entity=&quot;Location&quot;,
                is_self_reference=True
            )),
            Field(name=&quot;name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
        ]
    )

    generator = SchemaGenerator()
    sql = generator.generate_node_table(entity)

    # Should have trinity pattern
    assert &quot;pk_location INTEGER GENERATED ALWAYS AS IDENTITY PRIMARY KEY&quot; in sql
    assert &quot;id UUID NOT NULL DEFAULT gen_random_uuid()&quot; in sql
    assert &quot;identifier TEXT UNIQUE&quot; in sql

    # Should have LTREE path
    assert &quot;path LTREE NOT NULL&quot; in sql

    # Should have parent FK
    assert &quot;fk_parent_location INTEGER REFERENCES management.tb_location(pk_location)&quot; in sql

    # Should have FK to info table
    assert &quot;fk_location_info INTEGER NOT NULL REFERENCES management.tb_location_info(pk_location_info)&quot; in sql

    # Should NOT have domain fields
    assert &quot;name&quot; not in sql  # Domain field goes in info table

    # Should have audit fields
    assert &quot;created_at&quot; in sql
    assert &quot;updated_at&quot; in sql
</code></pre>
<p><strong>Expected failure</strong>: <code>AttributeError: 'SchemaGenerator' object has no attribute 'generate_node_table'</code></p>
<hr />
<p><strong>GREEN</strong>: Implement node table generation</p>
<pre><code class="language-python"># src/generators/schema/metadata_split_generator.py

class MetadataSplitGenerator:
    &quot;&quot;&quot;Generator for node+info two-table pattern&quot;&quot;&quot;

    def __init__(self, field_classifier: FieldClassifier):
        self.classifier = field_classifier

    def generate_node_table(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate tb_{entity} node table (structure only)&quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()
        pk_name = f&quot;pk_{entity_name}&quot;

        node_fields, _ = self.classifier.classify(entity)

        columns = []

        # Trinity pattern
        columns.append(f&quot;    {pk_name} INTEGER GENERATED ALWAYS AS IDENTITY PRIMARY KEY&quot;)
        columns.append(&quot;    id UUID NOT NULL DEFAULT gen_random_uuid() UNIQUE&quot;)
        columns.append(&quot;    identifier TEXT UNIQUE&quot;)

        # LTREE path (hierarchical)
        columns.append(&quot;    path LTREE NOT NULL&quot;)

        # Parent FK (self-reference)
        parent_field = next((f for f in node_fields if f.field_type.is_self_reference), None)
        if parent_field:
            parent_fk = f&quot;fk_{parent_field.name}&quot;
            columns.append(
                f&quot;    {parent_fk} INTEGER REFERENCES {schema}.tb_{entity_name}({pk_name})&quot;
            )

        # FK to info table
        columns.append(
            f&quot;    fk_{entity_name}_info INTEGER NOT NULL &quot;
            f&quot;REFERENCES {schema}.tb_{entity_name}_info(pk_{entity_name}_info)&quot;
        )

        # Audit fields
        columns.append(&quot;    created_at TIMESTAMPTZ NOT NULL DEFAULT now()&quot;)
        columns.append(&quot;    created_by UUID&quot;)
        columns.append(&quot;    updated_at TIMESTAMPTZ DEFAULT now()&quot;)
        columns.append(&quot;    updated_by UUID&quot;)
        columns.append(&quot;    deleted_at TIMESTAMPTZ&quot;)

        return f&quot;&quot;&quot;
CREATE TABLE {schema}.tb_{entity_name} (
{',\n'.join(columns)}
);
&quot;&quot;&quot;.strip()

# Update SchemaGenerator
class SchemaGenerator:
    def __init__(self):
        self.field_classifier = FieldClassifier()
        self.metadata_split_gen = MetadataSplitGenerator(self.field_classifier)
        self.ltree_gen = LtreeGenerator()

    def generate_node_table(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate node table for metadata split entities&quot;&quot;&quot;
        return self.metadata_split_gen.generate_node_table(entity)
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_node_info_generation.py::test_generate_node_table -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<h4 id="tdd-cycle-32-generate-info-table">TDD Cycle 3.2: Generate Info Table</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python">def test_generate_info_table():
    &quot;&quot;&quot;Should generate info table with domain attributes only&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[
            Field(name=&quot;parent&quot;, field_type=FieldType(
                base_type=&quot;ref&quot;,
                ref_entity=&quot;Location&quot;,
                is_self_reference=True
            )),
            Field(name=&quot;location_type&quot;, field_type=FieldType(
                base_type=&quot;ref&quot;,
                ref_entity=&quot;LocationType&quot;
            )),
            Field(name=&quot;legal_name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
            Field(name=&quot;tax_id&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
        ]
    )

    generator = SchemaGenerator()
    sql = generator.generate_info_table(entity)

    # Should have trinity pattern
    assert &quot;pk_location_info INTEGER GENERATED ALWAYS AS IDENTITY PRIMARY KEY&quot; in sql
    assert &quot;id UUID&quot; in sql

    # Should have domain attributes
    assert &quot;fk_location_type INTEGER REFERENCES catalog.tb_location_type&quot; in sql
    assert &quot;legal_name TEXT&quot; in sql
    assert &quot;tax_id TEXT&quot; in sql

    # Should NOT have structural fields
    assert &quot;path LTREE&quot; not in sql
    assert &quot;fk_parent_location&quot; not in sql

    # Should have audit fields
    assert &quot;created_at&quot; in sql
    assert &quot;updated_at&quot; in sql
</code></pre>
<hr />
<p><strong>GREEN</strong>: Implement info table generation</p>
<pre><code class="language-python"># src/generators/schema/metadata_split_generator.py

class MetadataSplitGenerator:
    def generate_info_table(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate tb_{entity}_info table (domain attributes)&quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()
        pk_name = f&quot;pk_{entity_name}_info&quot;

        _, info_fields = self.classifier.classify(entity)

        columns = []

        # Trinity pattern
        columns.append(f&quot;    {pk_name} INTEGER GENERATED ALWAYS AS IDENTITY PRIMARY KEY&quot;)
        columns.append(&quot;    id UUID NOT NULL DEFAULT gen_random_uuid() UNIQUE&quot;)
        columns.append(&quot;    identifier TEXT&quot;)

        # Domain attribute columns
        for field in info_fields:
            col_def = self._field_to_column(field, entity)
            columns.append(f&quot;    {col_def}&quot;)

        # Audit fields
        columns.append(&quot;    created_at TIMESTAMPTZ NOT NULL DEFAULT now()&quot;)
        columns.append(&quot;    created_by UUID&quot;)
        columns.append(&quot;    updated_at TIMESTAMPTZ DEFAULT now()&quot;)
        columns.append(&quot;    updated_by UUID&quot;)

        return f&quot;&quot;&quot;
CREATE TABLE {schema}.tb_{entity_name}_info (
{',\n'.join(columns)}
);
&quot;&quot;&quot;.strip()

    def _field_to_column(self, field: Field, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Convert field to SQL column definition&quot;&quot;&quot;
        field_type = field.field_type

        if field_type.base_type == &quot;ref&quot;:
            # Foreign key
            ref_table = f&quot;tb_{field_type.ref_entity.lower()}&quot;
            ref_pk = f&quot;pk_{field_type.ref_entity.lower()}&quot;
            # Determine schema (TODO: make this configurable)
            ref_schema = &quot;catalog&quot;  # Default for reference data
            col_name = f&quot;fk_{field.name}&quot;
            return f&quot;{col_name} INTEGER REFERENCES {ref_schema}.{ref_table}({ref_pk})&quot;

        elif field_type.base_type == &quot;text&quot;:
            return f&quot;{field.name} TEXT&quot;

        elif field_type.base_type == &quot;integer&quot;:
            return f&quot;{field.name} INTEGER&quot;

        # ... other type mappings ...

        else:
            raise ValueError(f&quot;Unsupported field type: {field_type.base_type}&quot;)
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_node_info_generation.py::test_generate_info_table -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Extract column generation to shared utility</p>
<pre><code class="language-python"># src/generators/schema/column_generator.py

class ColumnGenerator:
    &quot;&quot;&quot;Generate SQL column definitions from Field AST&quot;&quot;&quot;

    def generate(self, field: Field, entity: Entity, context: str = &quot;table&quot;) -&gt; str:
        &quot;&quot;&quot;
        Generate SQL column definition.

        Args:
            field: Field from AST
            entity: Parent entity
            context: &quot;table&quot; or &quot;info&quot; (affects FK schema resolution)
        &quot;&quot;&quot;
        # Centralized column generation logic
        # Used by both regular tables and info tables
        # ... implementation ...
</code></pre>
<hr />
<h4 id="tdd-cycle-33-orchestrate-generation">TDD Cycle 3.3: Orchestrate Generation</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python">def test_generate_metadata_split_tables():
    &quot;&quot;&quot;Should generate both node and info tables when metadata_split=true&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[...]
    )

    generator = SchemaGenerator()
    sql = generator.generate_table(entity)

    # Should contain both tables
    assert &quot;CREATE TABLE management.tb_location (&quot; in sql
    assert &quot;CREATE TABLE management.tb_location_info (&quot; in sql

    # Node table should come first (info table references it)
    info_pos = sql.index(&quot;tb_location_info&quot;)
    node_pos = sql.index(&quot;CREATE TABLE management.tb_location (&quot;)
    assert node_pos &lt; info_pos
</code></pre>
<hr />
<p><strong>GREEN</strong>: Update main generate_table method</p>
<pre><code class="language-python"># src/generators/schema/schema_generator.py

class SchemaGenerator:
    def generate_table(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;
        Generate table(s) for entity.

        - If metadata_split=true: generates node + info tables
        - Otherwise: generates single table
        &quot;&quot;&quot;
        if entity.metadata_split:
            return self._generate_metadata_split_tables(entity)
        else:
            return self._generate_single_table(entity)

    def _generate_metadata_split_tables(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate node + info tables&quot;&quot;&quot;
        parts = []

        # 1. Info table (no dependencies)
        parts.append(self.metadata_split_gen.generate_info_table(entity))

        # 2. Node table (references info table)
        parts.append(self.metadata_split_gen.generate_node_table(entity))

        # 3. Indexes for both tables
        parts.append(self._generate_metadata_split_indexes(entity))

        # 4. LTREE triggers (node table)
        if entity.is_hierarchical:
            parts.append(self.ltree_gen.generate_path_trigger(entity))

        # 5. Convenience view
        parts.append(self._generate_combined_view(entity))

        return &quot;\n\n&quot;.join(parts)

    def _generate_single_table(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate regular single table (existing implementation)&quot;&quot;&quot;
        # ... existing code ...
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_node_info_generation.py::test_generate_metadata_split_tables -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>QA</strong>: Integration test</p>
<pre><code class="language-python"># tests/integration/test_metadata_split_tables.py

def test_metadata_split_tables_execute(test_db):
    &quot;&quot;&quot;Node and info tables should execute without errors&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[
            Field(name=&quot;parent&quot;, field_type=FieldType(
                base_type=&quot;ref&quot;,
                ref_entity=&quot;Location&quot;,
                is_self_reference=True
            )),
            Field(name=&quot;name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
        ]
    )

    generator = SchemaGenerator()
    sql = generator.generate_table(entity)

    # Execute SQL
    test_db.execute(sql)

    # Verify both tables exist
    test_db.execute(&quot;&quot;&quot;
        SELECT table_name
        FROM information_schema.tables
        WHERE table_schema = 'management'
          AND table_name IN ('tb_location', 'tb_location_info')
        ORDER BY table_name
    &quot;&quot;&quot;)
    tables = [row[0] for row in test_db.fetchall()]
    assert tables == ['tb_location', 'tb_location_info']

    # Verify FK constraint exists
    test_db.execute(&quot;&quot;&quot;
        SELECT constraint_name
        FROM information_schema.table_constraints
        WHERE table_name = 'tb_location'
          AND constraint_type = 'FOREIGN KEY'
          AND constraint_name LIKE '%location_info%'
    &quot;&quot;&quot;)
    assert test_db.fetchone() is not None
</code></pre>
<hr />
<h3 id="phase-4-generate-convenience-view">PHASE 4: Generate Convenience View</h3>
<p><strong>Objective</strong>: Create <code>v_{entity}</code> view that joins node + info for easy querying</p>
<p><strong>Duration</strong>: 2 days</p>
<h4 id="tdd-cycle-41-generate-joined-view">TDD Cycle 4.1: Generate Joined View</h4>
<p><strong>RED</strong>: Write failing test</p>
<pre><code class="language-python"># tests/unit/schema/test_convenience_view.py

def test_generate_convenience_view():
    &quot;&quot;&quot;Should generate view that joins node and info tables&quot;&quot;&quot;
    entity = Entity(
        name=&quot;Location&quot;,
        schema=&quot;management&quot;,
        is_hierarchical=True,
        metadata_split=True,
        fields=[
            Field(name=&quot;parent&quot;, field_type=FieldType(
                base_type=&quot;ref&quot;,
                ref_entity=&quot;Location&quot;,
                is_self_reference=True
            )),
            Field(name=&quot;name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
            Field(name=&quot;legal_name&quot;, field_type=FieldType(base_type=&quot;text&quot;)),
        ]
    )

    generator = SchemaGenerator()
    sql = generator._generate_combined_view(entity)

    # Should create view
    assert &quot;CREATE OR REPLACE VIEW management.v_location&quot; in sql

    # Should select from both tables
    assert &quot;FROM management.tb_location n&quot; in sql
    assert &quot;JOIN management.tb_location_info i&quot; in sql
    assert &quot;ON n.fk_location_info = i.pk_location_info&quot; in sql

    # Should expose all fields
    assert &quot;n.pk_location&quot; in sql
    assert &quot;n.id&quot; in sql
    assert &quot;n.path&quot; in sql
    assert &quot;n.fk_parent_location&quot; in sql
    assert &quot;i.name&quot; in sql
    assert &quot;i.legal_name&quot; in sql

    # Should have FraiseQL annotation
    assert &quot;COMMENT ON VIEW management.v_location&quot; in sql
    assert &quot;@fraiseql:type name=Location&quot; in sql
</code></pre>
<p><strong>Expected failure</strong>: Method doesn't exist yet</p>
<hr />
<p><strong>GREEN</strong>: Implement view generation</p>
<pre><code class="language-python"># src/generators/schema/metadata_split_generator.py

class MetadataSplitGenerator:
    def generate_combined_view(self, entity: Entity) -&gt; str:
        &quot;&quot;&quot;Generate convenience view joining node + info tables&quot;&quot;&quot;
        schema = entity.schema
        entity_name = entity.name.lower()

        node_fields, info_fields = self.classifier.classify(entity)

        # Build SELECT list
        select_columns = []

        # Node table fields
        select_columns.append(f&quot;    n.pk_{entity_name}&quot;)
        select_columns.append(&quot;    n.id&quot;)
        select_columns.append(&quot;    n.identifier&quot;)
        select_columns.append(&quot;    n.path&quot;)
        select_columns.append(f&quot;    n.fk_parent_{entity_name} AS parent_id&quot;)
        select_columns.append(&quot;    n.created_at&quot;)
        select_columns.append(&quot;    n.created_by&quot;)
        select_columns.append(&quot;    n.updated_at&quot;)
        select_columns.append(&quot;    n.updated_by&quot;)
        select_columns.append(&quot;    n.deleted_at&quot;)

        # Info table fields
        for field in info_fields:
            select_columns.append(f&quot;    i.{field.name}&quot;)

        select_clause = &quot;,\n&quot;.join(select_columns)

        return f&quot;&quot;&quot;
CREATE OR REPLACE VIEW {schema}.v_{entity_name} AS
SELECT
{select_clause}
FROM {schema}.tb_{entity_name} n
JOIN {schema}.tb_{entity_name}_info i
    ON n.fk_{entity_name}_info = i.pk_{entity_name}_info
WHERE n.deleted_at IS NULL;  -- Soft delete filter

COMMENT ON VIEW {schema}.v_{entity_name} IS
  '@fraiseql:type name={entity.name},schema={schema}
   Convenience view combining node and info tables';
&quot;&quot;&quot;.strip()
</code></pre>
<p><strong>Run test</strong>: <code>uv run pytest tests/unit/schema/test_convenience_view.py -v</code></p>
<p><strong>Expected</strong>: ✅ PASS</p>
<hr />
<p><strong>REFACTOR</strong>: Make view queryable in FraiseQL</p>
<pre><code class="language-python"># Add field-level annotations

def generate_combined_view(self, entity: Entity) -&gt; str:
    # ... existing code ...

    view_sql = f&quot;&quot;&quot;
CREATE OR REPLACE VIEW {schema}.v_{entity_name} AS
SELECT
{select_clause}
FROM {schema}.tb_{entity_name} n
JOIN {schema}.tb_{entity_name}_info i
    ON n.fk_{entity_name}_info = i.pk_{entity_name}_info
WHERE n.deleted_at IS NULL;
&quot;&quot;&quot;

    # Add table-level comment
    comments = [f&quot;&quot;&quot;
COMMENT ON VIEW {schema}.v_{entity_name} IS
  '@fraiseql:type name={entity.name},schema={schema}';
&quot;&quot;&quot;]

    # Add column-level comments for GraphQL field mapping
    for field in info_fields:
        field_type = self._map_graphql_type(field.field_type)
        comments.append(f&quot;&quot;&quot;
COMMENT ON COLUMN {schema}.v_{entity_name}.{field.name} IS
  '@fraiseql:field name={field.name},type={field_type}';
&quot;&quot;&quot;)

    return view_sql + &quot;\n&quot; + &quot;\n&quot;.join(comments)
</code></pre>
<hr />
<p><strong>QA</strong>: Test view queries</p>
<pre><code class="language-python"># tests/integration/test_convenience_view_queries.py

def test_query_through_convenience_view(test_db):
    &quot;&quot;&quot;Should be able to query node+info through view&quot;&quot;&quot;

    # Setup tables and view
    entity = Entity(...)
    generator = SchemaGenerator()
    test_db.execute(generator.generate_table(entity))

    # Insert info record
    test_db.execute(&quot;&quot;&quot;
        INSERT INTO management.tb_location_info (id, identifier, name, legal_name)
        VALUES (gen_random_uuid(), 'usa-info', 'United States', 'United States of America')
        RETURNING pk_location_info
    &quot;&quot;&quot;)
    info_pk = test_db.fetchone()[0]

    # Insert node record
    test_db.execute(f&quot;&quot;&quot;
        INSERT INTO management.tb_location
        (id, identifier, path, fk_parent_location, fk_location_info)
        VALUES (gen_random_uuid(), 'USA', 'USA', NULL, {info_pk})
        RETURNING pk_location
    &quot;&quot;&quot;)

    # Query through view
    test_db.execute(&quot;&quot;&quot;
        SELECT identifier, name, legal_name, path::text
        FROM management.v_location
        WHERE identifier = 'USA'
    &quot;&quot;&quot;)

    result = test_db.fetchone()
    assert result[0] == 'USA'           # identifier (from node)
    assert result[1] == 'United States' # name (from info)
    assert result[2] == 'United States of America'  # legal_name (from info)
    assert result[3] == 'USA'           # path (from node)
</code></pre>
<hr />
<h3 id="phase-5-fraiseql-integration">PHASE 5: FraiseQL Integration</h3>
<p><strong>Objective</strong>: Generate proper FraiseQL annotations for both tables and view</p>
<p><strong>Duration</strong>: 2 days</p>
<p><em>(Implementation similar to Team D work - generates @fraiseql comments)</em></p>
<p><strong>Key Aspects</strong>:
- Annotate <code>v_{entity}</code> view as primary GraphQL type
- Mark <code>tb_{entity}</code> and <code>tb_{entity}_info</code> as internal
- Expose node structural fields (path, parent) through GraphQL
- Map info domain fields to GraphQL fields
- Generate mutations that work with both tables</p>
<hr />
<h2 id="success-criteria-pattern-3">Success Criteria - Pattern 3</h2>
<ul>
<li>[ ] Parser recognizes <code>metadata_split: true</code> flag</li>
<li>[ ] Field classifier correctly separates node vs info fields</li>
<li>[ ] <code>tb_{entity}</code> node table generated with structural fields only</li>
<li>[ ] <code>tb_{entity}_info</code> table generated with domain attributes</li>
<li>[ ] Info table created before node table (dependency order)</li>
<li>[ ] FK from node to info table established</li>
<li>[ ] LTREE path maintained in node table</li>
<li>[ ] Convenience view <code>v_{entity}</code> joins both tables</li>
<li>[ ] View exposes all fields (node + info)</li>
<li>[ ] FraiseQL annotations expose view as primary GraphQL type</li>
<li>[ ] All tests pass (90%+ coverage)</li>
<li>[ ] Integration tests verify queries work through view</li>
<li>[ ] Documentation includes node+info pattern examples</li>
</ul>
<hr />
<h2 id="overall-implementation-timeline">Overall Implementation Timeline</h2>
<table>
<thead>
<tr>
<th>Week</th>
<th>Pattern</th>
<th>Team</th>
<th>Focus</th>
<th>Deliverables</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1</strong></td>
<td>Recalcid</td>
<td>B</td>
<td>Foundation types</td>
<td><code>recalculation_context</code> type in migration 000</td>
</tr>
<tr>
<td><strong>2</strong></td>
<td>Recalcid</td>
<td>A, C</td>
<td>AST + Basic generation</td>
<td>Parse cascade_updates, generate simple recalcid functions</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td>LTREE</td>
<td>B</td>
<td>Detection + Schema</td>
<td>Detect hierarchical entities, generate path columns and triggers</td>
</tr>
<tr>
<td><strong>4</strong></td>
<td>LTREE</td>
<td>B</td>
<td>Helpers + Testing</td>
<td>Generate helper functions, comprehensive testing</td>
</tr>
<tr>
<td><strong>5</strong></td>
<td>Node+Info</td>
<td>A, B</td>
<td>AST + Field classification</td>
<td>Parse metadata_split, classify fields</td>
</tr>
<tr>
<td><strong>6</strong></td>
<td>Node+Info</td>
<td>B</td>
<td>Table generation</td>
<td>Generate both tables + view</td>
</tr>
</tbody>
</table>
<p><strong>Total Duration</strong>: 6 weeks (assumes 1 pattern per 2 weeks)</p>
<hr />
<h2 id="testing-strategy">Testing Strategy</h2>
<h3 id="unit-tests-per-pattern">Unit Tests (Per Pattern)</h3>
<ul>
<li><strong>Coverage target</strong>: 90%+</li>
<li><strong>Test first</strong>: RED → GREEN → REFACTOR → QA cycle</li>
<li><strong>Categories</strong>:</li>
<li>AST parsing (Team A)</li>
<li>SQL generation (Team B)</li>
<li>Validation logic</li>
<li>Edge cases</li>
</ul>
<h3 id="integration-tests">Integration Tests</h3>
<ul>
<li><strong>Database</strong>: Real PostgreSQL instance</li>
<li><strong>Execute generated SQL</strong>: Verify syntax and execution</li>
<li><strong>Data operations</strong>: INSERT, UPDATE, queries</li>
<li><strong>Cascade chains</strong>: Verify recalcid propagation</li>
<li><strong>Hierarchical queries</strong>: Test LTREE operators</li>
<li><strong>View queries</strong>: Test node+info joins</li>
</ul>
<h3 id="end-to-end-tests">End-to-End Tests</h3>
<ul>
<li><strong>Full pipeline</strong>: SpecQL YAML → SQL → Database → GraphQL</li>
<li><strong>FraiseQL introspection</strong>: Verify GraphQL schema generation</li>
<li><strong>Performance</strong>: Benchmark hierarchical queries with LTREE</li>
<li><strong>Migration</strong>: Test schema evolution scenarios</li>
</ul>
<hr />
<h2 id="documentation-deliverables">Documentation Deliverables</h2>
<h3 id="for-each-pattern">For Each Pattern</h3>
<ol>
<li><strong>Architecture Decision Record (ADR)</strong></li>
<li>Why this pattern?</li>
<li>What problem does it solve?</li>
<li>Alternatives considered</li>
<li>
<p>Trade-offs</p>
</li>
<li>
<p><strong>SpecQL Syntax Guide</strong></p>
</li>
<li>How to enable in YAML</li>
<li>Examples</li>
<li>
<p>Best practices</p>
</li>
<li>
<p><strong>Generated SQL Examples</strong></p>
</li>
<li>Before/after comparison</li>
<li>Annotated output</li>
<li>
<p>Performance considerations</p>
</li>
<li>
<p><strong>GraphQL Integration Guide</strong></p>
</li>
<li>FraiseQL annotations</li>
<li>Query examples</li>
<li>
<p>Mutation patterns</p>
</li>
<li>
<p><strong>Migration Guide</strong></p>
</li>
<li>Adding pattern to existing entities</li>
<li>Breaking changes</li>
<li>Backward compatibility</li>
</ol>
<hr />
<h2 id="risk-mitigation">Risk Mitigation</h2>
<h3 id="pattern-1-recalcid">Pattern 1: Recalcid</h3>
<p><strong>Risk</strong>: Cascade chains cause infinite loops
<strong>Mitigation</strong>:
- Limit cascade depth
- Add cycle detection
- Comprehensive tests for circular references</p>
<h3 id="pattern-2-ltree">Pattern 2: LTREE</h3>
<p><strong>Risk</strong>: Path updates on node moves are slow
<strong>Mitigation</strong>:
- Benchmark with large trees (10k+ nodes)
- Consider materialized path vs LTREE trade-offs
- Add indexes on common query patterns</p>
<h3 id="pattern-3-nodeinfo">Pattern 3: Node+Info</h3>
<p><strong>Risk</strong>: Confusion about which table to query
<strong>Mitigation</strong>:
- Default to view in documentation
- Clear naming conventions
- FraiseQL exposes only view by default</p>
<hr />
<h2 id="next-steps">Next Steps</h2>
<ol>
<li><strong>Review and approve</strong> this implementation plan</li>
<li><strong>Prioritize patterns</strong> - Which to implement first?</li>
<li><strong>Assign teams</strong> - Map to existing Team A/B/C structure</li>
<li><strong>Create epics</strong> - Break into sprint-sized chunks</li>
<li><strong>Begin Phase 1</strong> of highest-priority pattern</li>
</ol>
<p>Would you like me to:
1. <strong>Start implementing</strong> Pattern 1 (recalcid) immediately?
2. <strong>Create detailed test specifications</strong> for each phase?
3. <strong>Generate example YAML files</strong> showing pattern usage?
4. <strong>Draft ADRs</strong> for architectural decisions?</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
